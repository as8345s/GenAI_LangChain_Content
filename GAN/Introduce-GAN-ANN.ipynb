{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7680ebd-ae71-4fa5-80dc-626581270f03",
   "metadata": {},
   "source": [
    "<h1>GAN - Generative Adversarial Network - from Scratch</h1>\n",
    "- ANN, CNN als zweites Notebook mit anderen Ansätzen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc6292a-1179-40d0-bf92-55803f676e64",
   "metadata": {},
   "source": [
    "Ein GAN ist ein Netzwerk, das aus zwei verschiedenen Komponenten besteht. Das Ziel <u>hier</u> ist es Bilder zu generieren.<br>\n",
    "GAN kann auch andere Typen von Daten erzeugen wie Audio. Alle Typen von Daten die man aus einem Vektor eines Netzes erstellen kann, um es allgemein auszudrücken.\n",
    "- Bei Bildern zum Beispiel: Output ist ein 400 Pixel-Vektor -> Reshape -> 20x20 Pixel Bild.\n",
    "\n",
    "\n",
    "Ein GAN besteht aus:<br>\n",
    "- Einem Generator, der ein Bild erzeugen soll. Durch Anpassung der Weights kann das Model in eine Richtung gelenkt werden, das am Ende ein Vektor ausgibt das als Bild angezeigt werden kann. Quasi das Gegenteil von einem CNN.\n",
    "- Ein Discriminator, der das Generatornetz evaluiert.\n",
    "\n",
    "Beide versuchen einander zu übertrumpfen => Generator generiert immer bessere Fakes während der Discriminator immer besser darin wird Fakes zu erkennen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1864545-15f8-4e5b-89ca-1943d219ea55",
   "metadata": {},
   "source": [
    "Beide können aus einem ANN oder CNN erstellt werden. Je umfangreicher das Netz ist, desto mehr Features kann es besser Abdecken.\n",
    "\n",
    "Ein einfaches Netz kann aus zwei ANNs erstellt werden. \n",
    "\n",
    "GANs können in verschiedene Use-Cases eingesetzt werden. Um ein erstes einfaches Beispiel zu erstellen, ist die Aufgabe synthetische Bilder von einem Produkt herzustellen was für eine Qualitätskontrolle genutzt werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683e8617-f462-4df7-9285-96ec35405f3e",
   "metadata": {},
   "source": [
    "<i>Abb1</i>: Übersicht GAN. Generator generiert Fakes. Discriminator soll Fakes erkennen. <br>\n",
    "Wenn der Output eines Generators, der aus einem ANN besteht, einen Vektor ausgibt, muss dieser umgeformt werden.\n",
    "\n",
    "<img src=\"./data/img/2_gan.PNG\" height=500 width=700>\n",
    "\n",
    "Das Rauschen (noise) erlaubt dem Netz eine vielfältigere Generierung."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e0c43d-3b28-4998-aab5-2385cf633b15",
   "metadata": {},
   "source": [
    "Als Komponente haben wir ein 20 x 20 Bild mit einem \"L\" darauf. Das L könnte ein L-förmiges Bauteil sein. Bei der Produktion werden viele dieser Komponenten hergestellt. Mit der Synthetisierung dieser Bilder können wir mehr Daten generieren, die für das Training eines CNN verwendet werden können, um Abweichungen besser abzudecken. \n",
    "\n",
    "Wir gehen davon aus das es viel mehr Bilder von guten Bauteilen gibt und sehr wenige von nicht guten Bauteilen. Mit den synthetischen Bildern kann die Lücke geschlossen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4dc49a5-c4c5-45fd-bc28-ccf5950b06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image  as matimg\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535c6f11-affe-4908-884b-a7cb7276d894",
   "metadata": {},
   "source": [
    "<h2> Dataset </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ebe31d-ca05-4f7e-8330-ffff85e4f841",
   "metadata": {},
   "source": [
    "Um so ein Bild zu erstellen, kann ein Zeichenprogramm oder Numpy verwendet werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b112d56e-d57d-4f55-a10a-d01ffd115867",
   "metadata": {},
   "source": [
    "<i>Abb2</i>: Zeichnung L-Objekt.\n",
    "\n",
    "<img src=\"./data/img/1_gan.PNG\" width=400, height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff631f0c-d1cd-4aa7-97f1-7923dae206c9",
   "metadata": {},
   "source": [
    "Alternativ kann auch mit Numpy eine einfache Form gezeichnet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b93abf1-525e-4c00-8e0e-ff81b8791410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle 1 Sample. \n",
    "def create_image(color:int=1) -> np.array:\n",
    "    image = np.zeros((20, 20))  # 2D Matrix, 20x20 Pixel.\n",
    "    # img [yloc, xloc]\n",
    "    image[1:12, 7] = 1  # Zeichne Feld.\n",
    "    image[1:12, 8] = 1  # Zeichne Feld.\n",
    "\n",
    "    image[11, 9:15]  = 1  \n",
    "    image[12, 7:15] = 1  \n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54c30e4a-4a7d-4574-b181-fa799441a3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = create_image()\n",
    "plt.matshow(img)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af5550-6c08-4661-9ec0-0e35e4275eb3",
   "metadata": {},
   "source": [
    "Schnell und einfach ist das Bild erstellt. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8ae06f-79ff-4fe7-894b-723cd201e7d2",
   "metadata": {},
   "source": [
    "<h3>Numpy Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ebb913-7b87-4430-ba91-debc3965e979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(950, 20, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Erstelle Dataset aus n-Samples \n",
    "def numpy_dataset(n:int):\n",
    "    return np.array([create_image() for x in range(n)])\n",
    "    \n",
    "size = 950\n",
    "dataset_numpy = numpy_dataset(size)\n",
    "dataset_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0a83280-1fc3-4939-8394-7974b399c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_numpy = dataset_numpy.reshape(size, 20, 20, 1).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c74cdfb-e749-4cd5-8f0d-3c9d1972dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dann können die Daten normalisiert werden.\n",
    "dataset_numpy_scaled = ( dataset_numpy - 0.5 ) / 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bdb104",
   "metadata": {},
   "source": [
    "Oder lade das Bild als numpy Array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed2aa31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lade Bild mit OpenCV.\n",
    "# - Oder nutze Alternative wie PIL, ..., \n",
    "img = cv2.imread('./data/datasets/L__shape/lshape.jpg')\n",
    "type(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595d82b1",
   "metadata": {},
   "source": [
    "Danach kann das Bild in ein Dataframe geladen und ggf. Transformiert und angepasst werden. Oder nutze andere Methoden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a54d2",
   "metadata": {},
   "source": [
    "<h3>Tensorflow Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "9edd9447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20, 20, 3), dtype=uint8, numpy=\n",
       "array([[[248, 248, 248],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[246, 246, 246],\n",
       "        [255, 255, 255],\n",
       "        [253, 253, 253],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [247, 247, 247],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8)>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lade Bild\n",
    "img = tf.io.read_file('./data/datasets/L__shape/lshape.jpg')\n",
    "img = tf.image.decode_jpeg(img)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "9aa14c41-33d9-41b0-b3b8-5f6272471358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorDataset element_spec=TensorSpec(shape=(20, 20, 3), dtype=tf.uint8, name=None)>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Erstelle Dataset\n",
    "tf_dataset = tf.data.Dataset.from_tensors(img)\n",
    "tf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf9c9f8-c8a5-4aaf-a83b-1d6d162a351f",
   "metadata": {},
   "source": [
    "Danach kann das TF-Dataset beliebig genutzt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc139c-8c2d-4dc2-85d2-b0de1b051556",
   "metadata": {},
   "source": [
    "<h2>GAN Model - ANN</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e972ca2-75c2-4f35-9fd2-e22aa0317ebd",
   "metadata": {},
   "source": [
    "Dann erstellen wir zwei separate ANN Netze die verschiedene Aufgaben übernehmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f9dc5c8-be09-4c10-a80a-646cd8b490fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator ANN #\n",
    "\n",
    "def create_generator():\n",
    "    gen_ann = tf.keras.Sequential([\n",
    "        # Input 100 Units, Output 128 Units.\n",
    "        # - Als Input nehmen wir 100 Pixel. \n",
    "        tf.keras.layers.Dense(units=128, input_shape=(100,), activation='relu'),\n",
    "    \n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(units=400, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(units=400, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        # Erstelle Vektor der dann als Bild 20x20 Pixel dargestellt wird.\n",
    "        tf.keras.layers.Dense(units=20*20, activation='tanh'),\n",
    "        tf.keras.layers.Reshape((20, 20, 1))  # Reshape zu 20x20 Pixel. Könnte auch außerhalb des Netzes durchgeführt werden. \n",
    "    ])\n",
    "    return gen_ann\n",
    "\n",
    "\n",
    "# Discriminator ANN # \n",
    "def create_discriminator():\n",
    "    dis_ann = tf.keras.Sequential([\n",
    "        # Bild als Input. Netz soll Fake-Images erkennen. \n",
    "        # - Ein Netz das ein Bild klassifizieren soll. \n",
    "        tf.keras.layers.Flatten(input_shape=(20,20, 1)),\n",
    "        tf.keras.layers.Dense(350, activation='relu'),\n",
    "        tf.keras.layers.Dense(450, activation='relu'),\n",
    "        tf.keras.layers.Dense(200, activation='relu'),\n",
    "        # Als Output: Fake oder nicht.\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return dis_ann\n",
    "\n",
    "discriminator = create_discriminator()\n",
    "discriminator.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss      = 'binary_crossentropy',\n",
    "    metrics   = 'accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90306a96",
   "metadata": {},
   "source": [
    "Für einfache Formen sind die Netze ausreichend. Diese können später weiter optimiert werden. <br>\n",
    "Es gibt viele Freiheiten in der Gestaltung der Netze. \n",
    "\n",
    "Der nächste wichtige Schritt ist das Netz zu trainieren. Dazu fügen wir beide Netze zusammen und trainieren vorerst nur den Generator. \n",
    "- Mit einem Parameter können die Weights eines Models eingefroren werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4964736-9676-4e61-8d1d-12d3200e19a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ded1381b-ec02-42d8-8c0d-a718696c066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle GAN - Füge die Teile zusammen.\n",
    "generator = create_generator()\n",
    "gan_input = tf.keras.layers.Input(shape=(100,))  # 100 Startpixel.\n",
    "gen_image = generator(gan_input)\n",
    "\n",
    "net_output = discriminator(gen_image)\n",
    "GAN        = tf.keras.Model(gan_input, net_output)\n",
    "\n",
    "GAN.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb7b76-ad18-4d07-acca-914f71fd6417",
   "metadata": {},
   "source": [
    "Anders als sonst in Tensorflow schreiben wir eine detailreiche Trainingsschleife. \n",
    "- Batching möglich.\n",
    "\n",
    "Später werden wir uns weitere Details anschauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27712e9b-aa21-472c-bf93-f20d9fb0a559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Für das Batching: # \n",
    "# - Random-Index mit:\n",
    "np.random.randint(0, 3, 3)  #  (low, high, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df2680a0-b806-4902-89d2-f76b72efa305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2984485 , -0.92172736,  0.72957133, -0.68902928, -1.69707129,\n",
       "         0.12969378, -0.12396254,  0.17004015, -0.86574714, -0.14667895,\n",
       "        -0.91929565, -1.34390341, -0.82720447,  1.69783386, -1.07410447,\n",
       "        -0.42563261, -0.4322176 ,  0.75114083,  0.11922545, -0.71104917,\n",
       "        -0.57577682, -1.04487421,  1.87367546, -0.12971436,  0.67687567,\n",
       "        -0.0738158 , -0.16786957,  1.2816243 ,  0.54635226, -1.67372136,\n",
       "        -0.88070352, -0.76164491,  0.90045041,  1.24504236,  0.41038121,\n",
       "         1.91038373,  0.77377456, -1.02488568,  0.28679779,  0.01841451,\n",
       "        -0.26762003,  0.18728207, -1.14923996,  1.38017023, -0.4693225 ,\n",
       "        -0.88008422,  1.49973785,  0.85576871, -1.23595744, -0.69968208,\n",
       "         0.82783927, -0.77363653, -0.95372654,  0.35257098, -1.4173874 ,\n",
       "        -0.78598487, -0.38951167,  0.78834177,  0.0656049 , -0.12328854,\n",
       "         1.34490057,  1.31184188,  0.76359822,  2.94642482,  0.28855299,\n",
       "        -1.47900626,  0.80291799,  2.06734429,  0.63091525,  1.65403176,\n",
       "        -0.27702001, -0.21072006,  0.07130295, -1.7002116 , -0.50081343,\n",
       "        -0.82850695, -0.74501245,  0.89176283, -1.38885875,  0.62025264,\n",
       "        -0.03210703, -0.08362294, -1.25604161,  0.39301926, -0.56046729,\n",
       "         0.27899166, -0.47075531,  0.31706699,  0.46105977,  0.17220372,\n",
       "        -0.00982514,  0.99241953, -0.99049133, -0.34082865,  0.21831447,\n",
       "         0.56223779, -0.03843754, -0.03187741, -0.31582409, -0.39244122],\n",
       "       [ 0.90559123, -0.74477309, -1.03510867,  0.18050757, -0.55284267,\n",
       "        -0.73546539,  0.01023177,  0.17395667,  1.55416497,  1.48701652,\n",
       "        -1.48050816, -0.10064114,  0.33120736,  0.70502206,  0.94966198,\n",
       "        -1.20225292,  1.44767199,  0.15776441, -1.20450525,  0.11381235,\n",
       "        -0.2090013 ,  0.04066455,  1.98591894,  0.82507734, -0.10787021,\n",
       "         0.72664072,  0.07673503, -0.59434378, -0.8913211 ,  0.92292659,\n",
       "        -0.77275576,  1.51683761,  0.46867984, -0.19146792,  0.68752616,\n",
       "         0.62469601,  0.88240639, -1.07384365,  0.33660436,  0.56590382,\n",
       "         0.86145394, -1.91312431, -0.00428475, -1.69513844, -0.48241531,\n",
       "         0.50348602, -0.25550631, -0.40442763,  0.93805494, -0.45775768,\n",
       "         1.31251326,  1.35281048,  0.67515137, -2.43355581, -1.98580233,\n",
       "        -0.87701501,  0.97379943,  1.190567  , -0.05161137,  0.27789081,\n",
       "        -0.55216913,  2.04034981,  0.6312764 , -0.98740927, -0.74298153,\n",
       "         0.15339785,  0.08646634, -0.14084293, -1.06627161,  0.43495993,\n",
       "        -0.45672342, -0.14409172,  0.73614699,  1.43959762,  0.22832227,\n",
       "        -0.4897045 ,  1.01384754,  0.35135218,  1.32884648,  0.82553496,\n",
       "        -2.48436999, -0.8953003 ,  0.1697134 , -0.07926802, -1.29802134,\n",
       "        -0.83249348, -0.79181314, -0.48325969, -0.64105192, -1.01821331,\n",
       "         0.35853407,  0.8171843 ,  1.48989991, -1.47826694,  0.09484644,\n",
       "         0.86282813, -0.39168444,  1.26028191,  0.30609245, -1.96973157]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generator Input # \n",
    "# - Üblich: Rauschen. Kann aber alles sein... \n",
    "#   => Aus dem Rauschen soll ein Bild entstehen. \n",
    "np.random.normal(0, 1, (2, 100))  # (loc, scale, size(x-Samples, shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b96b8b9e-df98-4b24-bc34-ab6deab850a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d44813c-48fb-4642-9e93-d09fe42e03f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsschleife # \n",
    "\n",
    "def train(generator, discriminator, gan, train_img, epochs, batch_size):\n",
    "    \n",
    "    half_batch = int(batch_size / 2)  # Ausgleich an Samples für beide Netze. \n",
    "    \n",
    "    for epoch in range(epochs):  # Für jede Epoche mach das:\n",
    "        # Discriminator # \n",
    "        index = np.random.randint(0, train_img.shape[0], half_batch)  # Index für Samples. \n",
    "        real_images = train_img[index]  # Hole Samples.\n",
    "        noise       = np.random.normal(0, 1, (half_batch, 100))  # Erstelle Rauschen als Input. Kann aber auch komplett 0 sein. Üblich: Rauschen.\n",
    "        fake_images = generator.predict(noise)  # Erstelle Prediction. \n",
    "\n",
    "        # Berechne Loss. # Setze Labels.\n",
    "        # - train_on_batch(x, y), beide müssen n-Samples haben. \n",
    "        loss_real = discriminator.train_on_batch(real_images, np.ones(  (half_batch, 1) ))  # Label 1 für n-Samples für echte Bilder. \n",
    "        loss_fake = discriminator.train_on_batch(fake_images, np.zeros( (half_batch, 1) ))  # Label 0 für n-Samples für UN-echte Bilder.\n",
    "        d_loss = 0.5 * np.add(loss_real, loss_fake)  # Schnitt der Beiden Losses. \n",
    "\n",
    "        # Generator # Wie Oben. \n",
    "        noise    = np.random.normal(0, 1, (batch_size, 100))\n",
    "        y        = np.ones(batch_size)\n",
    "        gan_loss = gan.train_on_batch(noise, y)\n",
    "\n",
    "        # Manuelle Ausgabe.:\n",
    "        print(f\"Epoche: {epoch + 1}/{epochs} GAN loss: {gan_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fcd9e492-63b5-4219-8f76-004d9353c9cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step\n",
      "Epoche: 1/700 GAN loss: 0.6492092609405518\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 2/700 GAN loss: 0.8451676964759827\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 3/700 GAN loss: 1.2375006675720215\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 4/700 GAN loss: 1.8000348806381226\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 5/700 GAN loss: 2.563979148864746\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 6/700 GAN loss: 3.6261982917785645\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 7/700 GAN loss: 4.799901962280273\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 8/700 GAN loss: 5.576104164123535\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 9/700 GAN loss: 6.7033257484436035\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 10/700 GAN loss: 7.305302619934082\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 11/700 GAN loss: 8.043327331542969\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 12/700 GAN loss: 8.621284484863281\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 13/700 GAN loss: 8.937784194946289\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 14/700 GAN loss: 9.068886756896973\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 15/700 GAN loss: 9.253068923950195\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 16/700 GAN loss: 9.79439926147461\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 17/700 GAN loss: 10.041692733764648\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 18/700 GAN loss: 10.848760604858398\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 19/700 GAN loss: 11.514145851135254\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 20/700 GAN loss: 12.022664070129395\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 21/700 GAN loss: 13.35643196105957\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 22/700 GAN loss: 13.95964241027832\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 23/700 GAN loss: 13.75594425201416\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 24/700 GAN loss: 14.76464557647705\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 25/700 GAN loss: 14.680356979370117\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 26/700 GAN loss: 15.575873374938965\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 27/700 GAN loss: 15.648588180541992\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 28/700 GAN loss: 14.615825653076172\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 29/700 GAN loss: 15.826805114746094\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 30/700 GAN loss: 15.627568244934082\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 31/700 GAN loss: 15.30601692199707\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 32/700 GAN loss: 15.64183235168457\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 33/700 GAN loss: 15.735424041748047\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 34/700 GAN loss: 16.076309204101562\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 35/700 GAN loss: 15.77910041809082\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 36/700 GAN loss: 16.47552490234375\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 37/700 GAN loss: 16.58233642578125\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 38/700 GAN loss: 15.768316268920898\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 39/700 GAN loss: 16.205337524414062\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 40/700 GAN loss: 15.416949272155762\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 41/700 GAN loss: 15.900243759155273\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 42/700 GAN loss: 15.373575210571289\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 43/700 GAN loss: 16.50851058959961\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 44/700 GAN loss: 14.091719627380371\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 45/700 GAN loss: 13.072545051574707\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 46/700 GAN loss: 13.879311561584473\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 47/700 GAN loss: 13.766794204711914\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 48/700 GAN loss: 18.77649688720703\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 49/700 GAN loss: 14.821036338806152\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 50/700 GAN loss: 12.162260055541992\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 51/700 GAN loss: 12.809698104858398\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 52/700 GAN loss: 15.440591812133789\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 53/700 GAN loss: 17.521007537841797\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 54/700 GAN loss: 20.537384033203125\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 55/700 GAN loss: 22.014297485351562\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 56/700 GAN loss: 20.572715759277344\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 57/700 GAN loss: 12.440930366516113\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 58/700 GAN loss: 12.149066925048828\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 59/700 GAN loss: 22.722959518432617\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 60/700 GAN loss: 38.78468704223633\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 61/700 GAN loss: 20.00377655029297\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 62/700 GAN loss: 10.154197692871094\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 63/700 GAN loss: 10.239448547363281\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 64/700 GAN loss: 14.26668643951416\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 65/700 GAN loss: 22.91338539123535\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 66/700 GAN loss: 31.241609573364258\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 67/700 GAN loss: 34.54671859741211\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 68/700 GAN loss: 11.91874885559082\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 69/700 GAN loss: 9.245776176452637\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 70/700 GAN loss: 9.010881423950195\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 71/700 GAN loss: 8.935661315917969\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 72/700 GAN loss: 8.947633743286133\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 73/700 GAN loss: 7.509668827056885\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 74/700 GAN loss: 13.5586576461792\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 75/700 GAN loss: 24.979782104492188\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 76/700 GAN loss: 34.32640838623047\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 77/700 GAN loss: 21.935802459716797\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 78/700 GAN loss: 11.534440994262695\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 79/700 GAN loss: 8.403899192810059\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 80/700 GAN loss: 9.017014503479004\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 81/700 GAN loss: 8.067361831665039\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 82/700 GAN loss: 7.509592533111572\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 83/700 GAN loss: 8.494897842407227\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 84/700 GAN loss: 15.362476348876953\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 85/700 GAN loss: 20.89306640625\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 86/700 GAN loss: 22.803407669067383\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 87/700 GAN loss: 21.16642189025879\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 88/700 GAN loss: 12.027246475219727\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 89/700 GAN loss: 8.937902450561523\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 90/700 GAN loss: 8.553472518920898\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 91/700 GAN loss: 7.7445454597473145\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 92/700 GAN loss: 6.665497779846191\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 93/700 GAN loss: 8.427748680114746\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 94/700 GAN loss: 9.606555938720703\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 95/700 GAN loss: 13.287270545959473\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 96/700 GAN loss: 16.002294540405273\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 97/700 GAN loss: 12.534284591674805\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 98/700 GAN loss: 9.823328018188477\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 99/700 GAN loss: 6.2951836585998535\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 100/700 GAN loss: 5.2550249099731445\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 101/700 GAN loss: 5.485189437866211\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 102/700 GAN loss: 7.2638773918151855\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 103/700 GAN loss: 7.250497817993164\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 104/700 GAN loss: 8.945964813232422\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 105/700 GAN loss: 6.916513442993164\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 106/700 GAN loss: 5.501750946044922\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 107/700 GAN loss: 5.147622585296631\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 108/700 GAN loss: 4.636762619018555\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 109/700 GAN loss: 5.855008602142334\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 110/700 GAN loss: 5.495053768157959\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 111/700 GAN loss: 4.948556423187256\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 112/700 GAN loss: 5.495551109313965\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 113/700 GAN loss: 5.873210430145264\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 114/700 GAN loss: 6.865363121032715\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 115/700 GAN loss: 6.002630710601807\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 116/700 GAN loss: 4.842264175415039\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 117/700 GAN loss: 7.061517715454102\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 118/700 GAN loss: 9.480940818786621\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 119/700 GAN loss: 10.558239936828613\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 120/700 GAN loss: 10.261271476745605\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 121/700 GAN loss: 9.30516242980957\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 122/700 GAN loss: 8.512491226196289\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 123/700 GAN loss: 8.612885475158691\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 124/700 GAN loss: 8.73837661743164\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 125/700 GAN loss: 8.875825881958008\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 126/700 GAN loss: 9.67083740234375\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 127/700 GAN loss: 7.758847713470459\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 128/700 GAN loss: 7.359254837036133\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 129/700 GAN loss: 8.299901962280273\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 130/700 GAN loss: 9.528335571289062\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 131/700 GAN loss: 6.9752421379089355\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 132/700 GAN loss: 6.526793003082275\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 133/700 GAN loss: 7.2349162101745605\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 134/700 GAN loss: 9.631731033325195\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 135/700 GAN loss: 10.560343742370605\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 136/700 GAN loss: 9.828039169311523\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 137/700 GAN loss: 9.300069808959961\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 138/700 GAN loss: 7.845738410949707\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 139/700 GAN loss: 8.4861421585083\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 140/700 GAN loss: 8.545072555541992\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 141/700 GAN loss: 8.289287567138672\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 142/700 GAN loss: 7.307101726531982\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 143/700 GAN loss: 7.252072334289551\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 144/700 GAN loss: 7.444118499755859\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 145/700 GAN loss: 6.748844623565674\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 146/700 GAN loss: 6.738036632537842\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 147/700 GAN loss: 8.408548355102539\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 148/700 GAN loss: 6.71817684173584\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 149/700 GAN loss: 6.474740505218506\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 150/700 GAN loss: 6.756098747253418\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 151/700 GAN loss: 8.394808769226074\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 152/700 GAN loss: 9.161087036132812\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 153/700 GAN loss: 7.918556213378906\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 154/700 GAN loss: 7.6121954917907715\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 155/700 GAN loss: 9.45488166809082\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 156/700 GAN loss: 10.660839080810547\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 157/700 GAN loss: 9.064902305603027\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 158/700 GAN loss: 6.338179588317871\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 159/700 GAN loss: 6.124056339263916\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 160/700 GAN loss: 7.901553153991699\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 161/700 GAN loss: 9.591704368591309\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 162/700 GAN loss: 10.44946002960205\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 163/700 GAN loss: 11.638507843017578\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 164/700 GAN loss: 10.647310256958008\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 165/700 GAN loss: 9.549999237060547\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 166/700 GAN loss: 8.37893295288086\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 167/700 GAN loss: 7.621077060699463\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 168/700 GAN loss: 7.630180358886719\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 169/700 GAN loss: 8.031879425048828\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 170/700 GAN loss: 8.296401023864746\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 171/700 GAN loss: 8.900065422058105\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 172/700 GAN loss: 7.891191005706787\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 173/700 GAN loss: 7.272008895874023\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 174/700 GAN loss: 7.997169017791748\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 175/700 GAN loss: 8.130179405212402\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 176/700 GAN loss: 8.395760536193848\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 177/700 GAN loss: 8.721414566040039\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 178/700 GAN loss: 7.611650466918945\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 179/700 GAN loss: 7.799665927886963\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 180/700 GAN loss: 8.101044654846191\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 181/700 GAN loss: 7.844515800476074\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 182/700 GAN loss: 8.259729385375977\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 183/700 GAN loss: 8.983678817749023\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 184/700 GAN loss: 8.28364372253418\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 185/700 GAN loss: 8.59225845336914\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 186/700 GAN loss: 8.6433687210083\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 187/700 GAN loss: 8.683549880981445\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 188/700 GAN loss: 9.000481605529785\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 189/700 GAN loss: 8.84807014465332\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 190/700 GAN loss: 8.08000373840332\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 191/700 GAN loss: 7.586705684661865\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 192/700 GAN loss: 7.552797794342041\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 193/700 GAN loss: 7.642340660095215\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 194/700 GAN loss: 7.475473880767822\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 195/700 GAN loss: 6.181943416595459\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 196/700 GAN loss: 7.007135391235352\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 197/700 GAN loss: 7.380162239074707\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 198/700 GAN loss: 5.748953342437744\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 199/700 GAN loss: 6.280462265014648\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 200/700 GAN loss: 8.040153503417969\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 201/700 GAN loss: 9.871663093566895\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 202/700 GAN loss: 6.018009185791016\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 203/700 GAN loss: 5.923311233520508\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 204/700 GAN loss: 9.791801452636719\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 205/700 GAN loss: 13.097060203552246\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 206/700 GAN loss: 4.647116661071777\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 207/700 GAN loss: 4.783534526824951\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 208/700 GAN loss: 10.665773391723633\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 209/700 GAN loss: 16.941375732421875\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 210/700 GAN loss: 4.205519199371338\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 211/700 GAN loss: 1.3157025575637817\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 212/700 GAN loss: 2.8202457427978516\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 213/700 GAN loss: 8.440343856811523\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 214/700 GAN loss: 15.299489974975586\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 215/700 GAN loss: 19.466449737548828\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 216/700 GAN loss: 9.308099746704102\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 217/700 GAN loss: 5.612661361694336\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 218/700 GAN loss: 3.2890231609344482\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 219/700 GAN loss: 5.908099174499512\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 220/700 GAN loss: 9.967365264892578\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 221/700 GAN loss: 16.520395278930664\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 222/700 GAN loss: 20.643203735351562\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 223/700 GAN loss: 9.147838592529297\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 224/700 GAN loss: 4.410152435302734\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 225/700 GAN loss: 3.569133758544922\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 226/700 GAN loss: 5.637442588806152\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 227/700 GAN loss: 11.768026351928711\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 228/700 GAN loss: 15.575157165527344\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 229/700 GAN loss: 11.164648056030273\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 230/700 GAN loss: 6.514937400817871\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 231/700 GAN loss: 5.080802917480469\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 232/700 GAN loss: 6.047142028808594\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 233/700 GAN loss: 7.680939197540283\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 234/700 GAN loss: 9.103130340576172\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 235/700 GAN loss: 4.303152561187744\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 236/700 GAN loss: 2.3877429962158203\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 237/700 GAN loss: 3.798860549926758\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 238/700 GAN loss: 6.046351432800293\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 239/700 GAN loss: 3.137600898742676\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 240/700 GAN loss: 1.8941493034362793\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 241/700 GAN loss: 3.876100778579712\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 242/700 GAN loss: 7.037269592285156\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 243/700 GAN loss: 3.245690107345581\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 244/700 GAN loss: 2.596947193145752\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 245/700 GAN loss: 4.461944580078125\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 246/700 GAN loss: 6.9020867347717285\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 247/700 GAN loss: 4.42619514465332\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 248/700 GAN loss: 3.2998528480529785\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 249/700 GAN loss: 3.855795383453369\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 250/700 GAN loss: 5.957385063171387\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 251/700 GAN loss: 6.4934492111206055\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 252/700 GAN loss: 3.3179872035980225\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 253/700 GAN loss: 4.000995635986328\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 254/700 GAN loss: 7.937538146972656\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 255/700 GAN loss: 1.012528419494629\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 256/700 GAN loss: 1.0984790325164795\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 257/700 GAN loss: 5.498012542724609\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 258/700 GAN loss: 16.647920608520508\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 259/700 GAN loss: 2.2505247592926025\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 260/700 GAN loss: 0.5158238410949707\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 261/700 GAN loss: 0.5169458389282227\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 262/700 GAN loss: 0.942380428314209\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 263/700 GAN loss: 3.40525484085083\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 264/700 GAN loss: 7.666228771209717\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 265/700 GAN loss: 11.498983383178711\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 266/700 GAN loss: 8.647223472595215\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 267/700 GAN loss: 5.6339802742004395\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 268/700 GAN loss: 3.548814296722412\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 269/700 GAN loss: 2.7005698680877686\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 270/700 GAN loss: 2.600679397583008\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 271/700 GAN loss: 2.694338798522949\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 272/700 GAN loss: 3.9073848724365234\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 273/700 GAN loss: 4.768154621124268\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 274/700 GAN loss: 5.544126033782959\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 275/700 GAN loss: 5.578796863555908\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 276/700 GAN loss: 5.444835662841797\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 277/700 GAN loss: 4.535082817077637\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 278/700 GAN loss: 3.529291868209839\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 279/700 GAN loss: 3.1238577365875244\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 280/700 GAN loss: 2.7857418060302734\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 281/700 GAN loss: 2.92937970161438\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 282/700 GAN loss: 3.599614143371582\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 283/700 GAN loss: 3.7131242752075195\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 284/700 GAN loss: 3.505166530609131\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 285/700 GAN loss: 2.6562564373016357\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 286/700 GAN loss: 2.6626358032226562\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 287/700 GAN loss: 2.8435609340667725\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 288/700 GAN loss: 2.808218002319336\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 289/700 GAN loss: 2.855928897857666\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 290/700 GAN loss: 2.7122979164123535\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 291/700 GAN loss: 2.938789129257202\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 292/700 GAN loss: 3.128622055053711\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 293/700 GAN loss: 3.1382057666778564\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 294/700 GAN loss: 3.2432608604431152\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 295/700 GAN loss: 3.4210362434387207\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 296/700 GAN loss: 3.5541563034057617\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 297/700 GAN loss: 3.693905830383301\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 298/700 GAN loss: 3.640486240386963\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 299/700 GAN loss: 3.4077229499816895\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 300/700 GAN loss: 3.3636422157287598\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 301/700 GAN loss: 3.585287094116211\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 302/700 GAN loss: 3.4216737747192383\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 303/700 GAN loss: 3.13259220123291\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 304/700 GAN loss: 3.6870594024658203\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 305/700 GAN loss: 4.013599395751953\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 306/700 GAN loss: 2.97856068611145\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 307/700 GAN loss: 3.8132002353668213\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 308/700 GAN loss: 4.4562177658081055\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 309/700 GAN loss: 1.7870850563049316\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 310/700 GAN loss: 2.3705801963806152\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 311/700 GAN loss: 4.8387298583984375\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 312/700 GAN loss: 1.830387830734253\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 313/700 GAN loss: 2.3700733184814453\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 314/700 GAN loss: 5.427366733551025\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 315/700 GAN loss: 5.75705099105835\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 316/700 GAN loss: 3.260708808898926\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 317/700 GAN loss: 2.3982536792755127\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 318/700 GAN loss: 2.778862953186035\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 319/700 GAN loss: 4.321759223937988\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 320/700 GAN loss: 3.785924196243286\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 321/700 GAN loss: 2.9633612632751465\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 322/700 GAN loss: 2.421492576599121\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 323/700 GAN loss: 3.4970765113830566\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 324/700 GAN loss: 2.216743230819702\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 325/700 GAN loss: 2.570894956588745\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 326/700 GAN loss: 3.6781649589538574\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 327/700 GAN loss: 0.829164981842041\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 328/700 GAN loss: 1.9861489534378052\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 329/700 GAN loss: 5.370047569274902\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 330/700 GAN loss: 0.30917495489120483\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 331/700 GAN loss: 0.20381951332092285\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 332/700 GAN loss: 1.4051330089569092\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 333/700 GAN loss: 7.7679219245910645\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 334/700 GAN loss: 0.9839638471603394\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 335/700 GAN loss: 0.31174907088279724\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 336/700 GAN loss: 0.4744657278060913\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 337/700 GAN loss: 1.1976784467697144\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 338/700 GAN loss: 3.909971237182617\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 339/700 GAN loss: 4.645570278167725\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 340/700 GAN loss: 2.5552444458007812\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 341/700 GAN loss: 1.2406601905822754\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 342/700 GAN loss: 1.2723259925842285\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 343/700 GAN loss: 1.2789278030395508\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 344/700 GAN loss: 2.0369720458984375\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 345/700 GAN loss: 2.623806953430176\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 346/700 GAN loss: 4.1243414878845215\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 347/700 GAN loss: 3.9982802867889404\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 348/700 GAN loss: 3.2499547004699707\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 349/700 GAN loss: 2.5435619354248047\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 350/700 GAN loss: 2.5788211822509766\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 351/700 GAN loss: 2.585894823074341\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 352/700 GAN loss: 2.6494061946868896\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 353/700 GAN loss: 3.0868096351623535\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 354/700 GAN loss: 2.8469796180725098\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 355/700 GAN loss: 2.328643321990967\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 356/700 GAN loss: 2.657813549041748\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 357/700 GAN loss: 2.6033377647399902\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 358/700 GAN loss: 2.405564069747925\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 359/700 GAN loss: 2.2416086196899414\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 360/700 GAN loss: 2.4554567337036133\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 361/700 GAN loss: 2.5510988235473633\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 362/700 GAN loss: 2.4780712127685547\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 363/700 GAN loss: 2.229992628097534\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 364/700 GAN loss: 2.028550148010254\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 365/700 GAN loss: 2.670224189758301\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 366/700 GAN loss: 2.4858410358428955\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 367/700 GAN loss: 2.0598511695861816\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 368/700 GAN loss: 2.395902156829834\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 369/700 GAN loss: 2.5384788513183594\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 370/700 GAN loss: 2.6273179054260254\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 371/700 GAN loss: 2.419978380203247\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 372/700 GAN loss: 2.4576573371887207\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 373/700 GAN loss: 2.7423951625823975\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 374/700 GAN loss: 2.3210582733154297\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 375/700 GAN loss: 3.0169036388397217\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 376/700 GAN loss: 2.733604669570923\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 377/700 GAN loss: 2.015460252761841\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 378/700 GAN loss: 2.9252877235412598\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 379/700 GAN loss: 2.5199155807495117\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 380/700 GAN loss: 2.47287654876709\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 381/700 GAN loss: 3.0345234870910645\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 382/700 GAN loss: 2.6419591903686523\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 383/700 GAN loss: 3.227160930633545\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 384/700 GAN loss: 3.0725274085998535\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 385/700 GAN loss: 3.441464900970459\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 386/700 GAN loss: 3.297947883605957\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 387/700 GAN loss: 3.2722182273864746\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 388/700 GAN loss: 2.693117141723633\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 389/700 GAN loss: 3.187098503112793\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 390/700 GAN loss: 3.5613584518432617\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 391/700 GAN loss: 2.705921173095703\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 392/700 GAN loss: 2.796121597290039\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 393/700 GAN loss: 2.7821755409240723\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 394/700 GAN loss: 2.6145119667053223\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 395/700 GAN loss: 3.321746587753296\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 396/700 GAN loss: 1.6078526973724365\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 397/700 GAN loss: 3.5543410778045654\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 398/700 GAN loss: 0.7036920785903931\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 399/700 GAN loss: 0.827008843421936\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 400/700 GAN loss: 3.1759214401245117\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 401/700 GAN loss: 2.6159586906433105\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 402/700 GAN loss: 1.2388300895690918\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 403/700 GAN loss: 1.274592399597168\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 404/700 GAN loss: 2.064945936203003\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 405/700 GAN loss: 2.3115830421447754\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 406/700 GAN loss: 1.428375005722046\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 407/700 GAN loss: 1.0313234329223633\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 408/700 GAN loss: 1.3285939693450928\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 409/700 GAN loss: 1.9101892709732056\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 410/700 GAN loss: 2.06250262260437\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 411/700 GAN loss: 1.5646681785583496\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 412/700 GAN loss: 1.3599835634231567\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 413/700 GAN loss: 1.9957711696624756\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 414/700 GAN loss: 1.9090726375579834\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 415/700 GAN loss: 1.9626483917236328\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 416/700 GAN loss: 1.8454673290252686\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 417/700 GAN loss: 1.8479708433151245\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 418/700 GAN loss: 2.1345245838165283\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 419/700 GAN loss: 2.1081204414367676\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 420/700 GAN loss: 2.2178525924682617\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 421/700 GAN loss: 1.8634815216064453\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 422/700 GAN loss: 1.9011099338531494\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 423/700 GAN loss: 2.4818599224090576\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 424/700 GAN loss: 2.068234920501709\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 425/700 GAN loss: 1.8001952171325684\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 426/700 GAN loss: 2.485976219177246\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 427/700 GAN loss: 2.4879274368286133\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 428/700 GAN loss: 1.8945584297180176\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 429/700 GAN loss: 2.3919808864593506\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 430/700 GAN loss: 2.547496795654297\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 431/700 GAN loss: 1.7313357591629028\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 432/700 GAN loss: 2.4580283164978027\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 433/700 GAN loss: 3.048011541366577\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 434/700 GAN loss: 1.4109677076339722\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 435/700 GAN loss: 1.5147747993469238\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 436/700 GAN loss: 3.445828914642334\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 437/700 GAN loss: 2.2191274166107178\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 438/700 GAN loss: 1.4960211515426636\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 439/700 GAN loss: 2.2282917499542236\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 440/700 GAN loss: 2.79849910736084\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 441/700 GAN loss: 1.99465012550354\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 442/700 GAN loss: 2.0079360008239746\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 443/700 GAN loss: 2.739957809448242\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 444/700 GAN loss: 2.654834032058716\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 445/700 GAN loss: 1.6145410537719727\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 446/700 GAN loss: 1.8367167711257935\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 447/700 GAN loss: 3.175459384918213\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 448/700 GAN loss: 1.59404718875885\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 449/700 GAN loss: 1.4336049556732178\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 450/700 GAN loss: 2.287053108215332\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 451/700 GAN loss: 2.251777172088623\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 452/700 GAN loss: 1.5513416528701782\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 453/700 GAN loss: 1.594162940979004\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 454/700 GAN loss: 2.057703733444214\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 455/700 GAN loss: 2.648531198501587\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 456/700 GAN loss: 1.8994389772415161\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 457/700 GAN loss: 1.9696062803268433\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 458/700 GAN loss: 2.260314702987671\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 459/700 GAN loss: 2.260687828063965\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 460/700 GAN loss: 1.9928486347198486\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 461/700 GAN loss: 1.6475512981414795\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 462/700 GAN loss: 2.5964512825012207\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 463/700 GAN loss: 2.2063779830932617\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 464/700 GAN loss: 1.9488941431045532\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 465/700 GAN loss: 2.2379212379455566\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 466/700 GAN loss: 1.9193987846374512\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 467/700 GAN loss: 2.0171310901641846\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 468/700 GAN loss: 1.8119810819625854\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 469/700 GAN loss: 2.647859811782837\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 470/700 GAN loss: 2.6167964935302734\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 471/700 GAN loss: 2.304863929748535\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 472/700 GAN loss: 2.0306038856506348\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 473/700 GAN loss: 2.0079689025878906\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 474/700 GAN loss: 2.5695958137512207\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 475/700 GAN loss: 2.1995553970336914\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 476/700 GAN loss: 1.901820182800293\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 477/700 GAN loss: 2.279491424560547\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 478/700 GAN loss: 2.545827865600586\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 479/700 GAN loss: 2.2173144817352295\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 480/700 GAN loss: 2.5005297660827637\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 481/700 GAN loss: 2.651101589202881\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 482/700 GAN loss: 1.8690904378890991\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 483/700 GAN loss: 2.529024600982666\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 484/700 GAN loss: 2.5809388160705566\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 485/700 GAN loss: 2.0945627689361572\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 486/700 GAN loss: 3.293830156326294\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 487/700 GAN loss: 1.757025957107544\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 488/700 GAN loss: 1.5111795663833618\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 489/700 GAN loss: 2.977370500564575\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 490/700 GAN loss: 1.4955086708068848\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 491/700 GAN loss: 1.7103979587554932\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 492/700 GAN loss: 2.209726572036743\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 493/700 GAN loss: 2.936406135559082\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 494/700 GAN loss: 1.8275883197784424\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 495/700 GAN loss: 1.6836261749267578\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 496/700 GAN loss: 1.9133416414260864\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 497/700 GAN loss: 2.133193254470825\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 498/700 GAN loss: 2.5310070514678955\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 499/700 GAN loss: 1.7791054248809814\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 500/700 GAN loss: 2.16544246673584\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 501/700 GAN loss: 2.016793727874756\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 502/700 GAN loss: 1.4718337059020996\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 503/700 GAN loss: 2.3509790897369385\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 504/700 GAN loss: 2.2650609016418457\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 505/700 GAN loss: 1.8227267265319824\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 506/700 GAN loss: 1.9609538316726685\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 507/700 GAN loss: 1.8988783359527588\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 508/700 GAN loss: 1.8090099096298218\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 509/700 GAN loss: 1.877853274345398\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 510/700 GAN loss: 2.6139256954193115\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 511/700 GAN loss: 2.2597062587738037\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 512/700 GAN loss: 1.8933541774749756\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 513/700 GAN loss: 2.3637359142303467\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 514/700 GAN loss: 2.378288745880127\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 515/700 GAN loss: 1.7303141355514526\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 516/700 GAN loss: 2.511556625366211\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 517/700 GAN loss: 2.1907055377960205\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 518/700 GAN loss: 2.0219197273254395\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 519/700 GAN loss: 2.298366069793701\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 520/700 GAN loss: 1.723156213760376\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 521/700 GAN loss: 1.5887632369995117\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 522/700 GAN loss: 1.6962931156158447\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 523/700 GAN loss: 1.5956568717956543\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 524/700 GAN loss: 1.3503912687301636\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 525/700 GAN loss: 1.7483073472976685\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 526/700 GAN loss: 1.6986961364746094\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 527/700 GAN loss: 1.6005542278289795\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 528/700 GAN loss: 1.6845512390136719\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 529/700 GAN loss: 1.7963590621948242\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 530/700 GAN loss: 1.327404260635376\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 531/700 GAN loss: 1.7727413177490234\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 532/700 GAN loss: 1.6578664779663086\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 533/700 GAN loss: 1.958606243133545\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 534/700 GAN loss: 1.5498465299606323\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 535/700 GAN loss: 1.8780951499938965\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 536/700 GAN loss: 1.9006142616271973\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 537/700 GAN loss: 1.5507820844650269\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 538/700 GAN loss: 1.4360146522521973\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 539/700 GAN loss: 1.5946710109710693\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 540/700 GAN loss: 1.985560417175293\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 541/700 GAN loss: 1.072131872177124\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 542/700 GAN loss: 1.295461654663086\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 543/700 GAN loss: 1.811333179473877\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 544/700 GAN loss: 1.5597094297409058\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 545/700 GAN loss: 1.1426331996917725\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 546/700 GAN loss: 1.3045809268951416\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 547/700 GAN loss: 1.3753058910369873\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 548/700 GAN loss: 1.300345778465271\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 549/700 GAN loss: 1.4199762344360352\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 550/700 GAN loss: 1.3224209547042847\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 551/700 GAN loss: 1.3204752206802368\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 552/700 GAN loss: 1.5738346576690674\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 553/700 GAN loss: 1.6249204874038696\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 554/700 GAN loss: 1.3082877397537231\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 555/700 GAN loss: 1.437985897064209\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 556/700 GAN loss: 1.5192474126815796\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 557/700 GAN loss: 1.680682897567749\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 558/700 GAN loss: 1.4159736633300781\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 559/700 GAN loss: 1.6348762512207031\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 560/700 GAN loss: 1.2158335447311401\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 561/700 GAN loss: 1.8405680656433105\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 562/700 GAN loss: 1.7096478939056396\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 563/700 GAN loss: 2.041403293609619\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 564/700 GAN loss: 1.6419203281402588\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 565/700 GAN loss: 1.8629456758499146\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 566/700 GAN loss: 1.4705225229263306\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 567/700 GAN loss: 1.3141601085662842\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 568/700 GAN loss: 1.405691385269165\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 569/700 GAN loss: 1.5511585474014282\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 570/700 GAN loss: 1.845562219619751\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 571/700 GAN loss: 1.5816179513931274\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 572/700 GAN loss: 1.0496702194213867\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 573/700 GAN loss: 1.3585424423217773\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 574/700 GAN loss: 1.3886895179748535\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 575/700 GAN loss: 1.3187204599380493\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 576/700 GAN loss: 1.2523808479309082\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 577/700 GAN loss: 1.5325605869293213\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 578/700 GAN loss: 2.179466962814331\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 579/700 GAN loss: 1.2194222211837769\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 580/700 GAN loss: 1.4176084995269775\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 581/700 GAN loss: 1.5861507654190063\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 582/700 GAN loss: 1.0796167850494385\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 583/700 GAN loss: 1.1988855600357056\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 584/700 GAN loss: 1.2790496349334717\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 585/700 GAN loss: 1.5923619270324707\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 586/700 GAN loss: 1.1294524669647217\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 587/700 GAN loss: 1.239570140838623\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 588/700 GAN loss: 1.3731164932250977\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 589/700 GAN loss: 1.4058048725128174\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 590/700 GAN loss: 1.1620209217071533\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 591/700 GAN loss: 1.0776420831680298\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 592/700 GAN loss: 1.4176816940307617\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 593/700 GAN loss: 1.4749677181243896\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 594/700 GAN loss: 1.4828795194625854\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 595/700 GAN loss: 1.1975488662719727\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 596/700 GAN loss: 1.2786446809768677\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 597/700 GAN loss: 1.2426408529281616\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 598/700 GAN loss: 1.5359337329864502\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 599/700 GAN loss: 1.8118093013763428\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 600/700 GAN loss: 1.9061344861984253\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 601/700 GAN loss: 1.5480282306671143\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 602/700 GAN loss: 1.858492374420166\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 603/700 GAN loss: 1.5631160736083984\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 604/700 GAN loss: 1.3928916454315186\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 605/700 GAN loss: 1.485525369644165\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 606/700 GAN loss: 1.6184053421020508\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 607/700 GAN loss: 1.4828790426254272\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 608/700 GAN loss: 1.4683626890182495\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 609/700 GAN loss: 1.705397605895996\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 610/700 GAN loss: 1.2238402366638184\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 611/700 GAN loss: 1.3649358749389648\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 612/700 GAN loss: 1.6992578506469727\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 613/700 GAN loss: 1.3992379903793335\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 614/700 GAN loss: 1.5599541664123535\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 615/700 GAN loss: 1.3803683519363403\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 616/700 GAN loss: 1.164290189743042\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 617/700 GAN loss: 1.2699573040008545\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 618/700 GAN loss: 1.2440675497055054\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 619/700 GAN loss: 1.1845905780792236\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 620/700 GAN loss: 1.7179769277572632\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 621/700 GAN loss: 0.7304981350898743\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 622/700 GAN loss: 0.6669669151306152\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 623/700 GAN loss: 1.203265905380249\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 624/700 GAN loss: 1.6778080463409424\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 625/700 GAN loss: 1.1834834814071655\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 626/700 GAN loss: 0.7389645576477051\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 627/700 GAN loss: 0.5912050008773804\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 628/700 GAN loss: 0.7163904309272766\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 629/700 GAN loss: 0.967561662197113\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 630/700 GAN loss: 1.0585039854049683\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 631/700 GAN loss: 1.0727777481079102\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 632/700 GAN loss: 0.886925458908081\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 633/700 GAN loss: 0.6767643690109253\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 634/700 GAN loss: 0.7588462829589844\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 635/700 GAN loss: 0.7587080001831055\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 636/700 GAN loss: 0.8717121481895447\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 637/700 GAN loss: 0.8840853571891785\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 638/700 GAN loss: 0.834786593914032\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 639/700 GAN loss: 0.7676926851272583\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 640/700 GAN loss: 0.857109546661377\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 641/700 GAN loss: 1.0618418455123901\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 642/700 GAN loss: 1.0396724939346313\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 643/700 GAN loss: 1.2363126277923584\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 644/700 GAN loss: 1.0202887058258057\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 645/700 GAN loss: 1.1674787998199463\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 646/700 GAN loss: 1.127026915550232\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 647/700 GAN loss: 1.092427134513855\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 648/700 GAN loss: 1.1539068222045898\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 649/700 GAN loss: 1.2154932022094727\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 650/700 GAN loss: 0.975041925907135\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 651/700 GAN loss: 0.7959577441215515\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 652/700 GAN loss: 0.9644643664360046\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 653/700 GAN loss: 1.0049846172332764\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 654/700 GAN loss: 1.0818098783493042\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 655/700 GAN loss: 1.097677230834961\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 656/700 GAN loss: 1.0813965797424316\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 657/700 GAN loss: 1.181955337524414\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 658/700 GAN loss: 1.1303880214691162\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 659/700 GAN loss: 1.0243030786514282\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 660/700 GAN loss: 1.0752370357513428\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 661/700 GAN loss: 1.1579267978668213\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 662/700 GAN loss: 0.9683494567871094\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 663/700 GAN loss: 0.9605602025985718\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 664/700 GAN loss: 0.8864739537239075\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 665/700 GAN loss: 1.2324426174163818\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 666/700 GAN loss: 0.9087200164794922\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 667/700 GAN loss: 1.0499379634857178\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 668/700 GAN loss: 0.934159517288208\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 669/700 GAN loss: 1.06307852268219\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 670/700 GAN loss: 1.3311710357666016\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 671/700 GAN loss: 1.21803879737854\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 672/700 GAN loss: 1.2064712047576904\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 673/700 GAN loss: 1.0341901779174805\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 674/700 GAN loss: 1.5511474609375\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 675/700 GAN loss: 1.4514954090118408\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 676/700 GAN loss: 1.3816442489624023\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 677/700 GAN loss: 1.1075739860534668\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 678/700 GAN loss: 1.249824047088623\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 679/700 GAN loss: 1.2886239290237427\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 680/700 GAN loss: 1.051889181137085\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 681/700 GAN loss: 1.1845669746398926\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 682/700 GAN loss: 1.1014162302017212\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 683/700 GAN loss: 1.0700170993804932\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 684/700 GAN loss: 0.914715588092804\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 685/700 GAN loss: 0.812665581703186\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 686/700 GAN loss: 0.988379955291748\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 687/700 GAN loss: 0.9690199494361877\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 688/700 GAN loss: 0.9130574464797974\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 689/700 GAN loss: 0.8290256261825562\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 690/700 GAN loss: 0.7350273132324219\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 691/700 GAN loss: 0.8361021280288696\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 692/700 GAN loss: 0.9813188910484314\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 693/700 GAN loss: 1.0231012105941772\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 694/700 GAN loss: 0.9554481506347656\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 695/700 GAN loss: 0.9191904067993164\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 696/700 GAN loss: 1.032442569732666\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 697/700 GAN loss: 1.1730743646621704\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 698/700 GAN loss: 1.044196605682373\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 699/700 GAN loss: 1.0404860973358154\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 700/700 GAN loss: 0.9849920272827148\n"
     ]
    }
   ],
   "source": [
    "train(generator, discriminator, GAN, dataset_numpy_scaled, epochs=700, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0059ec67-69b1-4b32-968b-57fedae897bd",
   "metadata": {},
   "source": [
    "<h2>Erzeuge Bilder</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7a6ef3-a782-4b8a-ab54-57e78d1a4206",
   "metadata": {},
   "source": [
    "So, das Training ist beendet, wie können wir aber jetzt Bilder erzeugen? <br>\n",
    "Dazu geben wir dem Generator ein Startbild als Vektor, daraus soll dann Schritt für Schritt das Bild erzeugt werden. Später muss der Vektor durch das Netz oder Manuell in  die richtige Form gebracht werden.\n",
    "- Die Skalierung des Bildes sollte vor dem Plotten umgekehrt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8629f730-0ab8-4acb-a709-fc2f2ef9f96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeuge Bild und gebe als array zurück.\n",
    "def generate_img(noise, generator) -> np.array:\n",
    "    image = generator.predict(noise)  # Gebe Startbild => Netz => Prediction \n",
    "    image = 0.5 * image + 0.5  # Kehre die Skalierung um. \n",
    "    image = image.reshape((20,20,1))\n",
    "    return image\n",
    "\n",
    "# Plote Bild. \n",
    "def plot_image(img:np.array, gray=False):\n",
    "    plt.figure(figsize=(3,3))\n",
    "    if gray:\n",
    "        plt.imshow(img,  cmap='gray')\n",
    "    else:\n",
    "         plt.imshow(img)\n",
    "    plt.xlabel('X-Pixel')\n",
    "    plt.ylabel(\"Y-Pixel\")\n",
    "    plt.title(\"Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9f3c6ad1-1c3d-49b4-8838-23503a54e99d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Startbild.\n",
    "start_img = np.random.normal(0, 1, (1, 100)).reshape((10,10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "72918f47-d98a-4450-a7dd-d263e98caf2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Oder als schwarz/weiß.\n",
    "plot_image(start_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ed044e6e-bf77-469b-8b93-d3d575d0cf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_img_2 = np.random.normal(0, 0, (1, 100)).reshape((10,10, 1))\n",
    "plot_image(start_img_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd0dc427-3b37-4dfe-bad8-ac6fe14f47a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_img = np.random.normal(0, 1, (1, 100))\n",
    "img = generate_img(start_img, generator)\n",
    "plot_image(img, gray=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4e5594-68e2-4689-9fd5-3957e8f3e7e2",
   "metadata": {},
   "source": [
    "Was passiert wenn immer der gleiche Input gegeben wird? \n",
    "- Die Prediction-Funktion (Netz und Parameter) liefert immer dasselbe Ergebnis => Koeffizienten sind statisch genau wie Bias, daher kommt immer das gleiche heraus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "01bed838-5fc9-4a0d-9c92-1c6669de3694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Nehme selben Input.\n",
    "img = generate_img(start_img, gen_ann)\n",
    "plot_image(img, gray=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "76f17fba-7fbd-4f2c-bf42-4e965fa62793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "y_true = generate_img(start_img, gen_ann).reshape((400,))\n",
    "\n",
    "y_pred = [generate_img(start_img, gen_ann).reshape((400,)) for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ee0e3dbd-98f4-400b-8e7b-f47018d28634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(y_pred)):\n",
    "    print(np.array_equal(y_true, y_pred[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2986ccc-d3e4-457e-bf05-717f551182f4",
   "metadata": {},
   "source": [
    "Durch den Einbau von Seeds Dropouts und weitere Elementen kann eine Dynamik miteingebracht werden, damit jedes nachfolgende Bild sich von den vorherigen unterscheidet. \n",
    "- `np.random.normal` erzeugt immer einen anderen Input für das Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07c6d02-1db9-4078-9b31-f14f34f7fe15",
   "metadata": {},
   "source": [
    "<h2>Speichere Bilder während des Trainings</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1deb544-fee2-47d2-984f-fdbef3386e55",
   "metadata": {},
   "source": [
    "Während des Trainings können die Bilder nach n-Epochen gespeichert werden, um die Entwicklung sichtbar zu machen. <br>\n",
    "Auch Möglich: <br>\n",
    "- Vergleiche Vektoren: wie ähnlich sind diese am Ende?\n",
    "- Extrahiere Vektor jedes Layers des Models: Entwicklungsschritte Layer für Layer (möglich, wenn daraus ein Bild konstruiert werden kann)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "97ebae3a-2626-400f-b3f4-221d6a9e8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img(img, epoch):\n",
    "    img = 0.5 * img + 0.5\n",
    "    matimg.imsave(f'./data/data/1__GAN/img{epoch}.jpeg', img.reshape((20,20)))\n",
    "\n",
    "def train(generator, discriminator, gan, train_img, epochs, batch_size): \n",
    "    half_batch = int(batch_size / 2)  \n",
    "    for epoch in range(epochs):  \n",
    "        index = np.random.randint(0, train_img.shape[0], half_batch)  \n",
    "        real_images = train_img[index]  # Hole Samples.\n",
    "        noise       = np.random.normal(0, 1, (half_batch, 100)) \n",
    "        fake_images = generator.predict(noise)  # Erstelle Prediction. \n",
    "        # Berechne Loss. # Setze Labels.\n",
    "        loss_real = discriminator.train_on_batch(real_images, np.ones(  (half_batch, 1) ))  # Label 1 für n-Samples für echte Bilder. \n",
    "        loss_fake = discriminator.train_on_batch(fake_images, np.zeros( (half_batch, 1) ))  # Label 0 für n-Samples für UN-echte Bilder.\n",
    "        d_loss = 0.5 * np.add(loss_real, loss_fake)  # Schnitt der Beiden Losses. \n",
    "        # Generator # Wie Oben. \n",
    "        noise    = np.random.normal(0, 1, (batch_size, 100))\n",
    "        y        = np.ones(batch_size)\n",
    "        gan_loss = gan.train_on_batch(noise, y)\n",
    "        # Manuelle Ausgabe.:\n",
    "        print(f\"Epoche: {epoch + 1}/{epochs} GAN loss: {gan_loss}\")\n",
    "\n",
    "        if (epoch%200==0) | (epoch+1==epochs):\n",
    "            save_img(fake_images[0], epoch)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "85f7dd13-40da-4dd7-9ba1-6ac0d11674a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = create_discriminator()\n",
    "discriminator.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss      = 'binary_crossentropy',\n",
    "    metrics   = 'accuracy'\n",
    ")\n",
    "discriminator.trainable = False\n",
    "# Erstelle GAN\n",
    "generator = create_generator()\n",
    "gan_input = tf.keras.layers.Input(shape=(100,))  # 100 Startpixel.\n",
    "gen_image = generator(gan_input)\n",
    "net_output = discriminator(gen_image)\n",
    "GAN        = tf.keras.Model(gan_input, net_output)\n",
    "GAN.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "26dd3d04-fe1b-4397-8675-8099d36e4f8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step\n",
      "Epoche: 1/1200 GAN loss: 0.6330462694168091\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 2/1200 GAN loss: 0.9008914232254028\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 3/1200 GAN loss: 1.4039802551269531\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 4/1200 GAN loss: 2.2934913635253906\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 5/1200 GAN loss: 3.459859848022461\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 6/1200 GAN loss: 4.912616729736328\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 7/1200 GAN loss: 6.107210636138916\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 8/1200 GAN loss: 7.121273994445801\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 9/1200 GAN loss: 7.913349151611328\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 10/1200 GAN loss: 8.714920043945312\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 11/1200 GAN loss: 9.117280960083008\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 12/1200 GAN loss: 9.668832778930664\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 13/1200 GAN loss: 10.02971363067627\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 14/1200 GAN loss: 10.357820510864258\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 15/1200 GAN loss: 10.7017240524292\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 16/1200 GAN loss: 10.972935676574707\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 17/1200 GAN loss: 11.289938926696777\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 18/1200 GAN loss: 11.756820678710938\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 19/1200 GAN loss: 11.885259628295898\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 20/1200 GAN loss: 11.925607681274414\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 21/1200 GAN loss: 12.51010513305664\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 22/1200 GAN loss: 13.258755683898926\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 23/1200 GAN loss: 13.345620155334473\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 24/1200 GAN loss: 13.638751983642578\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 25/1200 GAN loss: 13.82319450378418\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 26/1200 GAN loss: 14.031973838806152\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 27/1200 GAN loss: 14.860153198242188\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 28/1200 GAN loss: 13.729991912841797\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 29/1200 GAN loss: 13.653818130493164\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 30/1200 GAN loss: 14.211989402770996\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 31/1200 GAN loss: 14.001249313354492\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 32/1200 GAN loss: 13.681350708007812\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 33/1200 GAN loss: 14.80032730102539\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 34/1200 GAN loss: 14.097219467163086\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 35/1200 GAN loss: 15.116413116455078\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 36/1200 GAN loss: 13.794171333312988\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 37/1200 GAN loss: 14.021451950073242\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 38/1200 GAN loss: 13.879140853881836\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 39/1200 GAN loss: 14.214170455932617\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 40/1200 GAN loss: 13.6533842086792\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 41/1200 GAN loss: 14.095791816711426\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 42/1200 GAN loss: 14.738024711608887\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 43/1200 GAN loss: 13.069442749023438\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 44/1200 GAN loss: 11.742183685302734\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 45/1200 GAN loss: 11.201948165893555\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 46/1200 GAN loss: 14.182422637939453\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 47/1200 GAN loss: 19.345184326171875\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 48/1200 GAN loss: 10.038726806640625\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 49/1200 GAN loss: 6.546813488006592\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 50/1200 GAN loss: 6.409512042999268\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 51/1200 GAN loss: 8.584779739379883\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 52/1200 GAN loss: 16.645183563232422\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 53/1200 GAN loss: 24.91088104248047\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 54/1200 GAN loss: 6.678999423980713\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 55/1200 GAN loss: 3.5586256980895996\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 56/1200 GAN loss: 4.434144973754883\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 57/1200 GAN loss: 4.212858200073242\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 58/1200 GAN loss: 4.501557350158691\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 59/1200 GAN loss: 4.969659805297852\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 60/1200 GAN loss: 17.586288452148438\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 61/1200 GAN loss: 27.667926788330078\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 62/1200 GAN loss: 38.70368194580078\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 63/1200 GAN loss: 18.067169189453125\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 64/1200 GAN loss: 6.643037796020508\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 65/1200 GAN loss: 4.026177883148193\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 66/1200 GAN loss: 3.9131808280944824\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 67/1200 GAN loss: 5.0192155838012695\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 68/1200 GAN loss: 4.67137336730957\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 69/1200 GAN loss: 5.950583457946777\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 70/1200 GAN loss: 9.54690933227539\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 71/1200 GAN loss: 21.904754638671875\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 72/1200 GAN loss: 29.101051330566406\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 73/1200 GAN loss: 38.946556091308594\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 74/1200 GAN loss: 24.347251892089844\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 75/1200 GAN loss: 11.067312240600586\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 76/1200 GAN loss: 8.997838020324707\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 77/1200 GAN loss: 9.39748764038086\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 78/1200 GAN loss: 10.143367767333984\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 79/1200 GAN loss: 9.5260648727417\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 80/1200 GAN loss: 8.619531631469727\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 81/1200 GAN loss: 7.331284523010254\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 82/1200 GAN loss: 13.138864517211914\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 83/1200 GAN loss: 19.435529708862305\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 84/1200 GAN loss: 25.464879989624023\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 85/1200 GAN loss: 12.876379013061523\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 86/1200 GAN loss: 5.998579978942871\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 87/1200 GAN loss: 4.74025821685791\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 88/1200 GAN loss: 4.553523540496826\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 89/1200 GAN loss: 3.754883050918579\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 90/1200 GAN loss: 6.363484859466553\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 91/1200 GAN loss: 4.829183101654053\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 92/1200 GAN loss: 7.199904918670654\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 93/1200 GAN loss: 8.568920135498047\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 94/1200 GAN loss: 8.556234359741211\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 95/1200 GAN loss: 6.886285781860352\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 96/1200 GAN loss: 6.911582946777344\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 97/1200 GAN loss: 6.520275115966797\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 98/1200 GAN loss: 6.6684370040893555\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 99/1200 GAN loss: 6.838249683380127\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 100/1200 GAN loss: 7.8261799812316895\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 101/1200 GAN loss: 8.255959510803223\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 102/1200 GAN loss: 7.762302398681641\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 103/1200 GAN loss: 7.994680404663086\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 104/1200 GAN loss: 7.872894287109375\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 105/1200 GAN loss: 7.430452346801758\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 106/1200 GAN loss: 8.05974292755127\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 107/1200 GAN loss: 7.077202796936035\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 108/1200 GAN loss: 6.704862594604492\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 109/1200 GAN loss: 7.433524131774902\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 110/1200 GAN loss: 7.400232315063477\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 111/1200 GAN loss: 7.425047874450684\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 112/1200 GAN loss: 6.888894081115723\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 113/1200 GAN loss: 7.928614139556885\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 114/1200 GAN loss: 7.093835830688477\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 115/1200 GAN loss: 7.996888160705566\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 116/1200 GAN loss: 6.286657810211182\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 117/1200 GAN loss: 6.6575775146484375\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 118/1200 GAN loss: 7.292400360107422\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 119/1200 GAN loss: 7.10474967956543\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 120/1200 GAN loss: 7.9164862632751465\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 121/1200 GAN loss: 7.308570384979248\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 122/1200 GAN loss: 6.85581111907959\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 123/1200 GAN loss: 7.59223747253418\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 124/1200 GAN loss: 8.047333717346191\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 125/1200 GAN loss: 7.962950706481934\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 126/1200 GAN loss: 7.536120414733887\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 127/1200 GAN loss: 7.822622776031494\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 128/1200 GAN loss: 7.76248836517334\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 129/1200 GAN loss: 6.440777778625488\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 130/1200 GAN loss: 6.722781181335449\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 131/1200 GAN loss: 7.110804557800293\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 132/1200 GAN loss: 7.155835151672363\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 133/1200 GAN loss: 5.24576997756958\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 134/1200 GAN loss: 6.562808513641357\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 135/1200 GAN loss: 8.684908866882324\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 136/1200 GAN loss: 8.415940284729004\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 137/1200 GAN loss: 7.456661224365234\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 138/1200 GAN loss: 6.932082653045654\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 139/1200 GAN loss: 7.495843887329102\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 140/1200 GAN loss: 7.724645614624023\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 141/1200 GAN loss: 8.924323081970215\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 142/1200 GAN loss: 6.7917680740356445\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 143/1200 GAN loss: 6.0717058181762695\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 144/1200 GAN loss: 6.837346076965332\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 145/1200 GAN loss: 8.517874717712402\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 146/1200 GAN loss: 6.734959602355957\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 147/1200 GAN loss: 6.547214508056641\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 148/1200 GAN loss: 6.802493095397949\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 149/1200 GAN loss: 7.915573596954346\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 150/1200 GAN loss: 9.048980712890625\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 151/1200 GAN loss: 8.932708740234375\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 152/1200 GAN loss: 9.252443313598633\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 153/1200 GAN loss: 8.083158493041992\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 154/1200 GAN loss: 7.418587684631348\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 155/1200 GAN loss: 7.775721549987793\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 156/1200 GAN loss: 8.631832122802734\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 157/1200 GAN loss: 8.64077091217041\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 158/1200 GAN loss: 8.919917106628418\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 159/1200 GAN loss: 8.636792182922363\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 160/1200 GAN loss: 8.0584077835083\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 161/1200 GAN loss: 7.9707512855529785\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 162/1200 GAN loss: 8.113912582397461\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 163/1200 GAN loss: 8.040816307067871\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 164/1200 GAN loss: 7.876589775085449\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 165/1200 GAN loss: 7.842996120452881\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 166/1200 GAN loss: 7.526246070861816\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 167/1200 GAN loss: 6.9815521240234375\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 168/1200 GAN loss: 6.635485649108887\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 169/1200 GAN loss: 6.889294624328613\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 170/1200 GAN loss: 7.188314914703369\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 171/1200 GAN loss: 6.609762668609619\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 172/1200 GAN loss: 6.563655853271484\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 173/1200 GAN loss: 6.255242347717285\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 174/1200 GAN loss: 7.208080291748047\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 175/1200 GAN loss: 7.724602222442627\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 176/1200 GAN loss: 6.764138698577881\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 177/1200 GAN loss: 6.866432189941406\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 178/1200 GAN loss: 7.876166343688965\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 179/1200 GAN loss: 8.114185333251953\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 180/1200 GAN loss: 8.163712501525879\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 181/1200 GAN loss: 7.750302314758301\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 182/1200 GAN loss: 7.383508682250977\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 183/1200 GAN loss: 7.555878639221191\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 184/1200 GAN loss: 7.782868385314941\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 185/1200 GAN loss: 7.102630138397217\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 186/1200 GAN loss: 7.171124458312988\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 187/1200 GAN loss: 7.12037467956543\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 188/1200 GAN loss: 7.380340576171875\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 189/1200 GAN loss: 7.476048469543457\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 190/1200 GAN loss: 7.4754228591918945\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 191/1200 GAN loss: 7.721980094909668\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 192/1200 GAN loss: 7.682490825653076\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 193/1200 GAN loss: 7.401941299438477\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 194/1200 GAN loss: 7.917817115783691\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 195/1200 GAN loss: 8.025394439697266\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 196/1200 GAN loss: 8.173685073852539\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 197/1200 GAN loss: 8.251579284667969\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 198/1200 GAN loss: 8.965103149414062\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 199/1200 GAN loss: 9.105961799621582\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 200/1200 GAN loss: 8.704972267150879\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 201/1200 GAN loss: 8.844050407409668\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 202/1200 GAN loss: 9.135599136352539\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 203/1200 GAN loss: 8.968649864196777\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 204/1200 GAN loss: 8.517326354980469\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 205/1200 GAN loss: 8.247672080993652\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 206/1200 GAN loss: 8.366483688354492\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 207/1200 GAN loss: 7.979848861694336\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 208/1200 GAN loss: 8.579353332519531\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 209/1200 GAN loss: 7.833390235900879\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 210/1200 GAN loss: 7.510876655578613\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 211/1200 GAN loss: 7.315765380859375\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 212/1200 GAN loss: 7.921927452087402\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 213/1200 GAN loss: 8.960442543029785\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 214/1200 GAN loss: 8.66719913482666\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 215/1200 GAN loss: 8.570035934448242\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 216/1200 GAN loss: 8.876103401184082\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 217/1200 GAN loss: 8.203323364257812\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 218/1200 GAN loss: 8.722477912902832\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 219/1200 GAN loss: 8.197065353393555\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 220/1200 GAN loss: 8.636670112609863\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 221/1200 GAN loss: 8.329069137573242\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 222/1200 GAN loss: 8.365462303161621\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 223/1200 GAN loss: 8.738482475280762\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 224/1200 GAN loss: 8.377241134643555\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 225/1200 GAN loss: 8.431722640991211\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 226/1200 GAN loss: 8.76877498626709\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 227/1200 GAN loss: 9.405860900878906\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 228/1200 GAN loss: 7.772044658660889\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 229/1200 GAN loss: 7.307994842529297\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 230/1200 GAN loss: 7.744997024536133\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 231/1200 GAN loss: 9.664928436279297\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 232/1200 GAN loss: 7.6919331550598145\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 233/1200 GAN loss: 7.28085994720459\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 234/1200 GAN loss: 8.241886138916016\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 235/1200 GAN loss: 8.92763614654541\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 236/1200 GAN loss: 8.929973602294922\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 237/1200 GAN loss: 7.971400737762451\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 238/1200 GAN loss: 7.282620906829834\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 239/1200 GAN loss: 7.643591403961182\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 240/1200 GAN loss: 7.61564826965332\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 241/1200 GAN loss: 7.408011436462402\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 242/1200 GAN loss: 7.691300392150879\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 243/1200 GAN loss: 8.062734603881836\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 244/1200 GAN loss: 8.725364685058594\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 245/1200 GAN loss: 8.206351280212402\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 246/1200 GAN loss: 7.469321250915527\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 247/1200 GAN loss: 7.818170547485352\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 248/1200 GAN loss: 8.192825317382812\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 249/1200 GAN loss: 8.821889877319336\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 250/1200 GAN loss: 7.871728897094727\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 251/1200 GAN loss: 7.326288223266602\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 252/1200 GAN loss: 8.482743263244629\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 253/1200 GAN loss: 7.694986343383789\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 254/1200 GAN loss: 7.541118621826172\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 255/1200 GAN loss: 7.784443378448486\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 256/1200 GAN loss: 6.6607160568237305\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 257/1200 GAN loss: 7.162131309509277\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 258/1200 GAN loss: 8.385763168334961\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 259/1200 GAN loss: 8.166059494018555\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 260/1200 GAN loss: 9.735832214355469\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 261/1200 GAN loss: 3.7643558979034424\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 262/1200 GAN loss: 11.627647399902344\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 263/1200 GAN loss: 1.437828779220581\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 264/1200 GAN loss: 2.303835868835449\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 265/1200 GAN loss: 10.31620979309082\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 266/1200 GAN loss: 24.77536392211914\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 267/1200 GAN loss: 6.484048843383789\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 268/1200 GAN loss: 1.187744140625\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 269/1200 GAN loss: 1.190402626991272\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 270/1200 GAN loss: 2.3286495208740234\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 271/1200 GAN loss: 5.822588920593262\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 272/1200 GAN loss: 11.458883285522461\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 273/1200 GAN loss: 9.294500350952148\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 274/1200 GAN loss: 5.203506946563721\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 275/1200 GAN loss: 2.3603625297546387\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 276/1200 GAN loss: 2.434323787689209\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 277/1200 GAN loss: 1.9201897382736206\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 278/1200 GAN loss: 2.9077610969543457\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 279/1200 GAN loss: 4.435585021972656\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 280/1200 GAN loss: 7.1632537841796875\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 281/1200 GAN loss: 8.887014389038086\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 282/1200 GAN loss: 6.897709846496582\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 283/1200 GAN loss: 5.753257751464844\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 284/1200 GAN loss: 4.478629112243652\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 285/1200 GAN loss: 3.507636547088623\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 286/1200 GAN loss: 5.065860271453857\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 287/1200 GAN loss: 5.796718597412109\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 288/1200 GAN loss: 6.570766448974609\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 289/1200 GAN loss: 5.795313835144043\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 290/1200 GAN loss: 4.591706275939941\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 291/1200 GAN loss: 3.9675817489624023\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 292/1200 GAN loss: 5.157262802124023\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 293/1200 GAN loss: 3.9485318660736084\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 294/1200 GAN loss: 3.3920209407806396\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 295/1200 GAN loss: 4.117463111877441\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 296/1200 GAN loss: 4.1066694259643555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 297/1200 GAN loss: 2.648930549621582\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 298/1200 GAN loss: 3.163172721862793\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 299/1200 GAN loss: 4.0611371994018555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 300/1200 GAN loss: 2.536067485809326\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 301/1200 GAN loss: 2.848034381866455\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 302/1200 GAN loss: 4.713226318359375\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 303/1200 GAN loss: 1.7452712059020996\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 304/1200 GAN loss: 2.8712000846862793\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 305/1200 GAN loss: 6.861828804016113\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 306/1200 GAN loss: 1.9910531044006348\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 307/1200 GAN loss: 0.7121304869651794\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 308/1200 GAN loss: 4.053701400756836\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 309/1200 GAN loss: 11.313594818115234\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 310/1200 GAN loss: 3.776500940322876\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 311/1200 GAN loss: 0.8958298563957214\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 312/1200 GAN loss: 1.0263264179229736\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 313/1200 GAN loss: 2.8721792697906494\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 314/1200 GAN loss: 4.766183853149414\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 315/1200 GAN loss: 3.019601345062256\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 316/1200 GAN loss: 2.0822224617004395\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 317/1200 GAN loss: 1.991628885269165\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 318/1200 GAN loss: 2.424372673034668\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 319/1200 GAN loss: 3.1200690269470215\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 320/1200 GAN loss: 2.220675468444824\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 321/1200 GAN loss: 1.4330493211746216\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 322/1200 GAN loss: 1.5976674556732178\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 323/1200 GAN loss: 2.3113303184509277\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 324/1200 GAN loss: 2.0698232650756836\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 325/1200 GAN loss: 1.702507495880127\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 326/1200 GAN loss: 1.59208345413208\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 327/1200 GAN loss: 1.9602546691894531\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 328/1200 GAN loss: 2.6805853843688965\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 329/1200 GAN loss: 1.6922900676727295\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 330/1200 GAN loss: 1.8590905666351318\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 331/1200 GAN loss: 1.81988525390625\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 332/1200 GAN loss: 2.278926372528076\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 333/1200 GAN loss: 2.056813955307007\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 334/1200 GAN loss: 2.2199220657348633\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 335/1200 GAN loss: 2.3679568767547607\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 336/1200 GAN loss: 1.9533125162124634\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 337/1200 GAN loss: 2.1882829666137695\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 338/1200 GAN loss: 2.669487476348877\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 339/1200 GAN loss: 2.57450008392334\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 340/1200 GAN loss: 2.1750259399414062\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 341/1200 GAN loss: 2.5568346977233887\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 342/1200 GAN loss: 3.166757583618164\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 343/1200 GAN loss: 2.5220370292663574\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 344/1200 GAN loss: 2.529393196105957\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 345/1200 GAN loss: 2.6436574459075928\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 346/1200 GAN loss: 2.4095520973205566\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 347/1200 GAN loss: 2.829519510269165\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 348/1200 GAN loss: 2.6480512619018555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 349/1200 GAN loss: 2.5701847076416016\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 350/1200 GAN loss: 2.9948976039886475\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 351/1200 GAN loss: 2.642673969268799\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 352/1200 GAN loss: 3.0863778591156006\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 353/1200 GAN loss: 3.0989842414855957\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 354/1200 GAN loss: 2.186008930206299\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 355/1200 GAN loss: 2.7714486122131348\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 356/1200 GAN loss: 3.8975324630737305\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 357/1200 GAN loss: 1.8609875440597534\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 358/1200 GAN loss: 2.1501388549804688\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 359/1200 GAN loss: 3.8883187770843506\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 360/1200 GAN loss: 1.3415846824645996\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 361/1200 GAN loss: 1.5013623237609863\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 362/1200 GAN loss: 2.732247829437256\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 363/1200 GAN loss: 3.085747241973877\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 364/1200 GAN loss: 1.1421582698822021\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 365/1200 GAN loss: 1.351019024848938\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 366/1200 GAN loss: 3.333603858947754\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 367/1200 GAN loss: 2.129749298095703\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 368/1200 GAN loss: 1.2587534189224243\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 369/1200 GAN loss: 2.614466428756714\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 370/1200 GAN loss: 3.4688327312469482\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 371/1200 GAN loss: 1.6658961772918701\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 372/1200 GAN loss: 1.4180129766464233\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 373/1200 GAN loss: 2.669703245162964\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 374/1200 GAN loss: 2.0843124389648438\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 375/1200 GAN loss: 1.8856112957000732\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 376/1200 GAN loss: 2.4056735038757324\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 377/1200 GAN loss: 1.9178552627563477\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 378/1200 GAN loss: 1.9147850275039673\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 379/1200 GAN loss: 2.0983848571777344\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 380/1200 GAN loss: 2.4455349445343018\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 381/1200 GAN loss: 1.6596205234527588\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 382/1200 GAN loss: 1.7127959728240967\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 383/1200 GAN loss: 2.3072359561920166\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 384/1200 GAN loss: 2.440401077270508\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 385/1200 GAN loss: 2.4481570720672607\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 386/1200 GAN loss: 1.9811203479766846\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 387/1200 GAN loss: 1.8358004093170166\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 388/1200 GAN loss: 2.3978323936462402\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 389/1200 GAN loss: 2.2252867221832275\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 390/1200 GAN loss: 2.8009085655212402\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 391/1200 GAN loss: 2.716038703918457\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 392/1200 GAN loss: 2.0905373096466064\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 393/1200 GAN loss: 2.5569796562194824\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 394/1200 GAN loss: 3.585645914077759\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 395/1200 GAN loss: 2.9689841270446777\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 396/1200 GAN loss: 2.710480213165283\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 397/1200 GAN loss: 2.5145435333251953\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 398/1200 GAN loss: 3.230210065841675\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 399/1200 GAN loss: 3.009425640106201\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 400/1200 GAN loss: 3.083754062652588\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 401/1200 GAN loss: 3.1910593509674072\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 402/1200 GAN loss: 2.116938352584839\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 403/1200 GAN loss: 2.4355571269989014\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 404/1200 GAN loss: 3.488558769226074\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 405/1200 GAN loss: 2.2752532958984375\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 406/1200 GAN loss: 2.309122085571289\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 407/1200 GAN loss: 2.8050479888916016\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 408/1200 GAN loss: 2.2750301361083984\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 409/1200 GAN loss: 2.616664171218872\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 410/1200 GAN loss: 2.8220534324645996\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 411/1200 GAN loss: 2.9218244552612305\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 412/1200 GAN loss: 2.215608835220337\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 413/1200 GAN loss: 2.0514416694641113\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 414/1200 GAN loss: 2.505873203277588\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 415/1200 GAN loss: 2.0458626747131348\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 416/1200 GAN loss: 1.4452511072158813\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 417/1200 GAN loss: 1.7105205059051514\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 418/1200 GAN loss: 2.407007932662964\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 419/1200 GAN loss: 1.5781240463256836\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 420/1200 GAN loss: 1.8132823705673218\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 421/1200 GAN loss: 1.8766499757766724\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 422/1200 GAN loss: 1.17913818359375\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 423/1200 GAN loss: 2.076223373413086\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 424/1200 GAN loss: 1.5602810382843018\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 425/1200 GAN loss: 1.4995415210723877\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 426/1200 GAN loss: 1.695509433746338\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 427/1200 GAN loss: 1.610483169555664\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 428/1200 GAN loss: 1.5294804573059082\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 429/1200 GAN loss: 1.9742989540100098\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 430/1200 GAN loss: 1.2283644676208496\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 431/1200 GAN loss: 1.8117038011550903\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 432/1200 GAN loss: 1.8140454292297363\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 433/1200 GAN loss: 1.8761016130447388\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 434/1200 GAN loss: 1.613419532775879\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 435/1200 GAN loss: 1.6477231979370117\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 436/1200 GAN loss: 1.7212555408477783\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 437/1200 GAN loss: 1.5485150814056396\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 438/1200 GAN loss: 2.1294045448303223\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 439/1200 GAN loss: 1.92245614528656\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 440/1200 GAN loss: 2.0295491218566895\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 441/1200 GAN loss: 1.8619129657745361\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 442/1200 GAN loss: 1.7363563776016235\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 443/1200 GAN loss: 1.4365432262420654\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 444/1200 GAN loss: 1.6362388134002686\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 445/1200 GAN loss: 1.602210283279419\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 446/1200 GAN loss: 1.3545987606048584\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 447/1200 GAN loss: 2.152794361114502\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 448/1200 GAN loss: 1.520467758178711\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 449/1200 GAN loss: 1.798109769821167\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 450/1200 GAN loss: 1.947858452796936\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 451/1200 GAN loss: 1.5489065647125244\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 452/1200 GAN loss: 1.3939043283462524\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 453/1200 GAN loss: 1.6170573234558105\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 454/1200 GAN loss: 1.5194783210754395\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 455/1200 GAN loss: 1.7865839004516602\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 456/1200 GAN loss: 1.468340277671814\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 457/1200 GAN loss: 1.614933967590332\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 458/1200 GAN loss: 1.545274257659912\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 459/1200 GAN loss: 1.3358339071273804\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 460/1200 GAN loss: 1.408733606338501\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 461/1200 GAN loss: 1.4148720502853394\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 462/1200 GAN loss: 1.1417369842529297\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 463/1200 GAN loss: 1.4670945405960083\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 464/1200 GAN loss: 1.7910653352737427\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 465/1200 GAN loss: 1.0539519786834717\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 466/1200 GAN loss: 1.8881499767303467\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 467/1200 GAN loss: 1.3986533880233765\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 468/1200 GAN loss: 1.306917428970337\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 469/1200 GAN loss: 1.2484869956970215\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 470/1200 GAN loss: 1.363702416419983\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 471/1200 GAN loss: 1.4394261837005615\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 472/1200 GAN loss: 1.178673505783081\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 473/1200 GAN loss: 1.2926779985427856\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 474/1200 GAN loss: 1.9051191806793213\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 475/1200 GAN loss: 1.2337161302566528\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 476/1200 GAN loss: 1.0271625518798828\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 477/1200 GAN loss: 1.2147661447525024\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 478/1200 GAN loss: 1.530301809310913\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 479/1200 GAN loss: 1.023578405380249\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 480/1200 GAN loss: 1.0953037738800049\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 481/1200 GAN loss: 1.3605921268463135\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 482/1200 GAN loss: 1.0108466148376465\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 483/1200 GAN loss: 0.9223932027816772\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 484/1200 GAN loss: 1.1873117685317993\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 485/1200 GAN loss: 1.0273466110229492\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 486/1200 GAN loss: 0.9078986644744873\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 487/1200 GAN loss: 0.9272300601005554\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 488/1200 GAN loss: 1.0148636102676392\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 489/1200 GAN loss: 1.0697784423828125\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 490/1200 GAN loss: 1.0115530490875244\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 491/1200 GAN loss: 0.900559663772583\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 492/1200 GAN loss: 1.029334306716919\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 493/1200 GAN loss: 1.1204214096069336\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 494/1200 GAN loss: 1.2470673322677612\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 495/1200 GAN loss: 0.964408278465271\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 496/1200 GAN loss: 0.9622360467910767\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 497/1200 GAN loss: 1.0016471147537231\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 498/1200 GAN loss: 1.0150014162063599\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 499/1200 GAN loss: 1.1411969661712646\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 500/1200 GAN loss: 1.0821365118026733\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 501/1200 GAN loss: 0.9913514852523804\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 502/1200 GAN loss: 0.9542583227157593\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 503/1200 GAN loss: 1.1011011600494385\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 504/1200 GAN loss: 1.1391425132751465\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 505/1200 GAN loss: 1.3976573944091797\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 506/1200 GAN loss: 0.9855842590332031\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 507/1200 GAN loss: 0.9641246795654297\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 508/1200 GAN loss: 1.0600155591964722\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 509/1200 GAN loss: 1.182120442390442\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 510/1200 GAN loss: 1.0855143070220947\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 511/1200 GAN loss: 0.98847895860672\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 512/1200 GAN loss: 0.9698599576950073\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 513/1200 GAN loss: 1.193195104598999\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 514/1200 GAN loss: 1.3832423686981201\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 515/1200 GAN loss: 1.1703161001205444\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 516/1200 GAN loss: 1.0911844968795776\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 517/1200 GAN loss: 0.9081012010574341\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 518/1200 GAN loss: 1.2923119068145752\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 519/1200 GAN loss: 1.1101405620574951\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 520/1200 GAN loss: 1.0081937313079834\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 521/1200 GAN loss: 0.9933271408081055\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 522/1200 GAN loss: 1.2008674144744873\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 523/1200 GAN loss: 1.0296858549118042\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 524/1200 GAN loss: 1.0526267290115356\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 525/1200 GAN loss: 0.9965561032295227\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 526/1200 GAN loss: 1.0167003870010376\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 527/1200 GAN loss: 1.1918601989746094\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 528/1200 GAN loss: 1.1207082271575928\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 529/1200 GAN loss: 1.0619913339614868\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 530/1200 GAN loss: 1.0818414688110352\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 531/1200 GAN loss: 1.1315422058105469\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 532/1200 GAN loss: 1.3568768501281738\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 533/1200 GAN loss: 0.9709545969963074\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 534/1200 GAN loss: 0.9176368117332458\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 535/1200 GAN loss: 1.086307168006897\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 536/1200 GAN loss: 1.2483930587768555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 537/1200 GAN loss: 1.0974669456481934\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 538/1200 GAN loss: 0.9566640853881836\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 539/1200 GAN loss: 1.0192055702209473\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 540/1200 GAN loss: 1.0812733173370361\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 541/1200 GAN loss: 1.0309460163116455\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 542/1200 GAN loss: 1.0642236471176147\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 543/1200 GAN loss: 1.0295897722244263\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 544/1200 GAN loss: 1.0263766050338745\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 545/1200 GAN loss: 1.111784815788269\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 546/1200 GAN loss: 0.9526546597480774\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 547/1200 GAN loss: 0.9459863901138306\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 548/1200 GAN loss: 0.9131144285202026\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 549/1200 GAN loss: 1.0340392589569092\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 550/1200 GAN loss: 1.0071254968643188\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 551/1200 GAN loss: 1.0459816455841064\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 552/1200 GAN loss: 0.9103097915649414\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 553/1200 GAN loss: 0.9695663452148438\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 554/1200 GAN loss: 0.9349659085273743\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 555/1200 GAN loss: 1.0200018882751465\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 556/1200 GAN loss: 1.0064963102340698\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 557/1200 GAN loss: 0.951189398765564\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 558/1200 GAN loss: 1.0955066680908203\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 559/1200 GAN loss: 1.0930839776992798\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 560/1200 GAN loss: 0.7692527770996094\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 561/1200 GAN loss: 0.911178469657898\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 562/1200 GAN loss: 1.0317721366882324\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 563/1200 GAN loss: 0.9283895492553711\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 564/1200 GAN loss: 0.9949090480804443\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 565/1200 GAN loss: 1.017229676246643\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 566/1200 GAN loss: 0.9935934543609619\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 567/1200 GAN loss: 0.8698107004165649\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 568/1200 GAN loss: 0.9620121121406555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 569/1200 GAN loss: 1.0475691556930542\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 570/1200 GAN loss: 0.7971445918083191\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 571/1200 GAN loss: 0.778547465801239\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 572/1200 GAN loss: 0.8708972930908203\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 573/1200 GAN loss: 1.0002647638320923\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 574/1200 GAN loss: 0.990918755531311\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 575/1200 GAN loss: 0.9000363349914551\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 576/1200 GAN loss: 0.8038191199302673\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 577/1200 GAN loss: 0.892519474029541\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 578/1200 GAN loss: 0.877020537853241\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 579/1200 GAN loss: 0.9000288844108582\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 580/1200 GAN loss: 0.8799275159835815\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 581/1200 GAN loss: 0.9005454778671265\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 582/1200 GAN loss: 0.8663122653961182\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 583/1200 GAN loss: 0.8184250593185425\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 584/1200 GAN loss: 0.8535908460617065\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 585/1200 GAN loss: 0.8497813940048218\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 586/1200 GAN loss: 0.9293833374977112\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 587/1200 GAN loss: 0.8603056073188782\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 588/1200 GAN loss: 0.8301904201507568\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 589/1200 GAN loss: 0.8685739040374756\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 590/1200 GAN loss: 0.9016048908233643\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 591/1200 GAN loss: 0.8524767756462097\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 592/1200 GAN loss: 0.8518459796905518\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 593/1200 GAN loss: 0.8102782964706421\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 594/1200 GAN loss: 0.7619680166244507\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 595/1200 GAN loss: 0.7779121398925781\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 596/1200 GAN loss: 0.8042911291122437\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 597/1200 GAN loss: 0.9322750568389893\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 598/1200 GAN loss: 0.9119129180908203\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 599/1200 GAN loss: 0.7579233646392822\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 600/1200 GAN loss: 0.7567697763442993\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 601/1200 GAN loss: 0.830854058265686\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 602/1200 GAN loss: 0.8331909775733948\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 603/1200 GAN loss: 0.9312007427215576\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 604/1200 GAN loss: 0.8191961050033569\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 605/1200 GAN loss: 0.6784911155700684\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 606/1200 GAN loss: 0.7904013395309448\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 607/1200 GAN loss: 0.8532025218009949\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 608/1200 GAN loss: 0.887607753276825\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 609/1200 GAN loss: 0.8431916236877441\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 610/1200 GAN loss: 0.8623156547546387\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 611/1200 GAN loss: 0.8465631008148193\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 612/1200 GAN loss: 0.8445168733596802\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 613/1200 GAN loss: 0.8456350564956665\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 614/1200 GAN loss: 0.8825680017471313\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 615/1200 GAN loss: 0.894598126411438\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 616/1200 GAN loss: 0.8423359394073486\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 617/1200 GAN loss: 0.8291342854499817\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 618/1200 GAN loss: 0.8690371513366699\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 619/1200 GAN loss: 0.8967956304550171\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 620/1200 GAN loss: 0.8882482051849365\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 621/1200 GAN loss: 0.7536066770553589\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 622/1200 GAN loss: 0.794872522354126\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 623/1200 GAN loss: 0.8346881866455078\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 624/1200 GAN loss: 0.8598315715789795\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 625/1200 GAN loss: 0.9470146894454956\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 626/1200 GAN loss: 0.8689396381378174\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 627/1200 GAN loss: 0.7731096744537354\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 628/1200 GAN loss: 0.7807458639144897\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 629/1200 GAN loss: 0.8001328110694885\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 630/1200 GAN loss: 0.8993741273880005\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 631/1200 GAN loss: 0.9044743776321411\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 632/1200 GAN loss: 0.814306378364563\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 633/1200 GAN loss: 0.7542288303375244\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 634/1200 GAN loss: 0.797302782535553\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 635/1200 GAN loss: 0.77118980884552\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 636/1200 GAN loss: 0.8491945266723633\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 637/1200 GAN loss: 0.8089175224304199\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 638/1200 GAN loss: 0.7924894094467163\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 639/1200 GAN loss: 0.8020374774932861\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 640/1200 GAN loss: 0.8051959276199341\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 641/1200 GAN loss: 0.8226836919784546\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 642/1200 GAN loss: 0.8152909874916077\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 643/1200 GAN loss: 0.8152337074279785\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 644/1200 GAN loss: 0.7858074903488159\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 645/1200 GAN loss: 0.8426216244697571\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 646/1200 GAN loss: 0.8173533082008362\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 647/1200 GAN loss: 0.825092077255249\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 648/1200 GAN loss: 0.832038402557373\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 649/1200 GAN loss: 0.7980612516403198\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 650/1200 GAN loss: 0.7985648512840271\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 651/1200 GAN loss: 0.8355981707572937\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 652/1200 GAN loss: 0.8514108657836914\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 653/1200 GAN loss: 0.8491425514221191\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 654/1200 GAN loss: 0.8572381734848022\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 655/1200 GAN loss: 0.8651933670043945\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 656/1200 GAN loss: 0.7895445823669434\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 657/1200 GAN loss: 0.7821528315544128\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 658/1200 GAN loss: 0.7639137506484985\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 659/1200 GAN loss: 0.7814640998840332\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 660/1200 GAN loss: 0.8338857293128967\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 661/1200 GAN loss: 0.8598409295082092\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 662/1200 GAN loss: 0.8199535608291626\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 663/1200 GAN loss: 0.7840808033943176\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 664/1200 GAN loss: 0.7766155004501343\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 665/1200 GAN loss: 0.7745009064674377\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 666/1200 GAN loss: 0.7535458207130432\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 667/1200 GAN loss: 0.7762597799301147\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 668/1200 GAN loss: 0.7785736918449402\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 669/1200 GAN loss: 0.7885770797729492\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 670/1200 GAN loss: 0.7784935235977173\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 671/1200 GAN loss: 0.800044059753418\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 672/1200 GAN loss: 0.7788609266281128\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 673/1200 GAN loss: 0.783791720867157\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 674/1200 GAN loss: 0.747995138168335\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 675/1200 GAN loss: 0.7425341606140137\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 676/1200 GAN loss: 0.7393088340759277\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 677/1200 GAN loss: 0.798914909362793\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 678/1200 GAN loss: 0.7955962419509888\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 679/1200 GAN loss: 0.7961407899856567\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 680/1200 GAN loss: 0.7637723684310913\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 681/1200 GAN loss: 0.7561427354812622\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 682/1200 GAN loss: 0.7702686190605164\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 683/1200 GAN loss: 0.7885153293609619\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 684/1200 GAN loss: 0.8742002248764038\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 685/1200 GAN loss: 0.8353051543235779\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 686/1200 GAN loss: 0.7868934869766235\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 687/1200 GAN loss: 0.7220702171325684\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 688/1200 GAN loss: 0.6915091276168823\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 689/1200 GAN loss: 0.7887654304504395\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 690/1200 GAN loss: 0.9027878046035767\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 691/1200 GAN loss: 0.9009344577789307\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 692/1200 GAN loss: 0.7833167314529419\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 693/1200 GAN loss: 0.8013193011283875\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 694/1200 GAN loss: 0.710577666759491\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 695/1200 GAN loss: 0.7798808217048645\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 696/1200 GAN loss: 0.7917491793632507\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 697/1200 GAN loss: 0.7967631816864014\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 698/1200 GAN loss: 0.7764912247657776\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 699/1200 GAN loss: 0.7681277990341187\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 700/1200 GAN loss: 0.7947492003440857\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 701/1200 GAN loss: 0.8189836144447327\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 702/1200 GAN loss: 0.8102301359176636\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 703/1200 GAN loss: 0.7812029123306274\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 704/1200 GAN loss: 0.8007184267044067\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 705/1200 GAN loss: 0.791236400604248\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 706/1200 GAN loss: 0.7770587205886841\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 707/1200 GAN loss: 0.7964344620704651\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 708/1200 GAN loss: 0.7905834913253784\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 709/1200 GAN loss: 0.7607834339141846\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 710/1200 GAN loss: 0.7594836354255676\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 711/1200 GAN loss: 0.7358587980270386\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 712/1200 GAN loss: 0.7977529168128967\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 713/1200 GAN loss: 0.7924935817718506\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 714/1200 GAN loss: 0.7720418572425842\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 715/1200 GAN loss: 0.7475780844688416\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 716/1200 GAN loss: 0.7353731989860535\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 717/1200 GAN loss: 0.7642362713813782\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 718/1200 GAN loss: 0.7894962430000305\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 719/1200 GAN loss: 0.7804520130157471\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 720/1200 GAN loss: 0.7786813378334045\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 721/1200 GAN loss: 0.7432419061660767\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 722/1200 GAN loss: 0.7225024700164795\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 723/1200 GAN loss: 0.7095808386802673\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 724/1200 GAN loss: 0.7335944771766663\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 725/1200 GAN loss: 0.7445595860481262\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 726/1200 GAN loss: 0.7783063054084778\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 727/1200 GAN loss: 0.7338018417358398\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 728/1200 GAN loss: 0.7079715728759766\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 729/1200 GAN loss: 0.7040195465087891\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 730/1200 GAN loss: 0.6870769262313843\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 731/1200 GAN loss: 0.7152402400970459\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 732/1200 GAN loss: 0.7341288924217224\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 733/1200 GAN loss: 0.7569977045059204\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 734/1200 GAN loss: 0.7532657384872437\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 735/1200 GAN loss: 0.7374204993247986\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 736/1200 GAN loss: 0.7150903940200806\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 737/1200 GAN loss: 0.7028498649597168\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 738/1200 GAN loss: 0.6943361759185791\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 739/1200 GAN loss: 0.7036136388778687\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 740/1200 GAN loss: 0.7235588431358337\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 741/1200 GAN loss: 0.7422800064086914\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 742/1200 GAN loss: 0.7504295706748962\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 743/1200 GAN loss: 0.7406589388847351\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 744/1200 GAN loss: 0.7110585570335388\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 745/1200 GAN loss: 0.6871423721313477\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 746/1200 GAN loss: 0.6862507462501526\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 747/1200 GAN loss: 0.691051721572876\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 748/1200 GAN loss: 0.7234463691711426\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 749/1200 GAN loss: 0.7403608560562134\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 750/1200 GAN loss: 0.7532036304473877\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 751/1200 GAN loss: 0.7464626431465149\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 752/1200 GAN loss: 0.7212547659873962\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 753/1200 GAN loss: 0.7265900373458862\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 754/1200 GAN loss: 0.7510574460029602\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 755/1200 GAN loss: 0.7478979229927063\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 756/1200 GAN loss: 0.775864839553833\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 757/1200 GAN loss: 0.7788416147232056\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 758/1200 GAN loss: 0.7969561815261841\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 759/1200 GAN loss: 0.8247897624969482\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 760/1200 GAN loss: 0.7707844972610474\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 761/1200 GAN loss: 0.7782716155052185\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 762/1200 GAN loss: 0.7442359924316406\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 763/1200 GAN loss: 0.7793256044387817\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 764/1200 GAN loss: 0.8144030570983887\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 765/1200 GAN loss: 0.7646869421005249\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 766/1200 GAN loss: 0.7329059839248657\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 767/1200 GAN loss: 0.759580135345459\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 768/1200 GAN loss: 0.7852548360824585\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 769/1200 GAN loss: 0.7771354913711548\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 770/1200 GAN loss: 0.7700490355491638\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 771/1200 GAN loss: 0.7816193699836731\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 772/1200 GAN loss: 0.7803319096565247\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 773/1200 GAN loss: 0.771869421005249\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 774/1200 GAN loss: 0.7409934997558594\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 775/1200 GAN loss: 0.7476544380187988\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 776/1200 GAN loss: 0.7210427522659302\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 777/1200 GAN loss: 0.762031078338623\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 778/1200 GAN loss: 0.7877262830734253\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 779/1200 GAN loss: 0.7773900032043457\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 780/1200 GAN loss: 0.7551893591880798\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 781/1200 GAN loss: 0.7569624185562134\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 782/1200 GAN loss: 0.7487810850143433\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 783/1200 GAN loss: 0.7524421215057373\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 784/1200 GAN loss: 0.7394455075263977\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 785/1200 GAN loss: 0.7437213659286499\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 786/1200 GAN loss: 0.7506176233291626\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 787/1200 GAN loss: 0.758074939250946\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 788/1200 GAN loss: 0.7644814252853394\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 789/1200 GAN loss: 0.7602220177650452\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 790/1200 GAN loss: 0.7454803586006165\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 791/1200 GAN loss: 0.700426459312439\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 792/1200 GAN loss: 0.7175391912460327\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 793/1200 GAN loss: 0.776055634021759\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 794/1200 GAN loss: 0.7938480377197266\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 795/1200 GAN loss: 0.7770359516143799\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 796/1200 GAN loss: 0.7510484457015991\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 797/1200 GAN loss: 0.7207030057907104\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 798/1200 GAN loss: 0.7170994281768799\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 799/1200 GAN loss: 0.7475563883781433\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 800/1200 GAN loss: 0.6947324872016907\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 801/1200 GAN loss: 0.6833019256591797\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 802/1200 GAN loss: 0.7025611400604248\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 803/1200 GAN loss: 0.7363930940628052\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 804/1200 GAN loss: 0.7426842451095581\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 805/1200 GAN loss: 0.7322657704353333\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 806/1200 GAN loss: 0.7190141081809998\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 807/1200 GAN loss: 0.7109912633895874\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 808/1200 GAN loss: 0.701292097568512\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 809/1200 GAN loss: 0.6954153776168823\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 810/1200 GAN loss: 0.7051605582237244\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 811/1200 GAN loss: 0.6977723240852356\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 812/1200 GAN loss: 0.7053983211517334\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 813/1200 GAN loss: 0.7280631065368652\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 814/1200 GAN loss: 0.7144575119018555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 815/1200 GAN loss: 0.7072696685791016\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 816/1200 GAN loss: 0.6979118585586548\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 817/1200 GAN loss: 0.7114379405975342\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 818/1200 GAN loss: 0.7345660924911499\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 819/1200 GAN loss: 0.7623218297958374\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 820/1200 GAN loss: 0.7686703205108643\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 821/1200 GAN loss: 0.7600202560424805\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 822/1200 GAN loss: 0.7497378587722778\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 823/1200 GAN loss: 0.7293493747711182\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 824/1200 GAN loss: 0.7162703275680542\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 825/1200 GAN loss: 0.7261989712715149\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 826/1200 GAN loss: 0.7491292953491211\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 827/1200 GAN loss: 0.7302889823913574\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 828/1200 GAN loss: 0.7580008506774902\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 829/1200 GAN loss: 0.7428104877471924\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 830/1200 GAN loss: 0.7532234191894531\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 831/1200 GAN loss: 0.7548500895500183\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 832/1200 GAN loss: 0.7430344223976135\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 833/1200 GAN loss: 0.7540103793144226\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 834/1200 GAN loss: 0.7494062185287476\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 835/1200 GAN loss: 0.7515493631362915\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 836/1200 GAN loss: 0.7518143057823181\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 837/1200 GAN loss: 0.7273602485656738\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 838/1200 GAN loss: 0.7232427000999451\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 839/1200 GAN loss: 0.7234352827072144\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 840/1200 GAN loss: 0.7372369766235352\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 841/1200 GAN loss: 0.7525472640991211\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 842/1200 GAN loss: 0.7708556056022644\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 843/1200 GAN loss: 0.7682381272315979\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 844/1200 GAN loss: 0.7517061829566956\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 845/1200 GAN loss: 0.7329963445663452\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 846/1200 GAN loss: 0.7280896902084351\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 847/1200 GAN loss: 0.7220551371574402\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 848/1200 GAN loss: 0.718031644821167\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 849/1200 GAN loss: 0.7307038307189941\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 850/1200 GAN loss: 0.7370951175689697\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 851/1200 GAN loss: 0.7540135383605957\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 852/1200 GAN loss: 0.7607226371765137\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 853/1200 GAN loss: 0.7664271593093872\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 854/1200 GAN loss: 0.745060384273529\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 855/1200 GAN loss: 0.7339102029800415\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 856/1200 GAN loss: 0.6959516406059265\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 857/1200 GAN loss: 0.6926960349082947\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 858/1200 GAN loss: 0.6997412443161011\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 859/1200 GAN loss: 0.7189662456512451\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 860/1200 GAN loss: 0.7226202487945557\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 861/1200 GAN loss: 0.7226194143295288\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 862/1200 GAN loss: 0.7274751663208008\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 863/1200 GAN loss: 0.7317649126052856\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 864/1200 GAN loss: 0.7306292057037354\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 865/1200 GAN loss: 0.7253001928329468\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 866/1200 GAN loss: 0.7293279767036438\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 867/1200 GAN loss: 0.7170689702033997\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 868/1200 GAN loss: 0.7117986083030701\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 869/1200 GAN loss: 0.7209327816963196\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 870/1200 GAN loss: 0.7193624973297119\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 871/1200 GAN loss: 0.7247059941291809\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 872/1200 GAN loss: 0.72157883644104\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 873/1200 GAN loss: 0.7181016206741333\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 874/1200 GAN loss: 0.7192299962043762\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 875/1200 GAN loss: 0.7213497161865234\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 876/1200 GAN loss: 0.7251196503639221\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 877/1200 GAN loss: 0.7334564924240112\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 878/1200 GAN loss: 0.7216359376907349\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 879/1200 GAN loss: 0.7302407026290894\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 880/1200 GAN loss: 0.7369099855422974\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 881/1200 GAN loss: 0.7355377674102783\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 882/1200 GAN loss: 0.7439550757408142\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 883/1200 GAN loss: 0.718212902545929\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 884/1200 GAN loss: 0.7138710618019104\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 885/1200 GAN loss: 0.7118610739707947\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 886/1200 GAN loss: 0.722274124622345\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 887/1200 GAN loss: 0.7350260019302368\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 888/1200 GAN loss: 0.7276633381843567\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 889/1200 GAN loss: 0.7285975813865662\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 890/1200 GAN loss: 0.7193829417228699\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 891/1200 GAN loss: 0.713473916053772\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 892/1200 GAN loss: 0.7133338451385498\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 893/1200 GAN loss: 0.7167972326278687\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 894/1200 GAN loss: 0.7209158539772034\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 895/1200 GAN loss: 0.7257611751556396\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 896/1200 GAN loss: 0.7207249999046326\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 897/1200 GAN loss: 0.7206850051879883\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 898/1200 GAN loss: 0.7211016416549683\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 899/1200 GAN loss: 0.7174118161201477\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 900/1200 GAN loss: 0.6998007297515869\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 901/1200 GAN loss: 0.6979312896728516\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 902/1200 GAN loss: 0.7052582502365112\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 903/1200 GAN loss: 0.7028746008872986\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 904/1200 GAN loss: 0.7160941362380981\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 905/1200 GAN loss: 0.7185105085372925\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 906/1200 GAN loss: 0.7201502323150635\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 907/1200 GAN loss: 0.7137422561645508\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 908/1200 GAN loss: 0.714840292930603\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 909/1200 GAN loss: 0.7208650708198547\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 910/1200 GAN loss: 0.7040690779685974\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 911/1200 GAN loss: 0.7053142189979553\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 912/1200 GAN loss: 0.7092733979225159\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 913/1200 GAN loss: 0.7114439606666565\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 914/1200 GAN loss: 0.7169018983840942\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 915/1200 GAN loss: 0.7180262804031372\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 916/1200 GAN loss: 0.718124270439148\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 917/1200 GAN loss: 0.7167215943336487\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 918/1200 GAN loss: 0.7149357795715332\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 919/1200 GAN loss: 0.708831250667572\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 920/1200 GAN loss: 0.7128003835678101\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 921/1200 GAN loss: 0.7064344882965088\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 922/1200 GAN loss: 0.7009618282318115\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 923/1200 GAN loss: 0.6992597579956055\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 924/1200 GAN loss: 0.6988201141357422\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 925/1200 GAN loss: 0.7027121782302856\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 926/1200 GAN loss: 0.7095702290534973\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 927/1200 GAN loss: 0.7258892059326172\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 928/1200 GAN loss: 0.7233608365058899\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 929/1200 GAN loss: 0.7201200127601624\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 930/1200 GAN loss: 0.7146206498146057\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 931/1200 GAN loss: 0.715130090713501\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 932/1200 GAN loss: 0.7031984329223633\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 933/1200 GAN loss: 0.7110884189605713\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 934/1200 GAN loss: 0.706590473651886\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 935/1200 GAN loss: 0.6959163546562195\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 936/1200 GAN loss: 0.7034580707550049\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 937/1200 GAN loss: 0.7083746194839478\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 938/1200 GAN loss: 0.7089554071426392\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 939/1200 GAN loss: 0.7104216814041138\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 940/1200 GAN loss: 0.7133357524871826\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 941/1200 GAN loss: 0.7188137769699097\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 942/1200 GAN loss: 0.7145019173622131\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 943/1200 GAN loss: 0.7073469161987305\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 944/1200 GAN loss: 0.7032510638237\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 945/1200 GAN loss: 0.6975207924842834\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 946/1200 GAN loss: 0.7046560049057007\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 947/1200 GAN loss: 0.7066870927810669\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 948/1200 GAN loss: 0.7064253687858582\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 949/1200 GAN loss: 0.7115869522094727\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 950/1200 GAN loss: 0.7207340002059937\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 951/1200 GAN loss: 0.718055248260498\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 952/1200 GAN loss: 0.7076458930969238\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 953/1200 GAN loss: 0.6996152400970459\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 954/1200 GAN loss: 0.700218141078949\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 955/1200 GAN loss: 0.6964115500450134\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 956/1200 GAN loss: 0.7000107765197754\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 957/1200 GAN loss: 0.7027319073677063\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 958/1200 GAN loss: 0.7051113247871399\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 959/1200 GAN loss: 0.7016251087188721\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 960/1200 GAN loss: 0.701381504535675\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 961/1200 GAN loss: 0.7025931477546692\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 962/1200 GAN loss: 0.7048218250274658\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 963/1200 GAN loss: 0.71121746301651\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 964/1200 GAN loss: 0.7103054523468018\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 965/1200 GAN loss: 0.706125020980835\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 966/1200 GAN loss: 0.7030412554740906\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 967/1200 GAN loss: 0.6994417905807495\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 968/1200 GAN loss: 0.7051701545715332\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 969/1200 GAN loss: 0.710145890712738\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 970/1200 GAN loss: 0.7152376174926758\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 971/1200 GAN loss: 0.7091015577316284\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 972/1200 GAN loss: 0.7012614011764526\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 973/1200 GAN loss: 0.6993530988693237\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 974/1200 GAN loss: 0.696582555770874\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 975/1200 GAN loss: 0.6945400238037109\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 976/1200 GAN loss: 0.693073034286499\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 977/1200 GAN loss: 0.6949310302734375\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 978/1200 GAN loss: 0.7006844282150269\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 979/1200 GAN loss: 0.7056746482849121\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 980/1200 GAN loss: 0.7054144144058228\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 981/1200 GAN loss: 0.7089731693267822\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 982/1200 GAN loss: 0.7131776809692383\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 983/1200 GAN loss: 0.7314783334732056\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 984/1200 GAN loss: 0.7356386184692383\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 985/1200 GAN loss: 0.7236097455024719\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 986/1200 GAN loss: 0.7111712694168091\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 987/1200 GAN loss: 0.6892648935317993\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 988/1200 GAN loss: 0.6828498244285583\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 989/1200 GAN loss: 0.6895449161529541\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 990/1200 GAN loss: 0.7028318047523499\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 991/1200 GAN loss: 0.7164719104766846\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 992/1200 GAN loss: 0.7368271946907043\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 993/1200 GAN loss: 0.7259730100631714\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 994/1200 GAN loss: 0.7148429751396179\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 995/1200 GAN loss: 0.7035245895385742\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 996/1200 GAN loss: 0.7037779092788696\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 997/1200 GAN loss: 0.6923351287841797\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 998/1200 GAN loss: 0.6955258250236511\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 999/1200 GAN loss: 0.7023220062255859\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1000/1200 GAN loss: 0.7596027255058289\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1001/1200 GAN loss: 0.7750356793403625\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1002/1200 GAN loss: 0.7606763243675232\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1003/1200 GAN loss: 0.7380738854408264\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1004/1200 GAN loss: 0.6961767673492432\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1005/1200 GAN loss: 0.678864598274231\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1006/1200 GAN loss: 0.6814988851547241\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1007/1200 GAN loss: 0.7011181116104126\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1008/1200 GAN loss: 0.7283244729042053\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1009/1200 GAN loss: 0.7455353140830994\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1010/1200 GAN loss: 0.7405768036842346\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1011/1200 GAN loss: 0.7299260497093201\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1012/1200 GAN loss: 0.7110673189163208\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1013/1200 GAN loss: 0.7019578814506531\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1014/1200 GAN loss: 0.700960099697113\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1015/1200 GAN loss: 0.7037162780761719\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1016/1200 GAN loss: 0.7170416116714478\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1017/1200 GAN loss: 0.7277514934539795\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1018/1200 GAN loss: 0.7245132923126221\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1019/1200 GAN loss: 0.7185207605361938\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1020/1200 GAN loss: 0.7051637172698975\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1021/1200 GAN loss: 0.7050984501838684\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1022/1200 GAN loss: 0.7039185166358948\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1023/1200 GAN loss: 0.699967086315155\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1024/1200 GAN loss: 0.696668267250061\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1025/1200 GAN loss: 0.7057832479476929\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1026/1200 GAN loss: 0.721583366394043\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1027/1200 GAN loss: 0.7299097180366516\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1028/1200 GAN loss: 0.7301987409591675\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1029/1200 GAN loss: 0.7238751649856567\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1030/1200 GAN loss: 0.7129793167114258\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1031/1200 GAN loss: 0.7066354751586914\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1032/1200 GAN loss: 0.6982800960540771\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1033/1200 GAN loss: 0.6989384889602661\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1034/1200 GAN loss: 0.7095341682434082\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1035/1200 GAN loss: 0.7063131332397461\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1036/1200 GAN loss: 0.711280882358551\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1037/1200 GAN loss: 0.706767737865448\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1038/1200 GAN loss: 0.7114092111587524\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1039/1200 GAN loss: 0.709470272064209\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1040/1200 GAN loss: 0.7124226689338684\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1041/1200 GAN loss: 0.7110518217086792\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1042/1200 GAN loss: 0.7086813449859619\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1043/1200 GAN loss: 0.7055490016937256\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1044/1200 GAN loss: 0.7222781777381897\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1045/1200 GAN loss: 0.7285976409912109\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1046/1200 GAN loss: 0.7284872531890869\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1047/1200 GAN loss: 0.7202993631362915\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1048/1200 GAN loss: 0.7140304446220398\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1049/1200 GAN loss: 0.7090951204299927\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1050/1200 GAN loss: 0.7026376724243164\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1051/1200 GAN loss: 0.7052079439163208\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1052/1200 GAN loss: 0.7023441791534424\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1053/1200 GAN loss: 0.7093645334243774\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1054/1200 GAN loss: 0.7089318037033081\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1055/1200 GAN loss: 0.7113025188446045\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1056/1200 GAN loss: 0.7128661274909973\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1057/1200 GAN loss: 0.7064933776855469\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1058/1200 GAN loss: 0.7043728232383728\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1059/1200 GAN loss: 0.7042382955551147\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1060/1200 GAN loss: 0.7011280059814453\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1061/1200 GAN loss: 0.7057880163192749\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1062/1200 GAN loss: 0.7123928070068359\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1063/1200 GAN loss: 0.7154446244239807\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1064/1200 GAN loss: 0.7177647948265076\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1065/1200 GAN loss: 0.716354250907898\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1066/1200 GAN loss: 0.7128221988677979\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1067/1200 GAN loss: 0.7127383947372437\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1068/1200 GAN loss: 0.7055197954177856\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1069/1200 GAN loss: 0.6963039040565491\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1070/1200 GAN loss: 0.6958970427513123\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1071/1200 GAN loss: 0.7042835354804993\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1072/1200 GAN loss: 0.7129435539245605\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1073/1200 GAN loss: 0.7139449119567871\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1074/1200 GAN loss: 0.7080453038215637\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1075/1200 GAN loss: 0.706567645072937\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1076/1200 GAN loss: 0.7064456939697266\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1077/1200 GAN loss: 0.7051828503608704\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1078/1200 GAN loss: 0.704953134059906\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1079/1200 GAN loss: 0.7094686031341553\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1080/1200 GAN loss: 0.707483172416687\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1081/1200 GAN loss: 0.7062095999717712\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1082/1200 GAN loss: 0.71234130859375\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1083/1200 GAN loss: 0.7162483930587769\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1084/1200 GAN loss: 0.7221437692642212\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1085/1200 GAN loss: 0.7179456949234009\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1086/1200 GAN loss: 0.7146565318107605\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1087/1200 GAN loss: 0.7107032537460327\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1088/1200 GAN loss: 0.704359769821167\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1089/1200 GAN loss: 0.7035211324691772\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1090/1200 GAN loss: 0.7028506994247437\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1091/1200 GAN loss: 0.708177924156189\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1092/1200 GAN loss: 0.7061406373977661\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1093/1200 GAN loss: 0.7079979777336121\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1094/1200 GAN loss: 0.7091197967529297\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1095/1200 GAN loss: 0.7098733186721802\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1096/1200 GAN loss: 0.7088533043861389\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1097/1200 GAN loss: 0.7102696895599365\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1098/1200 GAN loss: 0.7071918845176697\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1099/1200 GAN loss: 0.707218587398529\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1100/1200 GAN loss: 0.7077040672302246\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1101/1200 GAN loss: 0.7061553597450256\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1102/1200 GAN loss: 0.7079241275787354\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1103/1200 GAN loss: 0.7119584083557129\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1104/1200 GAN loss: 0.7129755616188049\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1105/1200 GAN loss: 0.7092664837837219\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1106/1200 GAN loss: 0.7078494429588318\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1107/1200 GAN loss: 0.7092239856719971\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1108/1200 GAN loss: 0.7106664776802063\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1109/1200 GAN loss: 0.7075693011283875\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1110/1200 GAN loss: 0.7107378840446472\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1111/1200 GAN loss: 0.7027265429496765\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1112/1200 GAN loss: 0.7036172151565552\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1113/1200 GAN loss: 0.7053517699241638\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1114/1200 GAN loss: 0.7094271183013916\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1115/1200 GAN loss: 0.7084897756576538\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1116/1200 GAN loss: 0.7087105512619019\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1117/1200 GAN loss: 0.7044039964675903\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1118/1200 GAN loss: 0.6986652612686157\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1119/1200 GAN loss: 0.6958814263343811\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1120/1200 GAN loss: 0.7019684314727783\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1121/1200 GAN loss: 0.7092869281768799\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1122/1200 GAN loss: 0.7124425172805786\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1123/1200 GAN loss: 0.7095993161201477\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1124/1200 GAN loss: 0.7091413736343384\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1125/1200 GAN loss: 0.7040496468544006\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1126/1200 GAN loss: 0.7024896740913391\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1127/1200 GAN loss: 0.7026003003120422\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1128/1200 GAN loss: 0.7026136517524719\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1129/1200 GAN loss: 0.702764630317688\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1130/1200 GAN loss: 0.7021383047103882\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1131/1200 GAN loss: 0.7030839323997498\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1132/1200 GAN loss: 0.7012056708335876\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1133/1200 GAN loss: 0.7018241882324219\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1134/1200 GAN loss: 0.7019511461257935\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1135/1200 GAN loss: 0.7041430473327637\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1136/1200 GAN loss: 0.7049407362937927\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1137/1200 GAN loss: 0.7051509022712708\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1138/1200 GAN loss: 0.7058151960372925\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1139/1200 GAN loss: 0.7053443193435669\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1140/1200 GAN loss: 0.7022683620452881\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1141/1200 GAN loss: 0.7032426595687866\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1142/1200 GAN loss: 0.7088467478752136\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1143/1200 GAN loss: 0.710820734500885\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1144/1200 GAN loss: 0.7148411870002747\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1145/1200 GAN loss: 0.7116649746894836\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1146/1200 GAN loss: 0.7072304487228394\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1147/1200 GAN loss: 0.7074123024940491\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1148/1200 GAN loss: 0.706357479095459\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1149/1200 GAN loss: 0.7021458148956299\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1150/1200 GAN loss: 0.7019590139389038\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1151/1200 GAN loss: 0.7015602588653564\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1152/1200 GAN loss: 0.706179141998291\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1153/1200 GAN loss: 0.709730863571167\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1154/1200 GAN loss: 0.7056254148483276\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1155/1200 GAN loss: 0.7042700052261353\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1156/1200 GAN loss: 0.7035249471664429\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1157/1200 GAN loss: 0.7014021277427673\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1158/1200 GAN loss: 0.6993834972381592\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1159/1200 GAN loss: 0.7000200748443604\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1160/1200 GAN loss: 0.7013843059539795\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1161/1200 GAN loss: 0.7025278806686401\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1162/1200 GAN loss: 0.7039949893951416\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1163/1200 GAN loss: 0.7059950828552246\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1164/1200 GAN loss: 0.7062544822692871\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1165/1200 GAN loss: 0.7052828073501587\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1166/1200 GAN loss: 0.7041597366333008\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1167/1200 GAN loss: 0.702556312084198\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1168/1200 GAN loss: 0.7020682692527771\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1169/1200 GAN loss: 0.6971753239631653\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1170/1200 GAN loss: 0.6985814571380615\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1171/1200 GAN loss: 0.6991336345672607\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1172/1200 GAN loss: 0.7012882828712463\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1173/1200 GAN loss: 0.7036395072937012\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1174/1200 GAN loss: 0.700537919998169\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1175/1200 GAN loss: 0.7042372822761536\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1176/1200 GAN loss: 0.7038785815238953\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1177/1200 GAN loss: 0.7049579620361328\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1178/1200 GAN loss: 0.7066014409065247\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1179/1200 GAN loss: 0.7074946165084839\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1180/1200 GAN loss: 0.7014616131782532\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1181/1200 GAN loss: 0.6993964910507202\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1182/1200 GAN loss: 0.693555474281311\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1183/1200 GAN loss: 0.6944904327392578\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1184/1200 GAN loss: 0.6964826583862305\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1185/1200 GAN loss: 0.6960654854774475\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1186/1200 GAN loss: 0.699006199836731\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1187/1200 GAN loss: 0.7008320093154907\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1188/1200 GAN loss: 0.7006557583808899\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1189/1200 GAN loss: 0.7009527087211609\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1190/1200 GAN loss: 0.7010678052902222\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1191/1200 GAN loss: 0.7010185122489929\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1192/1200 GAN loss: 0.7002825736999512\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1193/1200 GAN loss: 0.7015324831008911\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1194/1200 GAN loss: 0.6957631707191467\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1195/1200 GAN loss: 0.693472146987915\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1196/1200 GAN loss: 0.6946475505828857\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1197/1200 GAN loss: 0.6944913864135742\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1198/1200 GAN loss: 0.701262354850769\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1199/1200 GAN loss: 0.7044317722320557\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1200/1200 GAN loss: 0.7054157257080078\n"
     ]
    }
   ],
   "source": [
    "train(generator, discriminator, GAN, dataset_numpy_scaled, epochs=1200, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5b52e92b-0808-410d-9600-99fedbe8ab52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img0.jpeg',\n",
       " 'img1000.jpeg',\n",
       " 'img1199.jpeg',\n",
       " 'img200.jpeg',\n",
       " 'img400.jpeg',\n",
       " 'img600.jpeg',\n",
       " 'img800.jpeg']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path ='./data/data/1__GAN/'\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d0f47196-6124-4ea3-ab41-7c921550a027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = [np.asarray(Image.open(path+imgname)) for imgname in os.listdir(path)]\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "1f53ef2c-f847-4f37-a7c8-107ff0f63e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Füge optional weitere Inhalte zu.\n",
    "fig, axs = plt.subplots(1, 7, figsize=(10, 6))\n",
    "fig.tight_layout(pad=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "img_names = os.listdir(path)\n",
    "\n",
    "\n",
    "for i in range(len(images)):\n",
    "    axs[i].set_title(img_names[i])\n",
    "    axs[i].imshow(images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1cb142-38d2-46b5-ad68-8e3061174c94",
   "metadata": {},
   "source": [
    "<h1>Zweites Beispiel - 2 Verschiedene Formen</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8efc500-2565-4951-b551-c967e1d654db",
   "metadata": {},
   "source": [
    "Diesmal wollen wir 2 Formen und ein größeres Netz nutzen. Das Vorgehen ist ähnlich aber Umfangreicher.\n",
    "\n",
    "Um ein GAN zu erstellen, das verschiedene Klassen unterscheidet, nutzen wir Embeddings, um den Input des Generators zu verändern.<br>\n",
    "Zusätzlich können wir Dropouts nutzen. Bei komplexeren Formen und größeren Netzen nutzen wir auch CNN Layers. Weitere ist optional.\n",
    "- Hier wieder als ANN. CNN ist üblich bei GANs.\n",
    "- Es ist üblich, das man für das Training mehrere Klassen nutzt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc97c06-e37b-4215-8047-29bcd3c339db",
   "metadata": {},
   "source": [
    "<h2>Dataset</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5764b1e-bdc4-4523-b996-90fd41491c09",
   "metadata": {},
   "source": [
    "Für den Versuch erstellen wir 2 Formen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "80c16e8b-4e8e-40df-a8b3-3b7eebb70274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeichne Bild mit Numpy.\n",
    "def create_image_2(color:int=1) -> np.array:\n",
    "    image = np.zeros((20, 20))  # 2D Matrix, 20x20 Pixel.\n",
    "    # img [yloc, xloc]\n",
    "    image[1:17, 3]  = 1  \n",
    "    image[1:17, 4]  = 1  \n",
    "    image[2:10, 10] = 1  \n",
    "    image[2:10, 11] = 1  \n",
    "    image[9, 4:10]  = 1  \n",
    "    image[10, 4:12] = 1 \n",
    "    image[1, 4:17]  = 1  \n",
    "    image[2, 4:17]  = 1 \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aa68f50a-73d4-4561-ae5f-8bdd391defcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = create_image_2()\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(img)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcccc0f-b135-4b0f-9291-a66fe32f9042",
   "metadata": {},
   "source": [
    "Dann erstellen wir ein Encoding für die Labels als Input für das Embedding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "037209e8-058a-4bde-aecd-15e47e7191a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle Labels für Embeddings:\n",
    "# - Mit 0 und 1 soll die Klasse \"ausgewählt\" werden.\n",
    "form_labels    = ['Form A', 'Form B']\n",
    "encoded_labels = {'Form A':0, 'Form B': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eaa357ef-f893-46cd-b85d-14299496b448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle Dataset aus n-Samples \n",
    "def numpy_dataset(n:int):  # Shape A, Label 0\n",
    "    return np.array([create_image_2() for _ in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f0fea138-f0d4-4894-8126-f152273cf24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20, 20) (1000, 20, 20)\n"
     ]
    }
   ],
   "source": [
    "size = 1000  # n-Samples\n",
    "\n",
    "dataset_shape_A = numpy_dataset(  size)\n",
    "dataset_shape_B = np.array([create_image() for _ in range(size)])  # Shape L \n",
    "\n",
    "print(dataset_shape_A.shape, dataset_shape_B.shape )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9002a63d-1232-4e7c-a0ea-806429bef07b",
   "metadata": {},
   "source": [
    "plt.matshow(dataset_shape_A[0])  # Zeige Form. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8c8b0f2-69b5-4f27-b484-f639bd6a85a5",
   "metadata": {},
   "source": [
    "plt.matshow(dataset_shape_B[0])  # Zeige Form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4d5334d7-808d-466d-b901-efac094c956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape. # \n",
    "dataset_shape_A = dataset_shape_A.reshape(size, 20, 20, 1).astype('float')\n",
    "dataset_shape_B = dataset_shape_B.reshape(size, 20, 20, 1).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "de2a1448-f09c-4602-932b-f5b89a8b292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skaliere. #\n",
    "dataset_shape_A = ( dataset_shape_A - 0.5 ) / 0.5\n",
    "dataset_shape_B = ( dataset_shape_B - 0.5 ) / 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "98a57e5a-810a-472f-a795-882a28f71ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20, 1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_shape_A[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bf36ab1b-04c6-4681-9245-63bf7e19da49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20, 1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_shape_B[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "101c2119-0c5d-4f45-861d-18c6751cce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle Dataset mit A und B. \n",
    "dataset_shapes = []\n",
    "dataset_shapes.extend(dataset_shape_A)  # Label 0\n",
    "dataset_shapes.extend(dataset_shape_B)  # Label 1\n",
    "dataset_shapes = np.array(dataset_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e161d5a9-1e88-43a2-a516-61e038fec41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle Dataset Labels # \n",
    "dataset_labels = np.asarray([encoded_labels[label]   for label in form_labels  for _ in range(size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "35fe85ed-1a11-4c64-af46-3e606e549a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_labels) == size*2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5580cbfe-8e32-4925-8763-09435da939de",
   "metadata": {},
   "source": [
    "Das ist eine Möglichkeit Datasets zu erstellen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc7f32-53cc-4c69-b057-00925d9f437d",
   "metadata": {},
   "source": [
    "<h2>Erstelle Model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a0f207-5521-4b61-8520-1dd657f0ddec",
   "metadata": {},
   "source": [
    "Diesmal hat das Model Embeddings, um mehrere Klassen abzudecken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "966624c5-563c-490e-8eb2-26d6188e5991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle Generator für Bildgenerierung # \n",
    "def create_generator(num_classes: int = 2):\n",
    "    # Hier Nutzen wir zusätzlich Embeddings Layers.\n",
    "\n",
    "    noise_input = tf.keras.Input(shape=(100,))  # Startbild: 100 Pixel Vektor. \n",
    "    label_input = tf.keras.Input(shape=(1,), dtype='int32') # Klassen Label wie z. B. Form_A, Form_B als 0 und 1. \n",
    "    \n",
    "    label_embedding = tf.keras.layers.Embedding(input_dim=2, output_dim=100)(label_input)\n",
    "    label_embedding = tf.keras.layers.Flatten()(label_embedding)\n",
    "    model_input     = tf.keras.layers.multiply([noise_input, label_embedding])  # Multipliziere, damit haben die Labels direkten Einfluss.\n",
    "    \n",
    "    # --------- #\n",
    "    \"\"\" \n",
    "    gen_ann = tf.keras.Sequential()\n",
    "    gen_ann.add( tf.keras.layers.Dense(units=300, activation='relu'))\n",
    "    gen_ann.add( tf.keras.layers.BatchNormalization())\n",
    "    gen_ann.add( tf.keras.layers.Dense(units=500, activation='relu'))\n",
    "\n",
    "    \"\"\"\n",
    "    # Nutze andere Herangehensweise. \n",
    "    # - Dieser Ansatz funktioniert besser. \n",
    "    x = tf.keras.layers.Dense(units=300, activation='relu')(model_input)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(units=500, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(units=800, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = tf.keras.layers.Dense(units=450, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(units=20*20, activation='tanh')(x)\n",
    "    output = tf.keras.layers.Reshape((20, 20, 1))(x)\n",
    "   \n",
    "    return tf.keras.Model([noise_input, label_input], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "777602dd-60bb-41f6-860c-57ae4a1f56e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 99ms/step\n"
     ]
    }
   ],
   "source": [
    "# Teste, ob Aufbau funktioniert. \n",
    "generator = create_generator(2)\n",
    "noise     = np.random.normal(0, 1, (1, 100))\n",
    "\n",
    "fake_labels = np.random.randint(0, 2, 1)\n",
    "fake_images = generator.predict([noise, fake_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "35fedd6a-6b96-43ab-935c-36eb3c3a8eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator(num_classes: int = 2):\n",
    "    # Hier Nutzen wir zusätzlich Embeddings.\n",
    "    \n",
    "    image_input = tf.keras.Input(shape=(20, 20, 1))  # Bild als Input\n",
    "    label_input = tf.keras.Input(shape=(1,), dtype='int32')  # Auch hier kommen die Labels zum Einsatz. \n",
    "    \n",
    "    label_embedding = tf.keras.layers.Embedding(input_dim=2, output_dim=20*20)(label_input)\n",
    "    label_embedding = tf.keras.layers.Flatten()(label_embedding)\n",
    "    label_embedding = tf.keras.layers.Reshape((20, 20, 1))(label_embedding) \n",
    "    # Durch Konkatenation: Passt Bild auch zum Label? \n",
    "    model_input = tf.keras.layers.concatenate([image_input, label_embedding])   \n",
    "    # --------- #\n",
    "    x = tf.keras.layers.Flatten(input_shape=(20,20, 1))(model_input)\n",
    "    x = tf.keras.layers.Dense(500, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(700, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(550, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(320, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(150, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(75, activation='relu')(x)\n",
    "    output =  tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "   \n",
    "    return tf.keras.Model([image_input, label_input], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2e2e92ab-651e-4c0c-be02-a215f9f58b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4998795]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Teste, ob Aufbau funktioniert. \n",
    "discriminator = create_discriminator()\n",
    "\n",
    "generator = create_generator(2)\n",
    "noise     = np.random.normal(0, 1, (1, 100))\n",
    "\n",
    "fake_labels = np.random.randint(0, 2, 1)\n",
    "fake_images = generator.predict([noise, fake_labels])\n",
    "\n",
    "discriminator.predict([fake_images, fake_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "27ae3916-2621-40d6-86e9-d1603238d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = create_discriminator()\n",
    "discriminator.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss      = 'binary_crossentropy',\n",
    "    metrics   = 'accuracy'\n",
    ")\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Erstelle GAN # \n",
    "generator = create_generator()\n",
    "gan_input   = tf.keras.layers.Input(shape=(100,))  \n",
    "label_input = tf.keras.Input(shape=(1,), dtype='int32')\n",
    "\n",
    "generated_image = generator([gan_input, label_input])\n",
    "gan_output = discriminator([generated_image, label_input])\n",
    "\n",
    "GAN = tf.keras.Model([gan_input, label_input], gan_output)\n",
    "GAN.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "GAN.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7982ad7a-d419-4e86-871a-0965d5e96c6c",
   "metadata": {},
   "source": [
    "<h2>Training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3e42fc3f-19f8-45ea-a511-269ff3a2b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsschleife #\n",
    "# - Sehr ähnlicher Aufbau mit kleinen Unterschieden. \n",
    "def train(generator, discriminator, gan, train_images, train_labels, epochs, batch_size, num_classes:int=2):\n",
    "    \n",
    "    half_batch = int(batch_size / 2)  # Ausgleich an Samples. \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        #  Discriminator #\n",
    "        idx = np.random.randint(0, train_images.shape[0], half_batch)  # Index für Img und Label. \n",
    "        real_images = train_images[idx]  # Wie bisher.\n",
    "        real_labels = train_labels[idx]  # Nehme Labels dazu. \n",
    "        noise       = np.random.normal(0, 1, (half_batch, 100))  # Startbild.\n",
    "        fake_labels = np.random.randint(0, num_classes, half_batch)  # Wie Bisher.\n",
    "        fake_images = generator.predict([noise, fake_labels])  # Nehme Labels dazu. \n",
    "\n",
    "        loss_real = discriminator.train_on_batch([real_images, real_labels], np.ones(  (half_batch, 1)))  # Wie bisher\n",
    "        loss_fake = discriminator.train_on_batch([fake_images, fake_labels], np.zeros( (half_batch, 1)))  # Wie bisher.\n",
    "        d_loss = 0.5 * np.add(loss_real, loss_fake)  # Wie bisher.\n",
    "\n",
    "        # Generator #\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))  # Startbild\n",
    "        labels= np.random.randint(0, num_classes, batch_size)  # Labels\n",
    "        y = np.ones((batch_size, 1))\n",
    "        g_loss = gan.train_on_batch([noise, labels], y)\n",
    "\n",
    "        # Manuelle Ausgabe.:\n",
    "        print(f\"Epoche: {epoch + 1}/{epochs} GAN loss: {g_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "864126db-3b01-4d95-9d45-655867fb50b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 104ms/step\n",
      "Epoche: 1/1400 GAN loss: 0.4302443861961365\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 2/1400 GAN loss: 0.23123013973236084\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 3/1400 GAN loss: 0.18155628442764282\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 4/1400 GAN loss: 0.18626417219638824\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 5/1400 GAN loss: 0.18449760973453522\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 6/1400 GAN loss: 0.26186323165893555\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 7/1400 GAN loss: 0.40292102098464966\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 8/1400 GAN loss: 0.7289671897888184\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 9/1400 GAN loss: 1.90779447555542\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 10/1400 GAN loss: 3.853708505630493\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 11/1400 GAN loss: 7.616558074951172\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 12/1400 GAN loss: 1.4439494609832764\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 13/1400 GAN loss: 0.01294360589236021\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 14/1400 GAN loss: 0.0007101292721927166\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 15/1400 GAN loss: 0.0063783954828977585\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 16/1400 GAN loss: 0.08619379997253418\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 17/1400 GAN loss: 0.036987051367759705\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 18/1400 GAN loss: 0.5942601561546326\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 19/1400 GAN loss: 0.9487122297286987\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 20/1400 GAN loss: 2.124678373336792\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 21/1400 GAN loss: 3.522139549255371\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 22/1400 GAN loss: 3.287440299987793\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 23/1400 GAN loss: 3.541015148162842\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 24/1400 GAN loss: 5.168954849243164\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 25/1400 GAN loss: 6.350943088531494\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 26/1400 GAN loss: 7.171870231628418\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 27/1400 GAN loss: 5.828801155090332\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 28/1400 GAN loss: 8.079730987548828\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 29/1400 GAN loss: 8.570192337036133\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 30/1400 GAN loss: 10.606535911560059\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 31/1400 GAN loss: 11.019841194152832\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 32/1400 GAN loss: 10.625641822814941\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 33/1400 GAN loss: 12.126440048217773\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 34/1400 GAN loss: 11.047658920288086\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 35/1400 GAN loss: 11.285358428955078\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 36/1400 GAN loss: 10.944944381713867\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 37/1400 GAN loss: 12.657486915588379\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 38/1400 GAN loss: 12.389188766479492\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 39/1400 GAN loss: 13.385335922241211\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 40/1400 GAN loss: 7.584259510040283\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 41/1400 GAN loss: 5.163905143737793\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 42/1400 GAN loss: 3.4819400310516357\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 43/1400 GAN loss: 4.13353157043457\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 44/1400 GAN loss: 4.094311714172363\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 45/1400 GAN loss: 5.263805389404297\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 46/1400 GAN loss: 6.7325439453125\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 47/1400 GAN loss: 6.949418067932129\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 48/1400 GAN loss: 4.725765228271484\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 49/1400 GAN loss: 3.538722515106201\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 50/1400 GAN loss: 3.13767147064209\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 51/1400 GAN loss: 2.247286796569824\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 52/1400 GAN loss: 2.0219359397888184\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 53/1400 GAN loss: 2.570678472518921\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 54/1400 GAN loss: 3.7022602558135986\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 55/1400 GAN loss: 3.7434253692626953\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 56/1400 GAN loss: 5.469400405883789\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 57/1400 GAN loss: 4.107707977294922\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 58/1400 GAN loss: 5.86143684387207\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 59/1400 GAN loss: 6.807527542114258\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 60/1400 GAN loss: 6.750544548034668\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 61/1400 GAN loss: 7.151080131530762\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 62/1400 GAN loss: 11.352234840393066\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 63/1400 GAN loss: 10.150613784790039\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 64/1400 GAN loss: 13.916749954223633\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 65/1400 GAN loss: 14.633979797363281\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 66/1400 GAN loss: 10.392830848693848\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 67/1400 GAN loss: 17.34239959716797\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 68/1400 GAN loss: 16.02077293395996\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 69/1400 GAN loss: 17.62373924255371\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 70/1400 GAN loss: 19.480518341064453\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 71/1400 GAN loss: 27.91250991821289\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 72/1400 GAN loss: 13.897064208984375\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 73/1400 GAN loss: 14.994983673095703\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 74/1400 GAN loss: 9.281891822814941\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 75/1400 GAN loss: 10.009568214416504\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 76/1400 GAN loss: 13.287829399108887\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 77/1400 GAN loss: 17.69721221923828\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 78/1400 GAN loss: 21.262266159057617\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 79/1400 GAN loss: 21.207351684570312\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 80/1400 GAN loss: 18.821063995361328\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 81/1400 GAN loss: 17.03759002685547\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 82/1400 GAN loss: 15.075837135314941\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 83/1400 GAN loss: 13.612411499023438\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 84/1400 GAN loss: 9.405237197875977\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 85/1400 GAN loss: 10.706951141357422\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 86/1400 GAN loss: 11.059402465820312\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 87/1400 GAN loss: 14.200843811035156\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 88/1400 GAN loss: 14.131599426269531\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 89/1400 GAN loss: 18.785808563232422\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 90/1400 GAN loss: 16.441425323486328\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 91/1400 GAN loss: 17.166330337524414\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 92/1400 GAN loss: 16.492225646972656\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 93/1400 GAN loss: 19.45113754272461\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 94/1400 GAN loss: 17.57184410095215\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 95/1400 GAN loss: 16.55664825439453\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 96/1400 GAN loss: 11.96597671508789\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 97/1400 GAN loss: 16.55691909790039\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 98/1400 GAN loss: 15.314377784729004\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 99/1400 GAN loss: 15.895051956176758\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 100/1400 GAN loss: 19.634231567382812\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 101/1400 GAN loss: 20.068992614746094\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 102/1400 GAN loss: 21.663345336914062\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 103/1400 GAN loss: 21.828582763671875\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 104/1400 GAN loss: 24.038257598876953\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 105/1400 GAN loss: 15.41988468170166\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 106/1400 GAN loss: 32.258079528808594\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 107/1400 GAN loss: 32.85026550292969\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 108/1400 GAN loss: 28.679737091064453\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 109/1400 GAN loss: 21.094091415405273\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 110/1400 GAN loss: 17.94869613647461\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 111/1400 GAN loss: 14.14236831665039\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 112/1400 GAN loss: 10.76424503326416\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 113/1400 GAN loss: 7.636282920837402\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 114/1400 GAN loss: 6.896426200866699\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 115/1400 GAN loss: 6.254424095153809\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 116/1400 GAN loss: 4.2094502449035645\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 117/1400 GAN loss: 3.6539461612701416\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 118/1400 GAN loss: 6.775418758392334\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 119/1400 GAN loss: 2.6066370010375977\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 120/1400 GAN loss: 1.5677106380462646\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 121/1400 GAN loss: 5.720022201538086\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 122/1400 GAN loss: 3.2787466049194336\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 123/1400 GAN loss: 1.6841468811035156\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 124/1400 GAN loss: 2.0056498050689697\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 125/1400 GAN loss: 5.077363014221191\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 126/1400 GAN loss: 3.601466417312622\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 127/1400 GAN loss: 2.4568073749542236\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 128/1400 GAN loss: 2.7144856452941895\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 129/1400 GAN loss: 5.427190780639648\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 130/1400 GAN loss: 5.4727044105529785\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 131/1400 GAN loss: 9.998247146606445\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 132/1400 GAN loss: 9.168171882629395\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 133/1400 GAN loss: 6.165587425231934\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 134/1400 GAN loss: 8.576515197753906\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 135/1400 GAN loss: 6.151293754577637\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 136/1400 GAN loss: 12.417505264282227\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 137/1400 GAN loss: 12.521858215332031\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 138/1400 GAN loss: 15.042854309082031\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 139/1400 GAN loss: 0.6162223815917969\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 140/1400 GAN loss: 5.312684535980225\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 141/1400 GAN loss: 7.7146382331848145\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 142/1400 GAN loss: 9.405299186706543\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 143/1400 GAN loss: 13.35131549835205\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 144/1400 GAN loss: 22.567733764648438\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 145/1400 GAN loss: 11.280044555664062\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 146/1400 GAN loss: 9.55721664428711\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 147/1400 GAN loss: 6.353303909301758\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 148/1400 GAN loss: 5.032352924346924\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 149/1400 GAN loss: 22.820209503173828\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 150/1400 GAN loss: 29.936302185058594\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 151/1400 GAN loss: 34.76371765136719\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 152/1400 GAN loss: 33.34115219116211\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 153/1400 GAN loss: 35.68072509765625\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 154/1400 GAN loss: 35.29280090332031\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 155/1400 GAN loss: 31.574918746948242\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 156/1400 GAN loss: 29.680368423461914\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 157/1400 GAN loss: 25.594528198242188\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 158/1400 GAN loss: 27.174346923828125\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 159/1400 GAN loss: 25.876136779785156\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 160/1400 GAN loss: 37.6380615234375\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 161/1400 GAN loss: 23.863121032714844\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 162/1400 GAN loss: 30.15888214111328\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 163/1400 GAN loss: 27.119491577148438\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 164/1400 GAN loss: 32.347259521484375\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 165/1400 GAN loss: 33.42601013183594\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 166/1400 GAN loss: 32.47704315185547\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 167/1400 GAN loss: 37.620880126953125\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 168/1400 GAN loss: 32.71879577636719\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 169/1400 GAN loss: 37.77758026123047\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 170/1400 GAN loss: 37.48894500732422\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 171/1400 GAN loss: 35.041194915771484\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 172/1400 GAN loss: 28.088491439819336\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 173/1400 GAN loss: 32.390663146972656\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 174/1400 GAN loss: 29.346363067626953\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 175/1400 GAN loss: 26.868999481201172\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 176/1400 GAN loss: 24.47960662841797\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 177/1400 GAN loss: 29.880474090576172\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 178/1400 GAN loss: 31.864683151245117\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 179/1400 GAN loss: 25.18201446533203\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 180/1400 GAN loss: 19.554821014404297\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 181/1400 GAN loss: 24.058961868286133\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 182/1400 GAN loss: 24.559316635131836\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 183/1400 GAN loss: 19.767044067382812\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 184/1400 GAN loss: 18.621179580688477\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 185/1400 GAN loss: 18.568012237548828\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 186/1400 GAN loss: 25.1051025390625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 187/1400 GAN loss: 21.22987937927246\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 188/1400 GAN loss: 20.615100860595703\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 189/1400 GAN loss: 16.217554092407227\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 190/1400 GAN loss: 19.141279220581055\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 191/1400 GAN loss: 12.283614158630371\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 192/1400 GAN loss: 22.784326553344727\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 193/1400 GAN loss: 27.370716094970703\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 194/1400 GAN loss: 25.772876739501953\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 195/1400 GAN loss: 14.567268371582031\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 196/1400 GAN loss: 15.986526489257812\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 197/1400 GAN loss: 22.690513610839844\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 198/1400 GAN loss: 6.996827602386475\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 199/1400 GAN loss: 5.245804786682129\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 200/1400 GAN loss: 3.8479347229003906\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 201/1400 GAN loss: 4.604877471923828\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 202/1400 GAN loss: 5.602588653564453\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 203/1400 GAN loss: 6.493077754974365\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 204/1400 GAN loss: 8.399213790893555\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 205/1400 GAN loss: 4.8545942306518555\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 206/1400 GAN loss: 6.179898262023926\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 207/1400 GAN loss: 8.906457901000977\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 208/1400 GAN loss: 8.34416389465332\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 209/1400 GAN loss: 9.47364330291748\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 210/1400 GAN loss: 7.370079040527344\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 211/1400 GAN loss: 10.655414581298828\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 212/1400 GAN loss: 8.435600280761719\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 213/1400 GAN loss: 6.408063888549805\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 214/1400 GAN loss: 5.474884986877441\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 215/1400 GAN loss: 5.037870407104492\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 216/1400 GAN loss: 8.661550521850586\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 217/1400 GAN loss: 7.117850303649902\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 218/1400 GAN loss: 11.360878944396973\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 219/1400 GAN loss: 23.288990020751953\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 220/1400 GAN loss: 32.71106719970703\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 221/1400 GAN loss: 5.746906280517578\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 222/1400 GAN loss: 3.778287887573242\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 223/1400 GAN loss: 4.986633777618408\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 224/1400 GAN loss: 3.596909761428833\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 225/1400 GAN loss: 4.606741905212402\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 226/1400 GAN loss: 4.068869590759277\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 227/1400 GAN loss: 3.4227070808410645\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 228/1400 GAN loss: 4.020487308502197\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 229/1400 GAN loss: 2.9223482608795166\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 230/1400 GAN loss: 2.9514894485473633\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 231/1400 GAN loss: 3.2067368030548096\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 232/1400 GAN loss: 3.1196646690368652\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 233/1400 GAN loss: 2.1305251121520996\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 234/1400 GAN loss: 2.5849180221557617\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 235/1400 GAN loss: 4.047698020935059\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 236/1400 GAN loss: 1.6618571281433105\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 237/1400 GAN loss: 1.8232734203338623\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 238/1400 GAN loss: 1.8526039123535156\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 239/1400 GAN loss: 2.7630832195281982\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 240/1400 GAN loss: 3.4862380027770996\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 241/1400 GAN loss: 4.372115135192871\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 242/1400 GAN loss: 6.132260322570801\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 243/1400 GAN loss: 4.916362285614014\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 244/1400 GAN loss: 4.242417335510254\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 245/1400 GAN loss: 4.394186019897461\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 246/1400 GAN loss: 4.701981544494629\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 247/1400 GAN loss: 5.461516857147217\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 248/1400 GAN loss: 5.816259860992432\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 249/1400 GAN loss: 7.31103515625\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 250/1400 GAN loss: 8.402652740478516\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 251/1400 GAN loss: 9.095640182495117\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 252/1400 GAN loss: 8.863899230957031\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 253/1400 GAN loss: 9.604430198669434\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 254/1400 GAN loss: 10.11141586303711\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 255/1400 GAN loss: 10.644911766052246\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 256/1400 GAN loss: 9.483468055725098\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 257/1400 GAN loss: 11.37238883972168\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 258/1400 GAN loss: 10.39418888092041\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 259/1400 GAN loss: 10.680949211120605\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 260/1400 GAN loss: 9.98115348815918\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 261/1400 GAN loss: 9.388357162475586\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 262/1400 GAN loss: 8.375285148620605\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 263/1400 GAN loss: 9.627473831176758\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 264/1400 GAN loss: 8.026315689086914\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 265/1400 GAN loss: 9.60266399383545\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 266/1400 GAN loss: 9.253091812133789\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 267/1400 GAN loss: 11.293651580810547\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 268/1400 GAN loss: 13.216230392456055\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 269/1400 GAN loss: 13.034907341003418\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 270/1400 GAN loss: 13.515358924865723\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 271/1400 GAN loss: 14.702692031860352\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 272/1400 GAN loss: 16.632015228271484\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 273/1400 GAN loss: 15.41917610168457\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 274/1400 GAN loss: 13.727689743041992\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 275/1400 GAN loss: 14.186022758483887\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 276/1400 GAN loss: 16.564292907714844\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 277/1400 GAN loss: 16.024606704711914\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 278/1400 GAN loss: 17.868907928466797\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 279/1400 GAN loss: 15.651570320129395\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 280/1400 GAN loss: 10.681238174438477\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 281/1400 GAN loss: 12.158470153808594\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 282/1400 GAN loss: 8.550726890563965\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 283/1400 GAN loss: 11.221376419067383\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 284/1400 GAN loss: 16.236045837402344\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 285/1400 GAN loss: 12.620569229125977\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 286/1400 GAN loss: 8.982972145080566\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 287/1400 GAN loss: 9.675819396972656\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 288/1400 GAN loss: 8.202289581298828\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 289/1400 GAN loss: 7.011568546295166\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 290/1400 GAN loss: 7.266676902770996\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 291/1400 GAN loss: 6.935046195983887\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 292/1400 GAN loss: 7.8368072509765625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 293/1400 GAN loss: 9.06460952758789\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 294/1400 GAN loss: 10.441793441772461\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 295/1400 GAN loss: 11.132598876953125\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 296/1400 GAN loss: 11.377827644348145\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 297/1400 GAN loss: 11.708589553833008\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 298/1400 GAN loss: 11.139707565307617\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 299/1400 GAN loss: 11.088017463684082\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 300/1400 GAN loss: 11.585204124450684\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 301/1400 GAN loss: 10.690488815307617\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 302/1400 GAN loss: 9.890275955200195\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 303/1400 GAN loss: 10.66020679473877\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 304/1400 GAN loss: 10.84409236907959\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 305/1400 GAN loss: 12.317864418029785\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 306/1400 GAN loss: 12.07688045501709\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 307/1400 GAN loss: 15.36882209777832\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 308/1400 GAN loss: 12.179357528686523\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 309/1400 GAN loss: 10.10107421875\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 310/1400 GAN loss: 10.917495727539062\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 311/1400 GAN loss: 11.60188102722168\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 312/1400 GAN loss: 14.551538467407227\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 313/1400 GAN loss: 19.17937469482422\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 314/1400 GAN loss: 7.037428379058838\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 315/1400 GAN loss: 4.01915168762207\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 316/1400 GAN loss: 5.365755558013916\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 317/1400 GAN loss: 7.922158241271973\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 318/1400 GAN loss: 10.012463569641113\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 319/1400 GAN loss: 12.111459732055664\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 320/1400 GAN loss: 13.366008758544922\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 321/1400 GAN loss: 15.719085693359375\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 322/1400 GAN loss: 17.7137451171875\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 323/1400 GAN loss: 16.781837463378906\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 324/1400 GAN loss: 18.824539184570312\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 325/1400 GAN loss: 20.82476806640625\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 326/1400 GAN loss: 21.077571868896484\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 327/1400 GAN loss: 23.941619873046875\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 328/1400 GAN loss: 24.597293853759766\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 329/1400 GAN loss: 21.22689437866211\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 330/1400 GAN loss: 26.348766326904297\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 331/1400 GAN loss: 33.083274841308594\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 332/1400 GAN loss: 39.40258026123047\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 333/1400 GAN loss: 35.08668899536133\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 334/1400 GAN loss: 32.70377731323242\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 335/1400 GAN loss: 37.26538848876953\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 336/1400 GAN loss: 34.204315185546875\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 337/1400 GAN loss: 29.736021041870117\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 338/1400 GAN loss: 38.32847213745117\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 339/1400 GAN loss: 41.30882263183594\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 340/1400 GAN loss: 20.994972229003906\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 341/1400 GAN loss: 10.676082611083984\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 342/1400 GAN loss: 9.130451202392578\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 343/1400 GAN loss: 9.759068489074707\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 344/1400 GAN loss: 8.596025466918945\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 345/1400 GAN loss: 9.324466705322266\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 346/1400 GAN loss: 7.106316566467285\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 347/1400 GAN loss: 3.926304340362549\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 348/1400 GAN loss: 2.796048164367676\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 349/1400 GAN loss: 4.26100492477417\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 350/1400 GAN loss: 5.158904075622559\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 351/1400 GAN loss: 5.847291946411133\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 352/1400 GAN loss: 7.849797248840332\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 353/1400 GAN loss: 7.389141082763672\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 354/1400 GAN loss: 10.478789329528809\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 355/1400 GAN loss: 11.337133407592773\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 356/1400 GAN loss: 10.080547332763672\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 357/1400 GAN loss: 15.421794891357422\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 358/1400 GAN loss: 17.790393829345703\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 359/1400 GAN loss: 20.035812377929688\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 360/1400 GAN loss: 24.125213623046875\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 361/1400 GAN loss: 21.28660011291504\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 362/1400 GAN loss: 25.94099998474121\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 363/1400 GAN loss: 29.301023483276367\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 364/1400 GAN loss: 25.446678161621094\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 365/1400 GAN loss: 26.078895568847656\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 366/1400 GAN loss: 25.64182472229004\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 367/1400 GAN loss: 22.166385650634766\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 368/1400 GAN loss: 33.10101318359375\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 369/1400 GAN loss: 14.678971290588379\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 370/1400 GAN loss: 15.613792419433594\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 371/1400 GAN loss: 4.607694625854492\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 372/1400 GAN loss: 2.8843894004821777\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 373/1400 GAN loss: 1.5771082639694214\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 374/1400 GAN loss: 2.7564444541931152\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 375/1400 GAN loss: 1.047487735748291\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 376/1400 GAN loss: 0.34262189269065857\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 377/1400 GAN loss: 0.7663878798484802\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 378/1400 GAN loss: 0.41302400827407837\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 379/1400 GAN loss: 0.7002034187316895\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 380/1400 GAN loss: 2.1073598861694336\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 381/1400 GAN loss: 4.023953437805176\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 382/1400 GAN loss: 6.049759864807129\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 383/1400 GAN loss: 3.4557342529296875\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 384/1400 GAN loss: 9.064393997192383\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 385/1400 GAN loss: 6.836090087890625\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 386/1400 GAN loss: 9.475761413574219\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 387/1400 GAN loss: 9.427835464477539\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 388/1400 GAN loss: 12.914027214050293\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 389/1400 GAN loss: 12.053491592407227\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 390/1400 GAN loss: 10.085668563842773\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 391/1400 GAN loss: 14.239810943603516\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 392/1400 GAN loss: 18.123388290405273\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 393/1400 GAN loss: 12.271041870117188\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 394/1400 GAN loss: 12.698158264160156\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 395/1400 GAN loss: 11.8292236328125\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 396/1400 GAN loss: 19.243898391723633\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 397/1400 GAN loss: 21.291624069213867\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 398/1400 GAN loss: 19.138338088989258\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 399/1400 GAN loss: 19.177207946777344\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 400/1400 GAN loss: 22.221309661865234\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 401/1400 GAN loss: 24.795576095581055\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 402/1400 GAN loss: 9.074532508850098\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 403/1400 GAN loss: 3.0720114707946777\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 404/1400 GAN loss: 2.535538911819458\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 405/1400 GAN loss: 4.0079827308654785\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 406/1400 GAN loss: 4.415359973907471\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 407/1400 GAN loss: 10.447437286376953\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 408/1400 GAN loss: 7.823884010314941\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 409/1400 GAN loss: 7.800886154174805\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 410/1400 GAN loss: 19.69491195678711\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 411/1400 GAN loss: 22.606285095214844\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Epoche: 412/1400 GAN loss: 36.83858108520508\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 413/1400 GAN loss: 35.21778106689453\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 414/1400 GAN loss: 29.25380516052246\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 415/1400 GAN loss: 31.22989845275879\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 416/1400 GAN loss: 23.762378692626953\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 417/1400 GAN loss: 21.143638610839844\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 418/1400 GAN loss: 19.07986831665039\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 419/1400 GAN loss: 18.26004409790039\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 420/1400 GAN loss: 23.555068969726562\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 421/1400 GAN loss: 10.196236610412598\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 422/1400 GAN loss: 6.792538166046143\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 423/1400 GAN loss: 10.037786483764648\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 424/1400 GAN loss: 14.750717163085938\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 425/1400 GAN loss: 16.109661102294922\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 426/1400 GAN loss: 19.23721694946289\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 427/1400 GAN loss: 26.38922119140625\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 428/1400 GAN loss: 32.74687576293945\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 429/1400 GAN loss: 30.00438690185547\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 430/1400 GAN loss: 39.63840103149414\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 431/1400 GAN loss: 63.61720657348633\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 432/1400 GAN loss: 38.42414093017578\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 433/1400 GAN loss: 44.9085693359375\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 434/1400 GAN loss: 33.2251091003418\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 435/1400 GAN loss: 19.978652954101562\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 436/1400 GAN loss: 19.915576934814453\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 437/1400 GAN loss: 44.127410888671875\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 438/1400 GAN loss: 0.06733696162700653\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 439/1400 GAN loss: 0.04823494702577591\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 440/1400 GAN loss: 0.305950790643692\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 441/1400 GAN loss: 2.320178508758545\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 442/1400 GAN loss: 1.771950364112854\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 443/1400 GAN loss: 0.5651872158050537\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 444/1400 GAN loss: 5.088080883026123\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 445/1400 GAN loss: 1.8557225465774536\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 446/1400 GAN loss: 0.9272744059562683\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 447/1400 GAN loss: 0.463617205619812\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 448/1400 GAN loss: 0.8825623393058777\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 449/1400 GAN loss: 1.4862029552459717\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 450/1400 GAN loss: 0.6175677180290222\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 451/1400 GAN loss: 0.7210214138031006\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 452/1400 GAN loss: 1.3195550441741943\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 453/1400 GAN loss: 1.020613193511963\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 454/1400 GAN loss: 0.5713826417922974\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 455/1400 GAN loss: 0.8402538299560547\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 456/1400 GAN loss: 1.1524930000305176\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 457/1400 GAN loss: 0.7021692395210266\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 458/1400 GAN loss: 0.8046152591705322\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 459/1400 GAN loss: 1.0693351030349731\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 460/1400 GAN loss: 1.2426173686981201\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 461/1400 GAN loss: 0.7766904830932617\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 462/1400 GAN loss: 0.5577419996261597\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 463/1400 GAN loss: 0.7422477006912231\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 464/1400 GAN loss: 1.055588722229004\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 465/1400 GAN loss: 1.2206625938415527\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 466/1400 GAN loss: 1.0072364807128906\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 467/1400 GAN loss: 0.6578774452209473\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 468/1400 GAN loss: 0.60331791639328\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 469/1400 GAN loss: 0.7952858805656433\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 470/1400 GAN loss: 1.1038978099822998\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 471/1400 GAN loss: 0.9609464406967163\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 472/1400 GAN loss: 0.9543067216873169\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 473/1400 GAN loss: 0.7536357641220093\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 474/1400 GAN loss: 0.5352917909622192\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 475/1400 GAN loss: 0.6482300162315369\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 476/1400 GAN loss: 0.7557369470596313\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 477/1400 GAN loss: 1.016242265701294\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 478/1400 GAN loss: 1.1956998109817505\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 479/1400 GAN loss: 1.1587352752685547\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 480/1400 GAN loss: 0.8805484771728516\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 481/1400 GAN loss: 0.6602418422698975\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 482/1400 GAN loss: 0.6346685886383057\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 483/1400 GAN loss: 0.808473527431488\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 484/1400 GAN loss: 1.09921133518219\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 485/1400 GAN loss: 1.2309410572052002\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 486/1400 GAN loss: 1.098604679107666\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 487/1400 GAN loss: 0.7297424077987671\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 488/1400 GAN loss: 0.5078333616256714\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 489/1400 GAN loss: 0.6819982528686523\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 490/1400 GAN loss: 1.033437728881836\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 491/1400 GAN loss: 1.1458395719528198\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 492/1400 GAN loss: 0.9915058612823486\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 493/1400 GAN loss: 0.8723355531692505\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 494/1400 GAN loss: 0.7991674542427063\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 495/1400 GAN loss: 0.9158138036727905\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 496/1400 GAN loss: 1.2070887088775635\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 497/1400 GAN loss: 1.3542206287384033\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 498/1400 GAN loss: 1.4013911485671997\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 499/1400 GAN loss: 1.211613416671753\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 500/1400 GAN loss: 1.1387860774993896\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 501/1400 GAN loss: 1.2684807777404785\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 502/1400 GAN loss: 1.3221828937530518\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 503/1400 GAN loss: 1.5014984607696533\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 504/1400 GAN loss: 1.7045117616653442\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 505/1400 GAN loss: 1.8416963815689087\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 506/1400 GAN loss: 1.7332665920257568\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 507/1400 GAN loss: 1.9191136360168457\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 508/1400 GAN loss: 2.123292922973633\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 509/1400 GAN loss: 2.472299575805664\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 510/1400 GAN loss: 2.7660579681396484\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 511/1400 GAN loss: 2.7579896450042725\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 512/1400 GAN loss: 2.805180072784424\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 513/1400 GAN loss: 3.2270913124084473\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 514/1400 GAN loss: 3.508341073989868\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 515/1400 GAN loss: 4.244355201721191\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 516/1400 GAN loss: 5.04878044128418\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 517/1400 GAN loss: 5.748111724853516\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 518/1400 GAN loss: 6.597411155700684\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 519/1400 GAN loss: 7.42556095123291\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 520/1400 GAN loss: 7.9170074462890625\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 521/1400 GAN loss: 8.295761108398438\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 522/1400 GAN loss: 9.575603485107422\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 523/1400 GAN loss: 10.130680084228516\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 524/1400 GAN loss: 11.342690467834473\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 525/1400 GAN loss: 11.897237777709961\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 526/1400 GAN loss: 10.666557312011719\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 527/1400 GAN loss: 11.374028205871582\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 528/1400 GAN loss: 12.207225799560547\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 529/1400 GAN loss: 13.507040977478027\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 530/1400 GAN loss: 13.439424514770508\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 531/1400 GAN loss: 14.178621292114258\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 532/1400 GAN loss: 13.240094184875488\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 533/1400 GAN loss: 14.71816635131836\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 534/1400 GAN loss: 16.91225814819336\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 535/1400 GAN loss: 15.145682334899902\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 536/1400 GAN loss: 14.248172760009766\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 537/1400 GAN loss: 18.248088836669922\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 538/1400 GAN loss: 25.130184173583984\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 539/1400 GAN loss: 7.031335830688477\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 540/1400 GAN loss: 3.926565647125244\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 541/1400 GAN loss: 13.91032886505127\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 542/1400 GAN loss: 20.960952758789062\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 543/1400 GAN loss: 8.55579948425293\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 544/1400 GAN loss: 2.5045275688171387\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 545/1400 GAN loss: 1.9586026668548584\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 546/1400 GAN loss: 1.5184037685394287\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 547/1400 GAN loss: 1.9271200895309448\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 548/1400 GAN loss: 2.963894844055176\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 549/1400 GAN loss: 3.4070944786071777\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 550/1400 GAN loss: 3.049997329711914\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 551/1400 GAN loss: 3.018320322036743\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 552/1400 GAN loss: 3.6886708736419678\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 553/1400 GAN loss: 4.990782737731934\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 554/1400 GAN loss: 5.813745021820068\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 555/1400 GAN loss: 4.895444393157959\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 556/1400 GAN loss: 6.8784284591674805\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 557/1400 GAN loss: 8.010137557983398\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 558/1400 GAN loss: 9.293630599975586\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 559/1400 GAN loss: 9.122797966003418\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 560/1400 GAN loss: 8.941370010375977\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 561/1400 GAN loss: 9.30591869354248\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 562/1400 GAN loss: 10.392175674438477\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 563/1400 GAN loss: 10.833648681640625\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 564/1400 GAN loss: 9.758343696594238\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 565/1400 GAN loss: 11.49534797668457\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 566/1400 GAN loss: 14.686229705810547\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 567/1400 GAN loss: 16.449878692626953\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 568/1400 GAN loss: 7.830395221710205\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 569/1400 GAN loss: 8.575098037719727\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 570/1400 GAN loss: 13.849830627441406\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 571/1400 GAN loss: 13.819494247436523\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 572/1400 GAN loss: 12.66492748260498\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 573/1400 GAN loss: 8.272369384765625\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 574/1400 GAN loss: 9.849700927734375\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 575/1400 GAN loss: 11.165841102600098\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 576/1400 GAN loss: 12.593545913696289\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 577/1400 GAN loss: 11.174402236938477\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 578/1400 GAN loss: 12.924899101257324\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 579/1400 GAN loss: 13.029519081115723\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 580/1400 GAN loss: 13.075679779052734\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 581/1400 GAN loss: 14.141138076782227\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 582/1400 GAN loss: 12.958773612976074\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 583/1400 GAN loss: 16.8756160736084\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 584/1400 GAN loss: 13.38422679901123\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 585/1400 GAN loss: 13.262225151062012\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 586/1400 GAN loss: 22.110448837280273\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 587/1400 GAN loss: 24.377655029296875\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 588/1400 GAN loss: 22.241310119628906\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 589/1400 GAN loss: 7.144509315490723\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 590/1400 GAN loss: 4.497750282287598\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 591/1400 GAN loss: 7.167058944702148\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 592/1400 GAN loss: 7.253580570220947\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 593/1400 GAN loss: 6.737630844116211\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 594/1400 GAN loss: 7.252453327178955\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 595/1400 GAN loss: 5.40306282043457\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 596/1400 GAN loss: 4.677224636077881\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 597/1400 GAN loss: 4.769161224365234\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 598/1400 GAN loss: 3.6579697132110596\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 599/1400 GAN loss: 3.1980397701263428\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 600/1400 GAN loss: 5.512009620666504\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 601/1400 GAN loss: 6.102502822875977\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 602/1400 GAN loss: 4.9791765213012695\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 603/1400 GAN loss: 6.600766658782959\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 604/1400 GAN loss: 6.5915727615356445\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 605/1400 GAN loss: 4.811341762542725\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 606/1400 GAN loss: 5.811495780944824\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 607/1400 GAN loss: 6.814682483673096\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 608/1400 GAN loss: 5.987435817718506\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 609/1400 GAN loss: 7.752429962158203\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 610/1400 GAN loss: 7.810122489929199\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 611/1400 GAN loss: 6.546277046203613\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 612/1400 GAN loss: 5.2482757568359375\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 613/1400 GAN loss: 6.135370254516602\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 614/1400 GAN loss: 5.890528678894043\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 615/1400 GAN loss: 9.460948944091797\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 616/1400 GAN loss: 12.141700744628906\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 617/1400 GAN loss: 12.532825469970703\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 618/1400 GAN loss: 15.71922492980957\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 619/1400 GAN loss: 14.516182899475098\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 620/1400 GAN loss: 13.21131420135498\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 621/1400 GAN loss: 11.245166778564453\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 622/1400 GAN loss: 11.557682037353516\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 623/1400 GAN loss: 8.230175971984863\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 624/1400 GAN loss: 10.455972671508789\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 625/1400 GAN loss: 9.7868070602417\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 626/1400 GAN loss: 14.086689949035645\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 627/1400 GAN loss: 4.333726406097412\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 628/1400 GAN loss: 4.7935895919799805\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 629/1400 GAN loss: 2.8004634380340576\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 630/1400 GAN loss: 3.4150893688201904\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 631/1400 GAN loss: 2.827688694000244\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 632/1400 GAN loss: 3.2244255542755127\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 633/1400 GAN loss: 3.1219406127929688\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 634/1400 GAN loss: 4.312033653259277\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 635/1400 GAN loss: 2.191711902618408\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 636/1400 GAN loss: 3.1669976711273193\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 637/1400 GAN loss: 3.054877519607544\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 638/1400 GAN loss: 2.641533374786377\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 639/1400 GAN loss: 2.1404521465301514\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 640/1400 GAN loss: 3.869966983795166\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 641/1400 GAN loss: 3.929133892059326\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 642/1400 GAN loss: 3.213531494140625\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 643/1400 GAN loss: 4.909816741943359\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 644/1400 GAN loss: 5.535447120666504\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 645/1400 GAN loss: 7.686916828155518\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 646/1400 GAN loss: 5.380465507507324\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 647/1400 GAN loss: 5.75537633895874\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 648/1400 GAN loss: 7.374090194702148\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 649/1400 GAN loss: 9.121521949768066\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 650/1400 GAN loss: 10.89339542388916\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 651/1400 GAN loss: 3.8455305099487305\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoche: 652/1400 GAN loss: 2.3075783252716064\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 653/1400 GAN loss: 3.807429552078247\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 654/1400 GAN loss: 5.794424533843994\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 655/1400 GAN loss: 9.95792007446289\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 656/1400 GAN loss: 3.8809666633605957\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 657/1400 GAN loss: 2.3147804737091064\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 658/1400 GAN loss: 2.2690083980560303\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 659/1400 GAN loss: 2.4758784770965576\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 660/1400 GAN loss: 2.851490020751953\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 661/1400 GAN loss: 4.221813678741455\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 662/1400 GAN loss: 9.647689819335938\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 663/1400 GAN loss: 5.738748550415039\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 664/1400 GAN loss: 4.714066505432129\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 665/1400 GAN loss: 3.5466785430908203\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 666/1400 GAN loss: 4.391934871673584\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 667/1400 GAN loss: 4.780297756195068\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 668/1400 GAN loss: 3.9538822174072266\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 669/1400 GAN loss: 3.7088327407836914\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 670/1400 GAN loss: 4.539120674133301\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 671/1400 GAN loss: 2.9781274795532227\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 672/1400 GAN loss: 2.795222282409668\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 673/1400 GAN loss: 4.965784549713135\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 674/1400 GAN loss: 5.125779151916504\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 675/1400 GAN loss: 7.389106750488281\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 676/1400 GAN loss: 8.716789245605469\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 677/1400 GAN loss: 1.6193838119506836\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 678/1400 GAN loss: 0.7449181079864502\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 679/1400 GAN loss: 0.4662718176841736\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 680/1400 GAN loss: 0.833214521408081\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 681/1400 GAN loss: 0.9167259335517883\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 682/1400 GAN loss: 1.6027414798736572\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 683/1400 GAN loss: 2.570950746536255\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 684/1400 GAN loss: 3.4954793453216553\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 685/1400 GAN loss: 3.4004101753234863\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 686/1400 GAN loss: 3.5616207122802734\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 687/1400 GAN loss: 5.169429302215576\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 688/1400 GAN loss: 4.868618965148926\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 689/1400 GAN loss: 4.888997554779053\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 690/1400 GAN loss: 8.282608985900879\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 691/1400 GAN loss: 12.123495101928711\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 692/1400 GAN loss: 16.27837562561035\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 693/1400 GAN loss: 12.698598861694336\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 694/1400 GAN loss: 12.23124885559082\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 695/1400 GAN loss: 11.534530639648438\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 696/1400 GAN loss: 13.858434677124023\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 697/1400 GAN loss: 12.376520156860352\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 698/1400 GAN loss: 7.757259368896484\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 699/1400 GAN loss: 11.87562370300293\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 700/1400 GAN loss: 16.643831253051758\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 701/1400 GAN loss: 5.949368476867676\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 702/1400 GAN loss: 1.386033296585083\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 703/1400 GAN loss: 0.8416954278945923\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 704/1400 GAN loss: 1.9474880695343018\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 705/1400 GAN loss: 5.792167663574219\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 706/1400 GAN loss: 5.377226829528809\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 707/1400 GAN loss: 3.20278263092041\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 708/1400 GAN loss: 4.364535808563232\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 709/1400 GAN loss: 4.537954330444336\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 710/1400 GAN loss: 3.0531811714172363\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 711/1400 GAN loss: 2.109781265258789\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 712/1400 GAN loss: 1.8771657943725586\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 713/1400 GAN loss: 1.3955639600753784\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 714/1400 GAN loss: 1.350748896598816\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 715/1400 GAN loss: 1.17694091796875\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 716/1400 GAN loss: 1.327073335647583\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 717/1400 GAN loss: 1.7011442184448242\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 718/1400 GAN loss: 1.955179214477539\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 719/1400 GAN loss: 1.7826709747314453\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 720/1400 GAN loss: 2.522517681121826\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 721/1400 GAN loss: 2.10141921043396\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 722/1400 GAN loss: 1.169310212135315\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 723/1400 GAN loss: 1.9923694133758545\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 724/1400 GAN loss: 1.9224145412445068\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 725/1400 GAN loss: 1.790848731994629\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 726/1400 GAN loss: 2.3409628868103027\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 727/1400 GAN loss: 2.9095652103424072\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 728/1400 GAN loss: 2.0846643447875977\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 729/1400 GAN loss: 1.8436447381973267\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 730/1400 GAN loss: 2.8504438400268555\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 731/1400 GAN loss: 2.944495677947998\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 732/1400 GAN loss: 4.93644905090332\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 733/1400 GAN loss: 6.809510231018066\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 734/1400 GAN loss: 6.458317756652832\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 735/1400 GAN loss: 3.6978724002838135\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 736/1400 GAN loss: 3.0349230766296387\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 737/1400 GAN loss: 4.334927558898926\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 738/1400 GAN loss: 3.0309653282165527\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 739/1400 GAN loss: 3.112414598464966\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 740/1400 GAN loss: 7.4427337646484375\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 741/1400 GAN loss: 9.004266738891602\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 742/1400 GAN loss: 8.848762512207031\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 743/1400 GAN loss: 5.575245380401611\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 744/1400 GAN loss: 8.992568969726562\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 745/1400 GAN loss: 8.049871444702148\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 746/1400 GAN loss: 8.953577041625977\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 747/1400 GAN loss: 8.90921401977539\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 748/1400 GAN loss: 8.403497695922852\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 749/1400 GAN loss: 3.884037971496582\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 750/1400 GAN loss: 6.236865043640137\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 751/1400 GAN loss: 5.318638801574707\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 752/1400 GAN loss: 5.363767623901367\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 753/1400 GAN loss: 4.42221212387085\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 754/1400 GAN loss: 7.041959762573242\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 755/1400 GAN loss: 8.18984603881836\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 756/1400 GAN loss: 2.7947800159454346\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 757/1400 GAN loss: 5.114066123962402\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 758/1400 GAN loss: 7.709938049316406\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 759/1400 GAN loss: 7.579962730407715\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 760/1400 GAN loss: 4.578451156616211\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 761/1400 GAN loss: 3.4703190326690674\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 762/1400 GAN loss: 2.5168466567993164\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 763/1400 GAN loss: 2.469665288925171\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 764/1400 GAN loss: 2.636086940765381\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 765/1400 GAN loss: 4.69357442855835\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 766/1400 GAN loss: 5.884456157684326\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 767/1400 GAN loss: 6.859962463378906\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 768/1400 GAN loss: 12.001575469970703\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 769/1400 GAN loss: 9.47144889831543\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 770/1400 GAN loss: 9.598234176635742\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 771/1400 GAN loss: 14.064462661743164\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 772/1400 GAN loss: 15.588711738586426\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 773/1400 GAN loss: 15.381365776062012\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 774/1400 GAN loss: 15.52133560180664\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 775/1400 GAN loss: 15.719527244567871\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 776/1400 GAN loss: 12.097557067871094\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 777/1400 GAN loss: 15.055245399475098\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 778/1400 GAN loss: 0.1421581506729126\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 779/1400 GAN loss: 0.0375981479883194\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 780/1400 GAN loss: 0.0662573054432869\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 781/1400 GAN loss: 0.4114798903465271\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 782/1400 GAN loss: 1.985902190208435\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 783/1400 GAN loss: 1.5885579586029053\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 784/1400 GAN loss: 0.4292154014110565\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 785/1400 GAN loss: 0.3153771758079529\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 786/1400 GAN loss: 0.6503291726112366\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 787/1400 GAN loss: 1.4478838443756104\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 788/1400 GAN loss: 0.9038524627685547\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 789/1400 GAN loss: 0.4795033931732178\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 790/1400 GAN loss: 0.3914327323436737\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 791/1400 GAN loss: 0.43705812096595764\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 792/1400 GAN loss: 0.6565258502960205\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 793/1400 GAN loss: 0.9739165306091309\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 794/1400 GAN loss: 0.9816832542419434\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 795/1400 GAN loss: 0.9526942372322083\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 796/1400 GAN loss: 0.8289149403572083\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 797/1400 GAN loss: 0.8089183568954468\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 798/1400 GAN loss: 0.750677764415741\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 799/1400 GAN loss: 0.5660571455955505\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 800/1400 GAN loss: 0.6331788301467896\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 801/1400 GAN loss: 0.6553537845611572\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 802/1400 GAN loss: 0.7212945818901062\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 803/1400 GAN loss: 0.7164932489395142\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 804/1400 GAN loss: 0.7061534523963928\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 805/1400 GAN loss: 0.6437114477157593\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 806/1400 GAN loss: 0.6652737855911255\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 807/1400 GAN loss: 0.6783817410469055\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 808/1400 GAN loss: 0.7309403419494629\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 809/1400 GAN loss: 0.6799139380455017\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 810/1400 GAN loss: 0.7139421701431274\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 811/1400 GAN loss: 0.7232097387313843\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 812/1400 GAN loss: 0.7297704219818115\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 813/1400 GAN loss: 1.0976423025131226\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 814/1400 GAN loss: 0.7698179483413696\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 815/1400 GAN loss: 0.8249042630195618\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 816/1400 GAN loss: 1.0633169412612915\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 817/1400 GAN loss: 1.2711291313171387\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 818/1400 GAN loss: 0.9204561710357666\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 819/1400 GAN loss: 1.389162302017212\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 820/1400 GAN loss: 2.1819443702697754\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 821/1400 GAN loss: 2.194020986557007\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 822/1400 GAN loss: 3.248542308807373\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 823/1400 GAN loss: 3.269031047821045\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 824/1400 GAN loss: 4.6419677734375\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 825/1400 GAN loss: 3.783432960510254\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 826/1400 GAN loss: 4.913247108459473\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 827/1400 GAN loss: 8.007308959960938\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 828/1400 GAN loss: 9.790245056152344\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 829/1400 GAN loss: 10.387836456298828\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 830/1400 GAN loss: 14.712303161621094\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 831/1400 GAN loss: 11.143083572387695\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 832/1400 GAN loss: 23.18218994140625\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 833/1400 GAN loss: 22.473215103149414\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 834/1400 GAN loss: 7.325368881225586\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 835/1400 GAN loss: 5.056013584136963\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 836/1400 GAN loss: 7.56365442276001\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 837/1400 GAN loss: 11.392475128173828\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 838/1400 GAN loss: 13.294319152832031\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 839/1400 GAN loss: 6.22415018081665\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 840/1400 GAN loss: 5.359525680541992\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 841/1400 GAN loss: 7.6654887199401855\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 842/1400 GAN loss: 17.555919647216797\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 843/1400 GAN loss: 14.897005081176758\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 844/1400 GAN loss: 23.808883666992188\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 845/1400 GAN loss: 18.309158325195312\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 846/1400 GAN loss: 11.251480102539062\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 847/1400 GAN loss: 15.12992000579834\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 848/1400 GAN loss: 19.356304168701172\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 849/1400 GAN loss: 16.179988861083984\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 850/1400 GAN loss: 22.28618049621582\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 851/1400 GAN loss: 29.672670364379883\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 852/1400 GAN loss: 1.1615623235702515\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 853/1400 GAN loss: 0.14548778533935547\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 854/1400 GAN loss: 0.17473268508911133\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 855/1400 GAN loss: 0.6780380010604858\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 856/1400 GAN loss: 1.2652392387390137\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 857/1400 GAN loss: 1.184687614440918\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 858/1400 GAN loss: 0.7556074857711792\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 859/1400 GAN loss: 0.4098232686519623\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 860/1400 GAN loss: 0.3758975863456726\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 861/1400 GAN loss: 0.5120350122451782\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 862/1400 GAN loss: 0.9122252464294434\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 863/1400 GAN loss: 1.079075574874878\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 864/1400 GAN loss: 0.7845298051834106\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 865/1400 GAN loss: 0.6682361364364624\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 866/1400 GAN loss: 0.6475560069084167\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 867/1400 GAN loss: 0.7620241641998291\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 868/1400 GAN loss: 0.832234799861908\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 869/1400 GAN loss: 0.8895292282104492\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 870/1400 GAN loss: 0.840200662612915\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 871/1400 GAN loss: 0.7449671626091003\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 872/1400 GAN loss: 0.6183702945709229\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 873/1400 GAN loss: 0.6122993230819702\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 874/1400 GAN loss: 0.6122964024543762\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 875/1400 GAN loss: 0.6513344049453735\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 876/1400 GAN loss: 0.7248234748840332\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 877/1400 GAN loss: 0.7360685467720032\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 878/1400 GAN loss: 0.741302490234375\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 879/1400 GAN loss: 0.7312485575675964\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 880/1400 GAN loss: 0.6861868500709534\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 881/1400 GAN loss: 0.7265045642852783\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 882/1400 GAN loss: 0.7229070663452148\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 883/1400 GAN loss: 0.7605210542678833\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 884/1400 GAN loss: 0.8104466199874878\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 885/1400 GAN loss: 0.8216832876205444\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 886/1400 GAN loss: 0.7459939122200012\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 887/1400 GAN loss: 0.7069985866546631\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 888/1400 GAN loss: 0.6488428115844727\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 889/1400 GAN loss: 0.6867316961288452\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 890/1400 GAN loss: 0.7064967155456543\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 891/1400 GAN loss: 0.7698324918746948\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 892/1400 GAN loss: 0.796964704990387\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 893/1400 GAN loss: 0.6989172101020813\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 894/1400 GAN loss: 0.6419164538383484\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 895/1400 GAN loss: 0.5941131114959717\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 896/1400 GAN loss: 0.5662541389465332\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 897/1400 GAN loss: 0.5675761699676514\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 898/1400 GAN loss: 0.6553921699523926\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 899/1400 GAN loss: 0.7840070128440857\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 900/1400 GAN loss: 0.8840762972831726\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 901/1400 GAN loss: 0.859295666217804\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 902/1400 GAN loss: 0.7893576622009277\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 903/1400 GAN loss: 0.7426080703735352\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 904/1400 GAN loss: 0.6952773332595825\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 905/1400 GAN loss: 0.6547024846076965\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 906/1400 GAN loss: 0.6138006448745728\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 907/1400 GAN loss: 0.6857810020446777\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 908/1400 GAN loss: 0.7244824171066284\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 909/1400 GAN loss: 0.7439645528793335\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 910/1400 GAN loss: 0.7648519277572632\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 911/1400 GAN loss: 0.7623492479324341\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 912/1400 GAN loss: 0.7343300580978394\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 913/1400 GAN loss: 0.6926751732826233\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 914/1400 GAN loss: 0.6636571884155273\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 915/1400 GAN loss: 0.657711386680603\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 916/1400 GAN loss: 0.6528661847114563\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 917/1400 GAN loss: 0.7096859216690063\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 918/1400 GAN loss: 0.7506587505340576\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 919/1400 GAN loss: 0.8083585500717163\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 920/1400 GAN loss: 0.8378161191940308\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 921/1400 GAN loss: 0.7677905559539795\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 922/1400 GAN loss: 0.7563026547431946\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 923/1400 GAN loss: 0.7113056778907776\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 924/1400 GAN loss: 0.683310866355896\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 925/1400 GAN loss: 0.5992243885993958\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 926/1400 GAN loss: 0.6357213258743286\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 927/1400 GAN loss: 0.6233519911766052\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 928/1400 GAN loss: 0.6617697477340698\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 929/1400 GAN loss: 0.7138607501983643\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 930/1400 GAN loss: 0.7319952845573425\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 931/1400 GAN loss: 0.804664134979248\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 932/1400 GAN loss: 0.7993596196174622\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 933/1400 GAN loss: 0.8038768768310547\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 934/1400 GAN loss: 0.7672919631004333\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 935/1400 GAN loss: 0.6879134178161621\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 936/1400 GAN loss: 0.6649941802024841\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 937/1400 GAN loss: 0.5673048496246338\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 938/1400 GAN loss: 0.5728594660758972\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 939/1400 GAN loss: 0.5906343460083008\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 940/1400 GAN loss: 0.5881641507148743\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 941/1400 GAN loss: 0.6006346344947815\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 942/1400 GAN loss: 0.6218974590301514\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 943/1400 GAN loss: 0.665253758430481\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 944/1400 GAN loss: 0.631767988204956\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 945/1400 GAN loss: 0.7081902027130127\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 946/1400 GAN loss: 0.7615566253662109\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 947/1400 GAN loss: 0.8171337842941284\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 948/1400 GAN loss: 0.8198936581611633\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 949/1400 GAN loss: 0.8288001418113708\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 950/1400 GAN loss: 0.7861300706863403\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 951/1400 GAN loss: 0.7469086647033691\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 952/1400 GAN loss: 0.7720375657081604\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 953/1400 GAN loss: 0.6731835603713989\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 954/1400 GAN loss: 0.6950656771659851\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 955/1400 GAN loss: 0.6340093016624451\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 956/1400 GAN loss: 0.5890147686004639\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 957/1400 GAN loss: 0.6348373293876648\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 958/1400 GAN loss: 0.6236850619316101\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 959/1400 GAN loss: 0.6282905340194702\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 960/1400 GAN loss: 0.6871980428695679\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 961/1400 GAN loss: 0.7205663323402405\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 962/1400 GAN loss: 0.7370153665542603\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 963/1400 GAN loss: 0.7399946451187134\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 964/1400 GAN loss: 0.8094621896743774\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 965/1400 GAN loss: 0.8603321313858032\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 966/1400 GAN loss: 0.7587873935699463\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 967/1400 GAN loss: 0.7682828903198242\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 968/1400 GAN loss: 0.7697521448135376\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 969/1400 GAN loss: 0.8040263652801514\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 970/1400 GAN loss: 0.716402530670166\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 971/1400 GAN loss: 0.7930771112442017\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 972/1400 GAN loss: 0.7491148114204407\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 973/1400 GAN loss: 0.8681217432022095\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoche: 974/1400 GAN loss: 0.6725738644599915\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 975/1400 GAN loss: 0.8614113330841064\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 976/1400 GAN loss: 0.8860249519348145\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoche: 977/1400 GAN loss: 0.7541475296020508\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 978/1400 GAN loss: 0.9287008047103882\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 979/1400 GAN loss: 0.8969778418540955\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 980/1400 GAN loss: 0.7950776815414429\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 981/1400 GAN loss: 1.1309187412261963\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 982/1400 GAN loss: 0.7493935227394104\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 983/1400 GAN loss: 1.0060021877288818\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 984/1400 GAN loss: 1.1624610424041748\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 985/1400 GAN loss: 0.862531304359436\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 986/1400 GAN loss: 0.8557299375534058\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 987/1400 GAN loss: 0.9677276015281677\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 988/1400 GAN loss: 1.1189193725585938\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 989/1400 GAN loss: 1.1581542491912842\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 990/1400 GAN loss: 1.6319642066955566\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 991/1400 GAN loss: 1.3408877849578857\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 992/1400 GAN loss: 1.1698282957077026\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 993/1400 GAN loss: 1.2926098108291626\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 994/1400 GAN loss: 1.3694400787353516\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 995/1400 GAN loss: 1.5303173065185547\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 996/1400 GAN loss: 1.2975215911865234\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 997/1400 GAN loss: 1.30476975440979\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 998/1400 GAN loss: 1.559230923652649\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 999/1400 GAN loss: 0.9292005300521851\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1000/1400 GAN loss: 1.1597976684570312\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1001/1400 GAN loss: 1.8170366287231445\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1002/1400 GAN loss: 1.3685481548309326\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1003/1400 GAN loss: 1.2753322124481201\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1004/1400 GAN loss: 1.3809282779693604\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1005/1400 GAN loss: 1.819928765296936\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1006/1400 GAN loss: 1.4419389963150024\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1007/1400 GAN loss: 1.6349871158599854\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1008/1400 GAN loss: 1.9089164733886719\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1009/1400 GAN loss: 1.9951939582824707\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1010/1400 GAN loss: 1.7862238883972168\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1011/1400 GAN loss: 2.4839813709259033\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1012/1400 GAN loss: 2.240556001663208\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1013/1400 GAN loss: 2.090709686279297\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1014/1400 GAN loss: 2.7426490783691406\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1015/1400 GAN loss: 2.3476297855377197\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1016/1400 GAN loss: 2.886298656463623\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 1017/1400 GAN loss: 2.325040340423584\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1018/1400 GAN loss: 2.7914786338806152\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1019/1400 GAN loss: 2.462812900543213\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1020/1400 GAN loss: 2.6659650802612305\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 1021/1400 GAN loss: 2.7138314247131348\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1022/1400 GAN loss: 2.579623222351074\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1023/1400 GAN loss: 3.2718119621276855\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1024/1400 GAN loss: 3.1222925186157227\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1025/1400 GAN loss: 2.3289847373962402\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1026/1400 GAN loss: 3.4145607948303223\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1027/1400 GAN loss: 3.7807624340057373\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1028/1400 GAN loss: 4.030407905578613\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1029/1400 GAN loss: 5.22595739364624\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1030/1400 GAN loss: 3.9598565101623535\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1031/1400 GAN loss: 3.1560721397399902\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1032/1400 GAN loss: 3.6266374588012695\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1033/1400 GAN loss: 4.893362522125244\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1034/1400 GAN loss: 2.758450508117676\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1035/1400 GAN loss: 3.2844600677490234\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1036/1400 GAN loss: 4.122822284698486\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1037/1400 GAN loss: 3.844348430633545\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1038/1400 GAN loss: 3.3100814819335938\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1039/1400 GAN loss: 4.380290985107422\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 1040/1400 GAN loss: 3.6519455909729004\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1041/1400 GAN loss: 3.892673969268799\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1042/1400 GAN loss: 3.7330284118652344\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1043/1400 GAN loss: 2.585287094116211\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1044/1400 GAN loss: 2.6023333072662354\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1045/1400 GAN loss: 1.9427311420440674\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1046/1400 GAN loss: 3.155663013458252\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1047/1400 GAN loss: 4.455804824829102\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1048/1400 GAN loss: 3.691143035888672\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1049/1400 GAN loss: 3.4044504165649414\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1050/1400 GAN loss: 4.336816787719727\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1051/1400 GAN loss: 5.41131591796875\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1052/1400 GAN loss: 2.803145170211792\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1053/1400 GAN loss: 2.4337334632873535\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1054/1400 GAN loss: 1.9635077714920044\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1055/1400 GAN loss: 2.8363513946533203\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1056/1400 GAN loss: 3.0695526599884033\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1057/1400 GAN loss: 2.7454771995544434\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1058/1400 GAN loss: 3.1889147758483887\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1059/1400 GAN loss: 2.865405321121216\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1060/1400 GAN loss: 3.5413169860839844\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1061/1400 GAN loss: 2.9468536376953125\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1062/1400 GAN loss: 1.2980681657791138\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1063/1400 GAN loss: 3.009695529937744\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1064/1400 GAN loss: 2.8568074703216553\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 1065/1400 GAN loss: 2.6349544525146484\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1066/1400 GAN loss: 3.0455973148345947\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1067/1400 GAN loss: 2.419280767440796\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1068/1400 GAN loss: 4.299698829650879\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1069/1400 GAN loss: 4.166043281555176\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1070/1400 GAN loss: 4.887979507446289\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1071/1400 GAN loss: 4.056515693664551\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1072/1400 GAN loss: 4.524485111236572\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1073/1400 GAN loss: 3.150186538696289\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1074/1400 GAN loss: 4.388545989990234\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1075/1400 GAN loss: 3.6884684562683105\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1076/1400 GAN loss: 3.542015314102173\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1077/1400 GAN loss: 3.6293816566467285\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1078/1400 GAN loss: 2.2975783348083496\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1079/1400 GAN loss: 2.707836627960205\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1080/1400 GAN loss: 3.2847533226013184\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1081/1400 GAN loss: 2.0092597007751465\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1082/1400 GAN loss: 2.1152148246765137\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 1083/1400 GAN loss: 3.6850950717926025\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1084/1400 GAN loss: 3.24537992477417\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1085/1400 GAN loss: 4.08961296081543\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1086/1400 GAN loss: 2.8968162536621094\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1087/1400 GAN loss: 3.686781406402588\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1088/1400 GAN loss: 5.031775951385498\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1089/1400 GAN loss: 3.137181282043457\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1090/1400 GAN loss: 4.457945823669434\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1091/1400 GAN loss: 4.086907386779785\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1092/1400 GAN loss: 3.6962978839874268\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1093/1400 GAN loss: 4.6734395027160645\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1094/1400 GAN loss: 2.822558879852295\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1095/1400 GAN loss: 4.163622856140137\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1096/1400 GAN loss: 4.191819190979004\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1097/1400 GAN loss: 4.873983383178711\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1098/1400 GAN loss: 3.686187505722046\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 1099/1400 GAN loss: 4.006243705749512\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1100/1400 GAN loss: 7.05662727355957\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1101/1400 GAN loss: 4.555018424987793\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 1102/1400 GAN loss: 4.094906806945801\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1103/1400 GAN loss: 4.112850666046143\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1104/1400 GAN loss: 3.662200927734375\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1105/1400 GAN loss: 4.850966453552246\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1106/1400 GAN loss: 3.6001956462860107\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1107/1400 GAN loss: 5.875613212585449\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 1108/1400 GAN loss: 6.718936443328857\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1109/1400 GAN loss: 6.041286468505859\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1110/1400 GAN loss: 4.065579414367676\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1111/1400 GAN loss: 5.322592735290527\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1112/1400 GAN loss: 7.341952323913574\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1113/1400 GAN loss: 5.0072712898254395\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1114/1400 GAN loss: 6.111641883850098\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1115/1400 GAN loss: 5.7224273681640625\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1116/1400 GAN loss: 8.15876579284668\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1117/1400 GAN loss: 8.121207237243652\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 1118/1400 GAN loss: 4.9632768630981445\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1119/1400 GAN loss: 6.839888572692871\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1120/1400 GAN loss: 6.852753639221191\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1121/1400 GAN loss: 7.007730484008789\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoche: 1122/1400 GAN loss: 4.691105842590332\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1123/1400 GAN loss: 5.222659111022949\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1124/1400 GAN loss: 6.151175498962402\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1125/1400 GAN loss: 6.205026626586914\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1126/1400 GAN loss: 5.882814407348633\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1127/1400 GAN loss: 5.344008445739746\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 1128/1400 GAN loss: 9.581469535827637\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1129/1400 GAN loss: 10.882652282714844\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1130/1400 GAN loss: 10.314315795898438\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1131/1400 GAN loss: 7.250082969665527\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 1132/1400 GAN loss: 4.2096028327941895\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1133/1400 GAN loss: 2.6414217948913574\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1134/1400 GAN loss: 1.6127502918243408\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1135/1400 GAN loss: 1.7087881565093994\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1136/1400 GAN loss: 1.6000139713287354\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1137/1400 GAN loss: 1.9496240615844727\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1138/1400 GAN loss: 3.0022106170654297\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1139/1400 GAN loss: 4.672064304351807\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1140/1400 GAN loss: 2.793919086456299\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1141/1400 GAN loss: 4.112277984619141\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 1142/1400 GAN loss: 4.591123580932617\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1143/1400 GAN loss: 6.466375350952148\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1144/1400 GAN loss: 5.953176498413086\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoche: 1145/1400 GAN loss: 2.6688475608825684\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1146/1400 GAN loss: 5.671734809875488\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1147/1400 GAN loss: 6.858470439910889\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 1148/1400 GAN loss: 5.492517471313477\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1149/1400 GAN loss: 7.834097385406494\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1150/1400 GAN loss: 5.760792255401611\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1151/1400 GAN loss: 6.225106239318848\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1152/1400 GAN loss: 6.510307312011719\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1153/1400 GAN loss: 6.188676834106445\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1154/1400 GAN loss: 6.119479656219482\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 1155/1400 GAN loss: 6.446186065673828\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1156/1400 GAN loss: 6.159004211425781\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1157/1400 GAN loss: 6.100164413452148\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1158/1400 GAN loss: 6.459707736968994\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1159/1400 GAN loss: 8.515596389770508\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1160/1400 GAN loss: 8.2320556640625\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1161/1400 GAN loss: 7.6011528968811035\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1162/1400 GAN loss: 8.005040168762207\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1163/1400 GAN loss: 2.1933422088623047\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1164/1400 GAN loss: 8.042951583862305\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1165/1400 GAN loss: 10.154705047607422\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1166/1400 GAN loss: 6.212606906890869\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 1167/1400 GAN loss: 11.852277755737305\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1168/1400 GAN loss: 11.060063362121582\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1169/1400 GAN loss: 8.57500171661377\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1170/1400 GAN loss: 5.976043701171875\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1171/1400 GAN loss: 6.2404279708862305\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1172/1400 GAN loss: 10.194387435913086\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1173/1400 GAN loss: 8.853071212768555\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1174/1400 GAN loss: 3.2465624809265137\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1175/1400 GAN loss: 8.454004287719727\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 1176/1400 GAN loss: 9.65011215209961\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1177/1400 GAN loss: 5.621000289916992\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 1178/1400 GAN loss: 4.678853988647461\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1179/1400 GAN loss: 7.196302890777588\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1180/1400 GAN loss: 4.2526631355285645\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoche: 1181/1400 GAN loss: 8.139988899230957\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1182/1400 GAN loss: 4.465452194213867\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1183/1400 GAN loss: 5.0030035972595215\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1184/1400 GAN loss: 7.3048601150512695\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1185/1400 GAN loss: 10.216703414916992\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1186/1400 GAN loss: 8.52234172821045\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1187/1400 GAN loss: 10.895320892333984\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1188/1400 GAN loss: 7.89545202255249\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1189/1400 GAN loss: 7.26469087600708\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1190/1400 GAN loss: 9.092145919799805\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1191/1400 GAN loss: 9.419768333435059\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1192/1400 GAN loss: 9.337617874145508\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1193/1400 GAN loss: 10.59353256225586\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1194/1400 GAN loss: 14.371543884277344\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1195/1400 GAN loss: 10.16786003112793\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1196/1400 GAN loss: 7.089393615722656\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1197/1400 GAN loss: 4.912827491760254\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1198/1400 GAN loss: 16.557514190673828\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1199/1400 GAN loss: 5.035444259643555\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1200/1400 GAN loss: 8.241378784179688\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1201/1400 GAN loss: 8.15895938873291\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1202/1400 GAN loss: 12.053069114685059\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1203/1400 GAN loss: 8.845821380615234\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1204/1400 GAN loss: 5.803447246551514\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1205/1400 GAN loss: 9.364683151245117\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1206/1400 GAN loss: 9.185214042663574\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 1207/1400 GAN loss: 10.108155250549316\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1208/1400 GAN loss: 12.103328704833984\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1209/1400 GAN loss: 4.701842784881592\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1210/1400 GAN loss: 4.7641191482543945\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1211/1400 GAN loss: 10.483241081237793\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1212/1400 GAN loss: 8.11009693145752\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1213/1400 GAN loss: 8.203788757324219\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1214/1400 GAN loss: 5.8398942947387695\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1215/1400 GAN loss: 2.133820056915283\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 1216/1400 GAN loss: 2.7284703254699707\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 1217/1400 GAN loss: 0.7025508880615234\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1218/1400 GAN loss: 2.009913682937622\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1219/1400 GAN loss: 4.67539119720459\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1220/1400 GAN loss: 6.726034164428711\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1221/1400 GAN loss: 6.014352798461914\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1222/1400 GAN loss: 6.582870006561279\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1223/1400 GAN loss: 6.651528358459473\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1224/1400 GAN loss: 5.624948024749756\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1225/1400 GAN loss: 3.6163439750671387\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 1226/1400 GAN loss: 5.853848457336426\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 1227/1400 GAN loss: 4.674620628356934\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1228/1400 GAN loss: 5.454843997955322\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 1229/1400 GAN loss: 5.290684700012207\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1230/1400 GAN loss: 5.299991130828857\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1231/1400 GAN loss: 4.2954254150390625\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1232/1400 GAN loss: 4.883626937866211\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1233/1400 GAN loss: 3.32649564743042\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1234/1400 GAN loss: 4.154126167297363\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Epoche: 1235/1400 GAN loss: 7.9820942878723145\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1236/1400 GAN loss: 6.641807556152344\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1237/1400 GAN loss: 10.037590026855469\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1238/1400 GAN loss: 5.973484039306641\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1239/1400 GAN loss: 5.4539031982421875\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1240/1400 GAN loss: 13.031852722167969\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 1241/1400 GAN loss: 9.422142028808594\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1242/1400 GAN loss: 8.36338996887207\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1243/1400 GAN loss: 6.363929748535156\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1244/1400 GAN loss: 6.200120449066162\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1245/1400 GAN loss: 6.699346542358398\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1246/1400 GAN loss: 7.759760856628418\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1247/1400 GAN loss: 6.87694787979126\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1248/1400 GAN loss: 10.40501594543457\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1249/1400 GAN loss: 4.603575706481934\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1250/1400 GAN loss: 9.233682632446289\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1251/1400 GAN loss: 6.165902137756348\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1252/1400 GAN loss: 8.45821762084961\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1253/1400 GAN loss: 6.836866855621338\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1254/1400 GAN loss: 7.265535354614258\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 1255/1400 GAN loss: 13.872989654541016\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1256/1400 GAN loss: 7.839214324951172\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1257/1400 GAN loss: 10.217166900634766\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1258/1400 GAN loss: 16.100603103637695\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1259/1400 GAN loss: 17.962604522705078\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1260/1400 GAN loss: 17.328264236450195\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1261/1400 GAN loss: 12.11808967590332\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1262/1400 GAN loss: 10.15863037109375\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1263/1400 GAN loss: 18.012008666992188\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1264/1400 GAN loss: 14.16832447052002\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1265/1400 GAN loss: 13.517655372619629\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1266/1400 GAN loss: 9.19774341583252\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1267/1400 GAN loss: 20.8001708984375\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1268/1400 GAN loss: 16.339466094970703\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1269/1400 GAN loss: 8.9465913772583\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1270/1400 GAN loss: 19.578868865966797\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Epoche: 1271/1400 GAN loss: 19.147615432739258\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1272/1400 GAN loss: 23.50118064880371\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1273/1400 GAN loss: 25.624340057373047\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoche: 1274/1400 GAN loss: 14.10080337524414\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1275/1400 GAN loss: 20.98897933959961\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1276/1400 GAN loss: 2.907392740249634\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1277/1400 GAN loss: 1.9301680326461792\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1278/1400 GAN loss: 0.3135402202606201\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1279/1400 GAN loss: 0.4285345673561096\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1280/1400 GAN loss: 0.8938803672790527\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1281/1400 GAN loss: 1.4332443475723267\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1282/1400 GAN loss: 0.8617452383041382\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 1283/1400 GAN loss: 0.6739534735679626\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1284/1400 GAN loss: 0.8368197679519653\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1285/1400 GAN loss: 0.7739750146865845\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1286/1400 GAN loss: 0.6874299049377441\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 1287/1400 GAN loss: 0.9408097267150879\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1288/1400 GAN loss: 0.7927707433700562\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1289/1400 GAN loss: 0.670818567276001\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1290/1400 GAN loss: 0.8847174048423767\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1291/1400 GAN loss: 1.025962233543396\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1292/1400 GAN loss: 0.8121451139450073\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1293/1400 GAN loss: 0.7967026233673096\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1294/1400 GAN loss: 0.912416398525238\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1295/1400 GAN loss: 0.9063172936439514\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1296/1400 GAN loss: 0.8731585741043091\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1297/1400 GAN loss: 0.7764096260070801\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1298/1400 GAN loss: 0.716689944267273\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1299/1400 GAN loss: 0.6377930641174316\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1300/1400 GAN loss: 0.6414635181427002\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1301/1400 GAN loss: 0.5858801603317261\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 1302/1400 GAN loss: 0.5777696371078491\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1303/1400 GAN loss: 0.662068247795105\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1304/1400 GAN loss: 0.8260238766670227\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 1305/1400 GAN loss: 0.9072567224502563\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1306/1400 GAN loss: 0.9161429405212402\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1307/1400 GAN loss: 0.8519086241722107\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 1308/1400 GAN loss: 0.7782857418060303\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1309/1400 GAN loss: 0.6948282718658447\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1310/1400 GAN loss: 0.6575557589530945\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 1311/1400 GAN loss: 0.7186810374259949\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1312/1400 GAN loss: 0.6507284641265869\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1313/1400 GAN loss: 0.6284568309783936\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1314/1400 GAN loss: 0.7413078546524048\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1315/1400 GAN loss: 0.8499281406402588\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1316/1400 GAN loss: 1.2034821510314941\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1317/1400 GAN loss: 0.8454939723014832\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1318/1400 GAN loss: 0.7680861949920654\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 1319/1400 GAN loss: 0.7283905744552612\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1320/1400 GAN loss: 0.664138674736023\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1321/1400 GAN loss: 0.9862467646598816\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 1322/1400 GAN loss: 0.744623601436615\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1323/1400 GAN loss: 0.7835010290145874\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1324/1400 GAN loss: 1.5411319732666016\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 1325/1400 GAN loss: 0.899189829826355\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1326/1400 GAN loss: 0.8638399839401245\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1327/1400 GAN loss: 0.9599511027336121\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 1328/1400 GAN loss: 0.9958778619766235\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1329/1400 GAN loss: 1.0315160751342773\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1330/1400 GAN loss: 1.465756893157959\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 1331/1400 GAN loss: 0.8324916958808899\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1332/1400 GAN loss: 1.1046279668807983\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1333/1400 GAN loss: 1.3454930782318115\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1334/1400 GAN loss: 0.8957706093788147\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1335/1400 GAN loss: 1.4297213554382324\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1336/1400 GAN loss: 1.1101077795028687\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1337/1400 GAN loss: 0.6888195276260376\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1338/1400 GAN loss: 0.8211714029312134\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1339/1400 GAN loss: 1.6553701162338257\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1340/1400 GAN loss: 1.2680991888046265\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1341/1400 GAN loss: 1.4217631816864014\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1342/1400 GAN loss: 2.9609932899475098\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1343/1400 GAN loss: 3.536411762237549\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1344/1400 GAN loss: 1.6213140487670898\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1345/1400 GAN loss: 1.9554909467697144\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1346/1400 GAN loss: 3.1499619483947754\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1347/1400 GAN loss: 2.345440626144409\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1348/1400 GAN loss: 3.1074657440185547\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1349/1400 GAN loss: 1.8551068305969238\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1350/1400 GAN loss: 4.543313980102539\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1351/1400 GAN loss: 2.7737927436828613\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1352/1400 GAN loss: 1.9126139879226685\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1353/1400 GAN loss: 2.277550220489502\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 1354/1400 GAN loss: 3.334019660949707\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1355/1400 GAN loss: 3.9029603004455566\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1356/1400 GAN loss: 6.145922660827637\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1357/1400 GAN loss: 1.513972282409668\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1358/1400 GAN loss: 5.558484077453613\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1359/1400 GAN loss: 4.258013725280762\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1360/1400 GAN loss: 3.223576068878174\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1361/1400 GAN loss: 4.197271347045898\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1362/1400 GAN loss: 7.324889659881592\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1363/1400 GAN loss: 1.2633144855499268\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1364/1400 GAN loss: 1.9928994178771973\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1365/1400 GAN loss: 2.0305042266845703\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1366/1400 GAN loss: 2.4320387840270996\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1367/1400 GAN loss: 7.689224720001221\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1368/1400 GAN loss: 1.777897834777832\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoche: 1369/1400 GAN loss: 6.466294765472412\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1370/1400 GAN loss: 4.199954986572266\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1371/1400 GAN loss: 2.543428897857666\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 1372/1400 GAN loss: 7.606294631958008\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1373/1400 GAN loss: 2.962733030319214\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 1374/1400 GAN loss: 4.679564476013184\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1375/1400 GAN loss: 7.142472267150879\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1376/1400 GAN loss: 8.724849700927734\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1377/1400 GAN loss: 9.011008262634277\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1378/1400 GAN loss: 6.301296234130859\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1379/1400 GAN loss: 11.01803970336914\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1380/1400 GAN loss: 5.303479194641113\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1381/1400 GAN loss: 11.265962600708008\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1382/1400 GAN loss: 8.384421348571777\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1383/1400 GAN loss: 6.113456726074219\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1384/1400 GAN loss: 8.44533920288086\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1385/1400 GAN loss: 4.006645202636719\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1386/1400 GAN loss: 6.555616855621338\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1387/1400 GAN loss: 6.311016082763672\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1388/1400 GAN loss: 2.898855686187744\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 1389/1400 GAN loss: 0.9865127801895142\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1390/1400 GAN loss: 3.5037803649902344\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1391/1400 GAN loss: 7.1273651123046875\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1392/1400 GAN loss: 0.6006022691726685\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1393/1400 GAN loss: 2.9438695907592773\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1394/1400 GAN loss: 0.24607190489768982\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1395/1400 GAN loss: 0.43995869159698486\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1396/1400 GAN loss: 1.973816156387329\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1397/1400 GAN loss: 2.359813928604126\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1398/1400 GAN loss: 2.5054545402526855\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1399/1400 GAN loss: 3.141256332397461\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1400/1400 GAN loss: 0.7936974763870239\n"
     ]
    }
   ],
   "source": [
    "# Starte Training. \n",
    "train(generator, discriminator, GAN, dataset_shapes, dataset_labels, epochs=1400, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334e9e76-bc5c-4bd0-ac06-12dcf6199c49",
   "metadata": {},
   "source": [
    "<h2>Predict mit 2 Klassen</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db817221-f120-485c-ab8a-f710ae34f384",
   "metadata": {},
   "source": [
    "Jetzt können wir durch eingab eines Labels die Generierung der Bilder verändern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f5d00d65-f064-44f6-a167-7cddf854e402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aff03b9610>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise = np.random.normal(0, 1, (1, 100)) \n",
    "img   = generator([noise, np.array([1])])\n",
    "plt.imshow(img[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7698c33-627a-4ba4-a9bc-e509ed746a8d",
   "metadata": {},
   "source": [
    "Die Qualität nimmt mit umfangreicheren Netzen zu. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
