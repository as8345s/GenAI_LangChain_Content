{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7680ebd-ae71-4fa5-80dc-626581270f03",
   "metadata": {},
   "source": [
    "<h1>GAN - Generative Adversarial Network</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc6292a-1179-40d0-bf92-55803f676e64",
   "metadata": {},
   "source": [
    "Ein GAN ist ein Netzwerk, das aus zwei verschiedenen Komponenten besteht. Das Ziel ist es Bilder zu generieren.\n",
    "\n",
    "Ein GAN besteht aus:<br>\n",
    "- Einem Generator, der ein Bild erzeugen soll. Durch Anpassung der Weights kann das Model in eine Richtung gelenkt werden, das am Ende ein Vektor ausgibt das als Bild angezeigt werden kann. Quasi das Gegenteil von einem CNN.\n",
    "- Ein Discriminator, der das Generatornetz evaluiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1864545-15f8-4e5b-89ca-1943d219ea55",
   "metadata": {},
   "source": [
    "Beide können aus einem ANN oder CNN erstellt werden. Je umfangreicher das Netz ist, desto mehr Features kann es besser Abdecken.\n",
    "\n",
    "Ein einfaches Netz kann aus zwei ANNs erstellt werden. \n",
    "\n",
    "GANs können in verschiedene Use-Cases eingesetzt werden. Um ein erstes einfaches Beispiel zu erstellen, ist die Aufgabe synthetische Bilder von einem Produkt herzustellen was für eine Qualitätskontrolle genutzt werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683e8617-f462-4df7-9285-96ec35405f3e",
   "metadata": {},
   "source": [
    "<i>Abb1</i>: [Coming soon]\n",
    "\n",
    "<img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e0c43d-3b28-4998-aab5-2385cf633b15",
   "metadata": {},
   "source": [
    "Als Komponente haben wir ein 20 x 20 Bild mit einem \"L\" darauf. Das L könnte ein L-förmiges Bauteil sein. Bei der Produktion werden viele dieser Komponenten hergestellt.Mit der Synthetisierung dieser Bilder können wir mehr Daten generieren, die für das Training eines CNN verwendet werden können, um Abweichungen besser abzudecken. \n",
    "\n",
    "Wir gehen davon aus das es viel mehr Bilder von guten Bauteilen gibt und sehr wenige von nicht guten Bauteilen. Mit den synthetischen Bildern kann die Lücke geschlossen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a4dc49a5-c4c5-45fd-bc28-ccf5950b06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image  as matimg\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535c6f11-affe-4908-884b-a7cb7276d894",
   "metadata": {},
   "source": [
    "<h2> Dataset </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ebe31d-ca05-4f7e-8330-ffff85e4f841",
   "metadata": {},
   "source": [
    "Um so ein Bild zu erstellen, kann ein Zeichenprogramm oder Numpy verwendet werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b112d56e-d57d-4f55-a10a-d01ffd115867",
   "metadata": {},
   "source": [
    "<i>Abb2</i>: Zeichnung L-Objekt.\n",
    "\n",
    "<img src=\"./data/img/1_gan.PNG\" width=400, height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff631f0c-d1cd-4aa7-97f1-7923dae206c9",
   "metadata": {},
   "source": [
    "Alternativ kann auch mit Numpy eine einfache Form gezeichnet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b93abf1-525e-4c00-8e0e-ff81b8791410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle 1 Sample. \n",
    "def create_image(color:int=1) -> np.array:\n",
    "    image = np.zeros((20, 20))  # 2D Matrix, 20x20 Pixel.\n",
    "    # img [yloc, xloc]\n",
    "    image[1:12, 7] = 1  # Zeichne Feld.\n",
    "    image[1:12, 8] = 1  # Zeichne Feld.\n",
    "\n",
    "    image[11, 9:15]  = 1  \n",
    "    image[12, 7:15] = 1  \n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54c30e4a-4a7d-4574-b181-fa799441a3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = create_image()\n",
    "plt.matshow(img)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af5550-6c08-4661-9ec0-0e35e4275eb3",
   "metadata": {},
   "source": [
    "Schnell und einfach ist das Bild erstellt. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8ae06f-79ff-4fe7-894b-723cd201e7d2",
   "metadata": {},
   "source": [
    "<h3>Numpy Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ebb913-7b87-4430-ba91-debc3965e979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(950, 20, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Erstelle Dataset aus n-Samples \n",
    "def numpy_dataset(n:int):\n",
    "    return np.array([create_image() for x in range(n)])\n",
    "    \n",
    "size = 950\n",
    "dataset_numpy = numpy_dataset(size)\n",
    "dataset_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0a83280-1fc3-4939-8394-7974b399c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_numpy = dataset_numpy.reshape(size, 20, 20, 1).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c74cdfb-e749-4cd5-8f0d-3c9d1972dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dann können die Daten normalisiert werden.\n",
    "dataset_numpy_scaled = ( dataset_numpy - 0.5 ) / 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bdb104",
   "metadata": {},
   "source": [
    "Oder lade das Bild als numpy Array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "7ed2aa31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lade Bild mit OpenCV.\n",
    "# - Oder nutze Alternative wie PIL, ..., \n",
    "img = cv2.imread('./data/datasets/L__shape/lshape.jpg')\n",
    "type(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595d82b1",
   "metadata": {},
   "source": [
    "Danach kann das Bild in ein Dataframe geladen und ggf. Transformiert und angepasst werden. Oder nutze andere Methoden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a54d2",
   "metadata": {},
   "source": [
    "<h3>Tensorflow Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "9edd9447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20, 20, 3), dtype=uint8, numpy=\n",
       "array([[[248, 248, 248],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[246, 246, 246],\n",
       "        [255, 255, 255],\n",
       "        [253, 253, 253],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [247, 247, 247],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8)>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lade Bild\n",
    "img = tf.io.read_file('./data/datasets/L__shape/lshape.jpg')\n",
    "img = tf.image.decode_jpeg(img)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "9aa14c41-33d9-41b0-b3b8-5f6272471358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorDataset element_spec=TensorSpec(shape=(20, 20, 3), dtype=tf.uint8, name=None)>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Erstelle Dataset\n",
    "tf_dataset = tf.data.Dataset.from_tensors(img)\n",
    "tf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf9c9f8-c8a5-4aaf-a83b-1d6d162a351f",
   "metadata": {},
   "source": [
    "Danach kann das TF-Dataset beliebig genutzt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc139c-8c2d-4dc2-85d2-b0de1b051556",
   "metadata": {},
   "source": [
    "<h2>GAN Model - ANN</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e972ca2-75c2-4f35-9fd2-e22aa0317ebd",
   "metadata": {},
   "source": [
    "Dann erstellen wir zwei separate ANN Netze die verschiedene Aufgaben übernehmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0f9dc5c8-be09-4c10-a80a-646cd8b490fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator ANN #\n",
    "\n",
    "def create_generator():\n",
    "    gen_ann = tf.keras.Sequential([\n",
    "        # Input 100 Units, Output 128 Units.\n",
    "        tf.keras.layers.Dense(units=128, input_shape=(100,), activation='relu'),\n",
    "    \n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(units=400, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(units=400, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        # Erstelle Vektor der dann als Bild 20x20 Pixel dargestellt wird.\n",
    "        tf.keras.layers.Dense(units=20*20, activation='tanh'),\n",
    "        tf.keras.layers.Reshape((20, 20, 1))\n",
    "    ])\n",
    "    return gen_ann\n",
    "\n",
    "\n",
    "# Discriminator ANN # \n",
    "def create_discriminator():\n",
    "    dis_ann = tf.keras.Sequential([\n",
    "        # Bild als Input. Netz soll Fake-Images erkennen. \n",
    "        tf.keras.layers.Flatten(input_shape=(20,20, 1)),\n",
    "        tf.keras.layers.Dense(350, activation='relu'),\n",
    "        tf.keras.layers.Dense(450, activation='relu'),\n",
    "        tf.keras.layers.Dense(200, activation='relu'),\n",
    "        # Als Output: Fake oder nicht.\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return dis_ann\n",
    "\n",
    "discriminator = create_discriminator()\n",
    "discriminator.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss      = 'binary_crossentropy',\n",
    "    metrics   = 'accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90306a96",
   "metadata": {},
   "source": [
    "Für einfache Formen sind die Netze ausreichend. Diese können später weiter optimiert werden.\n",
    "\n",
    "Der nächste wichtige Schritt ist das Netz zu trainieren. Dazu fügen wir beide Netze zusammen und trainieren vorerst nur den Generator. \n",
    "- Mit einem Parameter können die Weights eines Models eingefroren werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b4964736-9676-4e61-8d1d-12d3200e19a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ded1381b-ec02-42d8-8c0d-a718696c066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle GAN\n",
    "generator = create_generator()\n",
    "gan_input = tf.keras.layers.Input(shape=(100,))  # 100 Startpixel.\n",
    "gen_image = generator(gan_input)\n",
    "\n",
    "net_output = discriminator(gen_image)\n",
    "GAN        = tf.keras.Model(gan_input, net_output)\n",
    "\n",
    "GAN.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb7b76-ad18-4d07-acca-914f71fd6417",
   "metadata": {},
   "source": [
    "Anders als sonst in Tensorflow schreiben wir eine detailreiche Trainingsschleife. \n",
    "- Batching möglich.\n",
    "\n",
    "Später werden wir uns weitere Details anschauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27712e9b-aa21-472c-bf93-f20d9fb0a559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Für das Batching: # \n",
    "# - Random-Index mit:\n",
    "np.random.randint(0, 3, 3)  #  (low, high, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df2680a0-b806-4902-89d2-f76b72efa305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.39782962e-01, -3.10202128e-01,  1.65800969e+00,\n",
       "        -4.97675987e-01,  7.78550346e-01,  9.68748206e-01,\n",
       "        -3.04415937e-01, -1.89076281e-02, -3.73261651e-01,\n",
       "        -1.55525828e+00,  4.70532909e-01, -2.68442098e-01,\n",
       "        -1.15237504e+00, -9.63809818e-01, -1.48104211e-01,\n",
       "        -6.57777960e-02,  2.70712605e-02,  1.17791695e+00,\n",
       "         5.52461789e-01,  1.40414667e+00, -1.60979634e+00,\n",
       "         5.92170840e-01,  7.01905012e-01,  3.40010321e-01,\n",
       "        -6.62022982e-01,  1.40517590e+00, -7.16884546e-01,\n",
       "         1.49486669e+00, -1.70991389e-01,  5.32584580e-01,\n",
       "        -1.19370327e+00, -1.58983268e-01, -4.51101165e-01,\n",
       "        -4.53239770e-01,  1.61885635e-01, -1.50889754e+00,\n",
       "         3.99815155e-01,  1.85668892e+00, -2.36656145e-03,\n",
       "        -1.49685538e+00,  2.73424970e+00,  1.58790819e+00,\n",
       "        -9.51698690e-01, -1.02370542e+00, -6.01330298e-01,\n",
       "         3.47095996e-01,  1.06514052e+00, -1.82129192e+00,\n",
       "        -1.62315857e+00, -1.10836805e+00,  3.65105948e-01,\n",
       "        -1.65580833e+00,  9.70527651e-01, -1.42109158e+00,\n",
       "         4.26893489e-01,  5.15048873e-01,  1.99678915e-01,\n",
       "        -1.89662671e+00, -2.43110055e+00, -7.09174954e-01,\n",
       "         2.42780321e-01, -3.16882610e-01, -3.22476650e-01,\n",
       "        -5.74503843e-01, -9.09318497e-01, -3.36459511e-01,\n",
       "         1.07549768e+00, -2.03303585e+00, -8.05449264e-02,\n",
       "        -7.68992401e-01,  6.98442832e-02,  5.35634406e-01,\n",
       "         5.73389662e-01,  1.06873556e+00, -1.67317315e+00,\n",
       "         9.20891833e-01,  2.14963552e-01,  8.68800974e-01,\n",
       "         1.27901833e+00, -5.98611172e-02, -1.92970022e-01,\n",
       "         3.22698171e-01,  9.24731891e-01, -2.10417447e-01,\n",
       "         9.03481373e-01, -2.77285329e-01,  1.94739436e+00,\n",
       "        -1.29771856e+00,  7.04967495e-01, -6.62550371e-01,\n",
       "        -1.18324899e+00,  8.44586781e-01, -2.20748725e-01,\n",
       "        -4.71454432e-01,  1.57467369e-01, -4.07884123e-02,\n",
       "         6.02944987e-01, -1.62363087e+00, -1.38680913e+00,\n",
       "         2.76806775e+00],\n",
       "       [-1.45292525e+00, -3.39507900e-02,  6.79737009e-01,\n",
       "        -1.38931875e-01, -2.24041062e-01, -1.21580271e+00,\n",
       "         1.82789707e+00, -2.37639077e+00,  1.01074824e+00,\n",
       "        -1.45658021e+00,  9.13291427e-01, -4.21154408e-02,\n",
       "        -7.13763333e-01,  3.92767106e-01, -1.56946330e+00,\n",
       "         6.76323191e-01, -2.33751843e+00, -1.23529285e+00,\n",
       "        -2.76723745e-01, -9.50270176e-02, -3.21085244e-01,\n",
       "         4.47645275e-01,  1.12109965e+00,  1.57179856e+00,\n",
       "         4.63971280e-01,  1.30033846e+00, -7.67976480e-01,\n",
       "         7.32598519e-01, -1.26794935e+00,  2.39155025e+00,\n",
       "         4.01811670e-01, -9.52522167e-01, -7.72162684e-01,\n",
       "         4.27661658e-01, -1.08888886e+00, -4.20157096e-01,\n",
       "         4.59203560e-01, -3.44721751e-01,  1.96386750e+00,\n",
       "        -1.61340990e+00,  6.40123358e-01, -4.55898959e-01,\n",
       "        -1.19291293e+00,  1.54716688e+00,  7.49124601e-01,\n",
       "         1.26876476e-01,  1.21561587e+00, -4.75418351e-01,\n",
       "        -2.94905371e-01,  1.22774194e+00, -9.56640379e-02,\n",
       "        -3.08472538e-01,  3.42534251e-01, -9.35115950e-02,\n",
       "        -9.57929656e-01,  5.57636812e-01, -2.77897398e-01,\n",
       "         1.07891956e+00, -2.09651630e-01,  8.96333951e-01,\n",
       "         1.74612561e+00, -6.72143690e-01, -9.55794590e-01,\n",
       "         1.45595696e+00,  3.88214093e-01,  6.70713854e-01,\n",
       "        -9.97635070e-01,  4.48251980e-01,  2.12521641e+00,\n",
       "        -1.00833935e+00,  1.79509160e+00,  1.05868415e+00,\n",
       "        -1.11277214e+00,  5.94837927e-01, -6.13204506e-01,\n",
       "        -3.00734774e-01, -1.20130198e+00, -6.31409462e-01,\n",
       "         7.75579796e-01, -1.01829871e+00,  5.05807211e-01,\n",
       "         2.77019301e-01,  1.17978409e+00, -8.43800341e-01,\n",
       "        -6.17458718e-01,  1.89334230e+00, -1.02724537e+00,\n",
       "         2.25773418e-01, -6.87663591e-01,  1.35685834e+00,\n",
       "         1.93181201e+00,  9.50508233e-01, -1.28284954e+00,\n",
       "         2.47505719e+00, -4.34701463e-01,  3.59555983e-01,\n",
       "         7.75163800e-01,  1.47431257e+00, -4.93163145e-02,\n",
       "        -5.13494837e-01]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generator Input # \n",
    "# - Üblich: Rauschen. Kann aber alles sein... \n",
    "#   => Aus dem Rauschen soll ein Bild entstehen. \n",
    "np.random.normal(0, 1, (2, 100))  # (loc, scale, size(x-Samples, shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b96b8b9e-df98-4b24-bc34-ab6deab850a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8d44813c-48fb-4642-9e93-d09fe42e03f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsschleife # \n",
    "\n",
    "def train(generator, discriminator, gan, train_img, epochs, batch_size):\n",
    "    \n",
    "    half_batch = int(batch_size / 2)  # Ausgleich an Samples für beide Netze. \n",
    "    \n",
    "    for epoch in range(epochs):  # Für jede Epoche mach das:\n",
    "        # Discriminator # \n",
    "        index = np.random.randint(0, train_img.shape[0], half_batch)  # Index für Samples. \n",
    "        real_images = train_img[index]  # Hole Samples.\n",
    "        noise       = np.random.normal(0, 1, (half_batch, 100))  # Erstelle Rauschen als Input. Kann aber auch komplett 0 sein. Üblich: Rauschen.\n",
    "        fake_images = generator.predict(noise)  # Erstelle Prediction. \n",
    "\n",
    "        # Berechne Loss. # Setze Labels.\n",
    "        # - train_on_batch(x, y), beide müssen n-Samples haben. \n",
    "        loss_real = discriminator.train_on_batch(real_images, np.ones(  (half_batch, 1) ))  # Label 1 für n-Samples für echte Bilder. \n",
    "        loss_fake = discriminator.train_on_batch(fake_images, np.zeros( (half_batch, 1) ))  # Label 0 für n-Samples für UN-echte Bilder.\n",
    "        d_loss = 0.5 * np.add(loss_real, loss_fake)  # Schnitt der Beiden Losses. \n",
    "\n",
    "        # Generator # Wie Oben. \n",
    "        noise    = np.random.normal(0, 1, (batch_size, 100))\n",
    "        y        = np.ones(batch_size)\n",
    "        gan_loss = gan.train_on_batch(noise, y)\n",
    "\n",
    "        # Manuelle Ausgabe.:\n",
    "        print(f\"Epoche: {epoch + 1}/{epochs} GAN loss: {gan_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fcd9e492-63b5-4219-8f76-004d9353c9cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step\n",
      "Epoche: 1/700 GAN loss: 0.6848864555358887\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 2/700 GAN loss: 0.9235652685165405\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 3/700 GAN loss: 1.4462690353393555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 4/700 GAN loss: 2.27596116065979\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 5/700 GAN loss: 3.2589735984802246\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 6/700 GAN loss: 4.243983268737793\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 7/700 GAN loss: 5.2005934715271\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 8/700 GAN loss: 6.154271602630615\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 9/700 GAN loss: 6.726434707641602\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 10/700 GAN loss: 7.356412887573242\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 11/700 GAN loss: 7.763110160827637\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 12/700 GAN loss: 8.093952178955078\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 13/700 GAN loss: 8.403820991516113\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 14/700 GAN loss: 8.815652847290039\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 15/700 GAN loss: 9.330961227416992\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 16/700 GAN loss: 9.861953735351562\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 17/700 GAN loss: 10.452150344848633\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 18/700 GAN loss: 11.451362609863281\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 19/700 GAN loss: 12.147927284240723\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 20/700 GAN loss: 12.805093765258789\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 21/700 GAN loss: 13.786515235900879\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 22/700 GAN loss: 14.559585571289062\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 23/700 GAN loss: 14.957928657531738\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 24/700 GAN loss: 15.717094421386719\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 25/700 GAN loss: 16.335716247558594\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 26/700 GAN loss: 18.29189109802246\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 27/700 GAN loss: 17.007469177246094\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 28/700 GAN loss: 16.75322914123535\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 29/700 GAN loss: 16.929798126220703\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 30/700 GAN loss: 16.395408630371094\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 31/700 GAN loss: 16.411815643310547\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 32/700 GAN loss: 16.52595329284668\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 33/700 GAN loss: 17.525493621826172\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 34/700 GAN loss: 19.835674285888672\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 35/700 GAN loss: 17.221633911132812\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 36/700 GAN loss: 15.139193534851074\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 37/700 GAN loss: 13.715166091918945\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 38/700 GAN loss: 16.033906936645508\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 39/700 GAN loss: 19.387508392333984\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 40/700 GAN loss: 22.320592880249023\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 41/700 GAN loss: 24.808574676513672\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 42/700 GAN loss: 13.473068237304688\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 43/700 GAN loss: 11.673587799072266\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 44/700 GAN loss: 9.953415870666504\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 45/700 GAN loss: 12.396557807922363\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 46/700 GAN loss: 19.958776473999023\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 47/700 GAN loss: 29.732919692993164\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 48/700 GAN loss: 36.79058837890625\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 49/700 GAN loss: 28.64609718322754\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 50/700 GAN loss: 19.734970092773438\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 51/700 GAN loss: 14.712992668151855\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 52/700 GAN loss: 14.107247352600098\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 53/700 GAN loss: 15.938132286071777\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 54/700 GAN loss: 24.228260040283203\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 55/700 GAN loss: 13.825467109680176\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 56/700 GAN loss: 13.955058097839355\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 57/700 GAN loss: 12.33902359008789\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 58/700 GAN loss: 11.890623092651367\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 59/700 GAN loss: 14.238059997558594\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 60/700 GAN loss: 15.847075462341309\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 61/700 GAN loss: 27.617103576660156\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 62/700 GAN loss: 39.87827682495117\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 63/700 GAN loss: 44.14763259887695\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 64/700 GAN loss: 52.16448211669922\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 65/700 GAN loss: 51.91902160644531\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 66/700 GAN loss: 33.55675506591797\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 67/700 GAN loss: 18.461729049682617\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 68/700 GAN loss: 9.454638481140137\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 69/700 GAN loss: 6.6774091720581055\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 70/700 GAN loss: 7.074187278747559\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 71/700 GAN loss: 7.3665266036987305\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 72/700 GAN loss: 6.186069488525391\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 73/700 GAN loss: 8.26076889038086\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 74/700 GAN loss: 9.546489715576172\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 75/700 GAN loss: 13.490345001220703\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 76/700 GAN loss: 17.953857421875\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 77/700 GAN loss: 23.06615447998047\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 78/700 GAN loss: 15.808881759643555\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 79/700 GAN loss: 9.072612762451172\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 80/700 GAN loss: 8.614302635192871\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 81/700 GAN loss: 7.456640243530273\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 82/700 GAN loss: 6.917603492736816\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 83/700 GAN loss: 8.498662948608398\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 84/700 GAN loss: 8.20305061340332\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 85/700 GAN loss: 13.742181777954102\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 86/700 GAN loss: 17.337291717529297\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 87/700 GAN loss: 17.82362937927246\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 88/700 GAN loss: 8.962325096130371\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 89/700 GAN loss: 5.718550682067871\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 90/700 GAN loss: 5.511441230773926\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 91/700 GAN loss: 4.5987420082092285\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 92/700 GAN loss: 4.289431571960449\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 93/700 GAN loss: 4.154730319976807\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 94/700 GAN loss: 4.798032760620117\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 95/700 GAN loss: 6.004870414733887\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 96/700 GAN loss: 8.80510139465332\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 97/700 GAN loss: 12.172431945800781\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 98/700 GAN loss: 8.343605041503906\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 99/700 GAN loss: 5.943718910217285\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 100/700 GAN loss: 4.620296478271484\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 101/700 GAN loss: 4.308602333068848\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 102/700 GAN loss: 4.3958659172058105\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 103/700 GAN loss: 4.274954795837402\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 104/700 GAN loss: 5.498208999633789\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 105/700 GAN loss: 7.235762596130371\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 106/700 GAN loss: 5.93559455871582\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 107/700 GAN loss: 5.086176872253418\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 108/700 GAN loss: 4.700897216796875\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 109/700 GAN loss: 4.838034629821777\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 110/700 GAN loss: 5.657942771911621\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 111/700 GAN loss: 6.7685160636901855\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 112/700 GAN loss: 4.8478288650512695\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 113/700 GAN loss: 4.753075122833252\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 114/700 GAN loss: 5.227439880371094\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 115/700 GAN loss: 6.5481462478637695\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 116/700 GAN loss: 5.5216593742370605\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 117/700 GAN loss: 6.083105087280273\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 118/700 GAN loss: 6.545401573181152\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 119/700 GAN loss: 7.4122700691223145\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 120/700 GAN loss: 5.985316276550293\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 121/700 GAN loss: 6.351287841796875\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 122/700 GAN loss: 7.698529243469238\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 123/700 GAN loss: 9.587669372558594\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 124/700 GAN loss: 6.68502140045166\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 125/700 GAN loss: 5.502832412719727\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 126/700 GAN loss: 7.374368667602539\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 127/700 GAN loss: 10.05405044555664\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 128/700 GAN loss: 10.374885559082031\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 129/700 GAN loss: 8.649325370788574\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 130/700 GAN loss: 8.160274505615234\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 131/700 GAN loss: 8.178879737854004\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 132/700 GAN loss: 8.190349578857422\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 133/700 GAN loss: 6.924114227294922\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 134/700 GAN loss: 6.939800262451172\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 135/700 GAN loss: 7.533277988433838\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 136/700 GAN loss: 3.9919915199279785\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 137/700 GAN loss: 4.196048736572266\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 138/700 GAN loss: 4.3835649490356445\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 139/700 GAN loss: 8.115449905395508\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 140/700 GAN loss: 11.674382209777832\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 141/700 GAN loss: 5.679590702056885\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 142/700 GAN loss: 3.5728211402893066\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 143/700 GAN loss: 3.7092559337615967\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 144/700 GAN loss: 4.801525115966797\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 145/700 GAN loss: 8.816672325134277\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 146/700 GAN loss: 11.265199661254883\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 147/700 GAN loss: 11.144604682922363\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 148/700 GAN loss: 10.574520111083984\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 149/700 GAN loss: 8.855388641357422\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 150/700 GAN loss: 8.585959434509277\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 151/700 GAN loss: 8.386653900146484\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 152/700 GAN loss: 8.47491455078125\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 153/700 GAN loss: 8.72637939453125\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 154/700 GAN loss: 9.420341491699219\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 155/700 GAN loss: 9.570456504821777\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 156/700 GAN loss: 9.039734840393066\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 157/700 GAN loss: 7.1151442527771\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 158/700 GAN loss: 6.927902698516846\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 159/700 GAN loss: 6.272957801818848\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 160/700 GAN loss: 7.400373935699463\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 161/700 GAN loss: 7.595269203186035\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 162/700 GAN loss: 6.9689531326293945\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 163/700 GAN loss: 6.494719505310059\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 164/700 GAN loss: 6.298135757446289\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 165/700 GAN loss: 6.407501220703125\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 166/700 GAN loss: 6.829466819763184\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 167/700 GAN loss: 6.346194744110107\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 168/700 GAN loss: 5.993758678436279\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 169/700 GAN loss: 5.819904327392578\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 170/700 GAN loss: 5.923416614532471\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 171/700 GAN loss: 6.294100761413574\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 172/700 GAN loss: 6.128492832183838\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 173/700 GAN loss: 5.274738311767578\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 174/700 GAN loss: 6.0323052406311035\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 175/700 GAN loss: 6.329678535461426\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 176/700 GAN loss: 6.59760856628418\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 177/700 GAN loss: 5.6775031089782715\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 178/700 GAN loss: 5.976290702819824\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 179/700 GAN loss: 5.95972204208374\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 180/700 GAN loss: 6.022268772125244\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 181/700 GAN loss: 6.388745307922363\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 182/700 GAN loss: 6.092168807983398\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 183/700 GAN loss: 5.845605850219727\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 184/700 GAN loss: 5.915683269500732\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 185/700 GAN loss: 5.836647987365723\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 186/700 GAN loss: 6.384652137756348\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 187/700 GAN loss: 6.659918785095215\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 188/700 GAN loss: 6.666696071624756\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 189/700 GAN loss: 6.638806343078613\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 190/700 GAN loss: 6.516841888427734\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 191/700 GAN loss: 6.675111770629883\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 192/700 GAN loss: 6.899492263793945\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 193/700 GAN loss: 6.793239116668701\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 194/700 GAN loss: 6.631356239318848\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 195/700 GAN loss: 7.254270553588867\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 196/700 GAN loss: 7.200162887573242\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 197/700 GAN loss: 6.5318708419799805\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 198/700 GAN loss: 6.409685134887695\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 199/700 GAN loss: 6.327808856964111\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 200/700 GAN loss: 7.061127662658691\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 201/700 GAN loss: 6.007372856140137\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 202/700 GAN loss: 6.643689155578613\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 203/700 GAN loss: 7.2543721199035645\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 204/700 GAN loss: 6.04090690612793\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 205/700 GAN loss: 6.440610408782959\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 206/700 GAN loss: 7.555131912231445\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 207/700 GAN loss: 6.965683460235596\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 208/700 GAN loss: 6.362462043762207\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 209/700 GAN loss: 6.619128704071045\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 210/700 GAN loss: 7.0491766929626465\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 211/700 GAN loss: 6.460575103759766\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 212/700 GAN loss: 6.559420108795166\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 213/700 GAN loss: 7.771331787109375\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 214/700 GAN loss: 3.4721198081970215\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 215/700 GAN loss: 3.4758403301239014\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 216/700 GAN loss: 7.215496063232422\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 217/700 GAN loss: 12.547547340393066\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 218/700 GAN loss: 2.2628490924835205\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 219/700 GAN loss: 0.9914628267288208\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 220/700 GAN loss: 1.1834197044372559\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 221/700 GAN loss: 2.2951855659484863\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 222/700 GAN loss: 8.016702651977539\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 223/700 GAN loss: 14.690787315368652\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 224/700 GAN loss: 11.962201118469238\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 225/700 GAN loss: 9.832006454467773\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 226/700 GAN loss: 7.935732841491699\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 227/700 GAN loss: 7.85527229309082\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 228/700 GAN loss: 8.598930358886719\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 229/700 GAN loss: 8.806520462036133\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 230/700 GAN loss: 12.070486068725586\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 231/700 GAN loss: 14.234644889831543\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 232/700 GAN loss: 14.695340156555176\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 233/700 GAN loss: 12.848808288574219\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 234/700 GAN loss: 10.107580184936523\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 235/700 GAN loss: 7.857265472412109\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 236/700 GAN loss: 7.607516765594482\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 237/700 GAN loss: 6.351706504821777\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 238/700 GAN loss: 7.271566867828369\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 239/700 GAN loss: 8.131799697875977\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 240/700 GAN loss: 8.08652114868164\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 241/700 GAN loss: 6.141772270202637\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 242/700 GAN loss: 6.043698310852051\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 243/700 GAN loss: 6.867480278015137\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 244/700 GAN loss: 7.56334114074707\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 245/700 GAN loss: 4.335806846618652\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 246/700 GAN loss: 3.901892900466919\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 247/700 GAN loss: 6.154580116271973\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 248/700 GAN loss: 8.689573287963867\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 249/700 GAN loss: 3.061464548110962\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 250/700 GAN loss: 1.569135069847107\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 251/700 GAN loss: 3.6075572967529297\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 252/700 GAN loss: 10.17386245727539\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 253/700 GAN loss: 12.74525260925293\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 254/700 GAN loss: 3.5697407722473145\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 255/700 GAN loss: 1.3282124996185303\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 256/700 GAN loss: 1.6926970481872559\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 257/700 GAN loss: 6.080650329589844\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 258/700 GAN loss: 10.44565486907959\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 259/700 GAN loss: 9.469240188598633\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 260/700 GAN loss: 6.418617248535156\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 261/700 GAN loss: 4.942958354949951\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 262/700 GAN loss: 4.545916557312012\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 263/700 GAN loss: 4.169506072998047\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 264/700 GAN loss: 6.462635517120361\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 265/700 GAN loss: 7.377744197845459\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 266/700 GAN loss: 3.2811973094940186\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 267/700 GAN loss: 2.5598807334899902\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 268/700 GAN loss: 3.8213443756103516\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 269/700 GAN loss: 6.339676856994629\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 270/700 GAN loss: 2.370560884475708\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 271/700 GAN loss: 1.210496425628662\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 272/700 GAN loss: 2.9383623600006104\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 273/700 GAN loss: 5.910724639892578\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 274/700 GAN loss: 8.370157241821289\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 275/700 GAN loss: 3.129056692123413\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 276/700 GAN loss: 1.970184326171875\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 277/700 GAN loss: 2.027360677719116\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 278/700 GAN loss: 4.232169151306152\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 279/700 GAN loss: 7.312441825866699\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 280/700 GAN loss: 4.216395378112793\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 281/700 GAN loss: 2.6102395057678223\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 282/700 GAN loss: 2.971034526824951\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 283/700 GAN loss: 4.7522172927856445\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 284/700 GAN loss: 5.44746208190918\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 285/700 GAN loss: 2.6231069564819336\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 286/700 GAN loss: 2.6856977939605713\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 287/700 GAN loss: 4.530421257019043\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 288/700 GAN loss: 4.681040287017822\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 289/700 GAN loss: 2.132396936416626\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 290/700 GAN loss: 2.734372615814209\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 291/700 GAN loss: 6.239696502685547\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 292/700 GAN loss: 1.1310440301895142\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 293/700 GAN loss: 0.732447624206543\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 294/700 GAN loss: 2.971479892730713\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 295/700 GAN loss: 10.334095001220703\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 296/700 GAN loss: 2.870631217956543\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 297/700 GAN loss: 1.3085594177246094\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 298/700 GAN loss: 1.6597189903259277\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 299/700 GAN loss: 4.249872207641602\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 300/700 GAN loss: 8.646869659423828\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 301/700 GAN loss: 5.496110916137695\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 302/700 GAN loss: 2.8885037899017334\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 303/700 GAN loss: 2.3493549823760986\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 304/700 GAN loss: 2.4347879886627197\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 305/700 GAN loss: 3.8535776138305664\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 306/700 GAN loss: 4.7509284019470215\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 307/700 GAN loss: 3.797049045562744\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 308/700 GAN loss: 2.787632465362549\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 309/700 GAN loss: 2.356179714202881\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 310/700 GAN loss: 3.4208831787109375\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 311/700 GAN loss: 3.3537631034851074\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 312/700 GAN loss: 3.1921751499176025\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 313/700 GAN loss: 2.640072822570801\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 314/700 GAN loss: 2.970287322998047\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 315/700 GAN loss: 1.9931390285491943\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 316/700 GAN loss: 2.4223177433013916\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 317/700 GAN loss: 3.206310987472534\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 318/700 GAN loss: 1.9527535438537598\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 319/700 GAN loss: 2.4788060188293457\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 320/700 GAN loss: 4.4402618408203125\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 321/700 GAN loss: 2.059028148651123\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 322/700 GAN loss: 2.7381653785705566\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 323/700 GAN loss: 5.996251106262207\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 324/700 GAN loss: 1.338374137878418\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 325/700 GAN loss: 2.536661148071289\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 326/700 GAN loss: 8.517162322998047\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 327/700 GAN loss: 1.6385018825531006\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 328/700 GAN loss: 1.4419318437576294\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 329/700 GAN loss: 4.5751752853393555\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 330/700 GAN loss: 11.74276351928711\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 331/700 GAN loss: 2.6874876022338867\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 332/700 GAN loss: 1.103926658630371\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 333/700 GAN loss: 2.3252105712890625\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 334/700 GAN loss: 6.884838104248047\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 335/700 GAN loss: 10.502218246459961\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 336/700 GAN loss: 2.7470269203186035\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 337/700 GAN loss: 1.089829921722412\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 338/700 GAN loss: 2.152956962585449\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 339/700 GAN loss: 5.102973937988281\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 340/700 GAN loss: 8.399124145507812\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 341/700 GAN loss: 6.202235698699951\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 342/700 GAN loss: 3.6698291301727295\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 343/700 GAN loss: 2.264749050140381\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 344/700 GAN loss: 2.747666835784912\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 345/700 GAN loss: 3.8312480449676514\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 346/700 GAN loss: 5.119260787963867\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 347/700 GAN loss: 5.54817008972168\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 348/700 GAN loss: 3.7862777709960938\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 349/700 GAN loss: 3.0476417541503906\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 350/700 GAN loss: 2.9540576934814453\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 351/700 GAN loss: 3.8995606899261475\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 352/700 GAN loss: 3.9373233318328857\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 353/700 GAN loss: 2.6783218383789062\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 354/700 GAN loss: 3.0383853912353516\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 355/700 GAN loss: 3.833158493041992\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 356/700 GAN loss: 1.796386957168579\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 357/700 GAN loss: 3.3980612754821777\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 358/700 GAN loss: 3.5937724113464355\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 359/700 GAN loss: 2.3530211448669434\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 360/700 GAN loss: 3.4736199378967285\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 361/700 GAN loss: 2.161391258239746\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 362/700 GAN loss: 3.83772611618042\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 363/700 GAN loss: 2.3320319652557373\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 364/700 GAN loss: 3.36818265914917\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 365/700 GAN loss: 3.2039265632629395\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 366/700 GAN loss: 2.6178760528564453\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 367/700 GAN loss: 3.182424545288086\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 368/700 GAN loss: 2.8436121940612793\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 369/700 GAN loss: 3.9772212505340576\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 370/700 GAN loss: 2.8394622802734375\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 371/700 GAN loss: 3.33423113822937\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 372/700 GAN loss: 3.3736648559570312\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 373/700 GAN loss: 2.8029322624206543\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 374/700 GAN loss: 2.801701068878174\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 375/700 GAN loss: 2.577789545059204\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 376/700 GAN loss: 2.506560802459717\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 377/700 GAN loss: 3.7886874675750732\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 378/700 GAN loss: 2.1882553100585938\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 379/700 GAN loss: 2.9880928993225098\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 380/700 GAN loss: 3.397023916244507\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 381/700 GAN loss: 2.8368735313415527\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 382/700 GAN loss: 3.852414131164551\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 383/700 GAN loss: 2.420466423034668\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 384/700 GAN loss: 3.9729421138763428\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 385/700 GAN loss: 3.259706974029541\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 386/700 GAN loss: 3.895991325378418\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 387/700 GAN loss: 4.262989521026611\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 388/700 GAN loss: 3.8906848430633545\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 389/700 GAN loss: 4.591060161590576\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 390/700 GAN loss: 3.8151512145996094\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 391/700 GAN loss: 4.634757041931152\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 392/700 GAN loss: 2.7264254093170166\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 393/700 GAN loss: 4.392443656921387\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 394/700 GAN loss: 3.38871431350708\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 395/700 GAN loss: 3.59633731842041\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 396/700 GAN loss: 3.8699591159820557\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 397/700 GAN loss: 3.4948995113372803\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 398/700 GAN loss: 4.771611213684082\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 399/700 GAN loss: 3.937300682067871\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 400/700 GAN loss: 4.912715435028076\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 401/700 GAN loss: 2.485581874847412\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 402/700 GAN loss: 5.964143753051758\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 403/700 GAN loss: 1.9162366390228271\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 404/700 GAN loss: 3.233776569366455\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 405/700 GAN loss: 6.374483108520508\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 406/700 GAN loss: 0.9792425632476807\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 407/700 GAN loss: 0.9275796413421631\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 408/700 GAN loss: 2.3941450119018555\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 409/700 GAN loss: 6.100395202636719\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 410/700 GAN loss: 2.376094341278076\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 411/700 GAN loss: 1.1011143922805786\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 412/700 GAN loss: 1.068263292312622\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 413/700 GAN loss: 2.313199043273926\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 414/700 GAN loss: 2.4817311763763428\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 415/700 GAN loss: 1.4063466787338257\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 416/700 GAN loss: 1.0542199611663818\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 417/700 GAN loss: 1.3468972444534302\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 418/700 GAN loss: 2.250932216644287\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 419/700 GAN loss: 2.6519594192504883\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 420/700 GAN loss: 1.7216166257858276\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 421/700 GAN loss: 1.364999771118164\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 422/700 GAN loss: 1.6502054929733276\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 423/700 GAN loss: 2.2597639560699463\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 424/700 GAN loss: 2.528271436691284\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 425/700 GAN loss: 1.9226394891738892\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 426/700 GAN loss: 1.9071877002716064\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 427/700 GAN loss: 2.2448158264160156\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 428/700 GAN loss: 2.3082573413848877\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 429/700 GAN loss: 2.085275650024414\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 430/700 GAN loss: 2.1455085277557373\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 431/700 GAN loss: 2.0529417991638184\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 432/700 GAN loss: 2.1967949867248535\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 433/700 GAN loss: 2.38731050491333\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 434/700 GAN loss: 2.3560948371887207\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 435/700 GAN loss: 2.0417888164520264\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 436/700 GAN loss: 2.059971332550049\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 437/700 GAN loss: 2.415910482406616\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 438/700 GAN loss: 2.2003164291381836\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 439/700 GAN loss: 2.052389621734619\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 440/700 GAN loss: 2.1513993740081787\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 441/700 GAN loss: 2.1620864868164062\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 442/700 GAN loss: 2.1764698028564453\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 443/700 GAN loss: 2.390766143798828\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 444/700 GAN loss: 2.351170063018799\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 445/700 GAN loss: 1.948186993598938\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 446/700 GAN loss: 1.9130444526672363\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 447/700 GAN loss: 3.020575523376465\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 448/700 GAN loss: 2.173522710800171\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 449/700 GAN loss: 1.866520881652832\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 450/700 GAN loss: 2.2151219844818115\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 451/700 GAN loss: 2.7092175483703613\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 452/700 GAN loss: 1.8113529682159424\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 453/700 GAN loss: 2.009462833404541\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 454/700 GAN loss: 2.6471118927001953\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 455/700 GAN loss: 1.5950860977172852\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 456/700 GAN loss: 2.2094600200653076\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 457/700 GAN loss: 2.593031883239746\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 458/700 GAN loss: 1.759778618812561\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 459/700 GAN loss: 2.1089110374450684\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 460/700 GAN loss: 2.5136098861694336\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 461/700 GAN loss: 1.5128201246261597\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 462/700 GAN loss: 2.1157190799713135\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 463/700 GAN loss: 2.849817991256714\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 464/700 GAN loss: 1.6097745895385742\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 465/700 GAN loss: 2.2744884490966797\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 466/700 GAN loss: 2.3919737339019775\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 467/700 GAN loss: 2.0861291885375977\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 468/700 GAN loss: 2.538917064666748\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 469/700 GAN loss: 1.7452348470687866\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 470/700 GAN loss: 1.9938760995864868\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 471/700 GAN loss: 2.203097343444824\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 472/700 GAN loss: 2.1959028244018555\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 473/700 GAN loss: 2.5207979679107666\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 474/700 GAN loss: 2.0356674194335938\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 475/700 GAN loss: 2.7080962657928467\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 476/700 GAN loss: 2.0421454906463623\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 477/700 GAN loss: 2.637171506881714\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 478/700 GAN loss: 2.706908702850342\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 479/700 GAN loss: 2.3152832984924316\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 480/700 GAN loss: 2.3631839752197266\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 481/700 GAN loss: 2.6540284156799316\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 482/700 GAN loss: 1.9935100078582764\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 483/700 GAN loss: 2.4610610008239746\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 484/700 GAN loss: 2.1284093856811523\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 485/700 GAN loss: 2.067319393157959\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 486/700 GAN loss: 2.0311126708984375\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 487/700 GAN loss: 2.065181255340576\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 488/700 GAN loss: 2.068347692489624\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 489/700 GAN loss: 2.007742166519165\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 490/700 GAN loss: 2.040405511856079\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 491/700 GAN loss: 2.2712242603302\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 492/700 GAN loss: 2.1034317016601562\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 493/700 GAN loss: 2.0683815479278564\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 494/700 GAN loss: 1.7593705654144287\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 495/700 GAN loss: 1.82053804397583\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 496/700 GAN loss: 1.744517207145691\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 497/700 GAN loss: 1.7524687051773071\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 498/700 GAN loss: 1.9632679224014282\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 499/700 GAN loss: 1.4984755516052246\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 500/700 GAN loss: 1.5353924036026\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 501/700 GAN loss: 2.643234968185425\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 502/700 GAN loss: 1.2440452575683594\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 503/700 GAN loss: 2.2298243045806885\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 504/700 GAN loss: 1.613105297088623\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 505/700 GAN loss: 1.1803045272827148\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 506/700 GAN loss: 1.6956106424331665\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 507/700 GAN loss: 1.9515607357025146\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 508/700 GAN loss: 1.2564274072647095\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 509/700 GAN loss: 1.7793364524841309\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 510/700 GAN loss: 2.4807071685791016\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 511/700 GAN loss: 1.5770756006240845\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 512/700 GAN loss: 2.019184112548828\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 513/700 GAN loss: 2.366591453552246\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 514/700 GAN loss: 1.676119089126587\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 515/700 GAN loss: 1.5244953632354736\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 516/700 GAN loss: 2.0192031860351562\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 517/700 GAN loss: 1.5672255754470825\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 518/700 GAN loss: 1.7171509265899658\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 519/700 GAN loss: 1.607839584350586\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 520/700 GAN loss: 1.7629003524780273\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 521/700 GAN loss: 1.4910203218460083\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 522/700 GAN loss: 1.902326226234436\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 523/700 GAN loss: 1.8021756410598755\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 524/700 GAN loss: 1.6298084259033203\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 525/700 GAN loss: 1.7430665493011475\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 526/700 GAN loss: 1.972074270248413\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 527/700 GAN loss: 1.9841563701629639\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 528/700 GAN loss: 1.9671472311019897\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 529/700 GAN loss: 1.9026250839233398\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 530/700 GAN loss: 2.3533949851989746\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 531/700 GAN loss: 1.4665297269821167\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 532/700 GAN loss: 1.313744068145752\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 533/700 GAN loss: 1.6238971948623657\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 534/700 GAN loss: 1.3893024921417236\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 535/700 GAN loss: 1.668742299079895\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 536/700 GAN loss: 1.855509638786316\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 537/700 GAN loss: 1.7176308631896973\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 538/700 GAN loss: 1.7944862842559814\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 539/700 GAN loss: 1.7093498706817627\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 540/700 GAN loss: 1.797994613647461\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 541/700 GAN loss: 1.4755403995513916\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 542/700 GAN loss: 1.9127689599990845\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 543/700 GAN loss: 1.7625455856323242\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 544/700 GAN loss: 1.635810375213623\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 545/700 GAN loss: 1.6845965385437012\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 546/700 GAN loss: 1.8345918655395508\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 547/700 GAN loss: 1.8096784353256226\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 548/700 GAN loss: 1.5399340391159058\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 549/700 GAN loss: 1.272071361541748\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 550/700 GAN loss: 1.860695719718933\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 551/700 GAN loss: 1.9273602962493896\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 552/700 GAN loss: 1.406595230102539\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 553/700 GAN loss: 1.6814498901367188\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 554/700 GAN loss: 1.8476369380950928\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 555/700 GAN loss: 1.4612798690795898\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 556/700 GAN loss: 2.034381866455078\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 557/700 GAN loss: 1.2830630540847778\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 558/700 GAN loss: 1.355177640914917\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 559/700 GAN loss: 1.7774856090545654\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 560/700 GAN loss: 0.8198575377464294\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 561/700 GAN loss: 1.434277057647705\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 562/700 GAN loss: 1.8443138599395752\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 563/700 GAN loss: 1.014073371887207\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 564/700 GAN loss: 1.3502347469329834\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 565/700 GAN loss: 1.524772047996521\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 566/700 GAN loss: 1.2767727375030518\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 567/700 GAN loss: 1.264995813369751\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 568/700 GAN loss: 1.4832409620285034\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 569/700 GAN loss: 1.426401972770691\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 570/700 GAN loss: 1.109987735748291\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 571/700 GAN loss: 1.5570423603057861\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 572/700 GAN loss: 1.2424532175064087\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 573/700 GAN loss: 1.1840183734893799\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 574/700 GAN loss: 1.5303785800933838\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 575/700 GAN loss: 1.3596711158752441\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 576/700 GAN loss: 0.9813545942306519\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 577/700 GAN loss: 1.307197093963623\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 578/700 GAN loss: 1.4440945386886597\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 579/700 GAN loss: 1.3256454467773438\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 580/700 GAN loss: 1.0088155269622803\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 581/700 GAN loss: 1.4270612001419067\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 582/700 GAN loss: 1.3736658096313477\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 583/700 GAN loss: 1.366044521331787\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 584/700 GAN loss: 1.1555535793304443\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 585/700 GAN loss: 1.3270678520202637\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 586/700 GAN loss: 1.7274112701416016\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 587/700 GAN loss: 1.290618896484375\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 588/700 GAN loss: 1.2801172733306885\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 589/700 GAN loss: 1.7339422702789307\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 590/700 GAN loss: 1.5315439701080322\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 591/700 GAN loss: 1.2548675537109375\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 592/700 GAN loss: 1.3207674026489258\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 593/700 GAN loss: 1.4021987915039062\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 594/700 GAN loss: 1.579996109008789\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 595/700 GAN loss: 0.9912340641021729\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 596/700 GAN loss: 1.1867766380310059\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 597/700 GAN loss: 1.2648189067840576\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 598/700 GAN loss: 1.2538294792175293\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 599/700 GAN loss: 1.1744557619094849\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 600/700 GAN loss: 1.319286584854126\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 601/700 GAN loss: 1.360168695449829\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 602/700 GAN loss: 1.219531774520874\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 603/700 GAN loss: 1.2125791311264038\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 604/700 GAN loss: 1.2547178268432617\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 605/700 GAN loss: 1.1925251483917236\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 606/700 GAN loss: 1.3325974941253662\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 607/700 GAN loss: 1.2962148189544678\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 608/700 GAN loss: 1.2666294574737549\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 609/700 GAN loss: 1.2084333896636963\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 610/700 GAN loss: 1.3261927366256714\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 611/700 GAN loss: 1.3176686763763428\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 612/700 GAN loss: 1.2737617492675781\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 613/700 GAN loss: 1.2752677202224731\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 614/700 GAN loss: 1.0957380533218384\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 615/700 GAN loss: 1.2189998626708984\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 616/700 GAN loss: 1.281294584274292\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 617/700 GAN loss: 1.30625581741333\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 618/700 GAN loss: 1.1621249914169312\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 619/700 GAN loss: 1.1685305833816528\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 620/700 GAN loss: 1.356693983078003\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 621/700 GAN loss: 1.3990670442581177\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 622/700 GAN loss: 1.1314876079559326\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 623/700 GAN loss: 1.0630154609680176\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 624/700 GAN loss: 1.216726303100586\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 625/700 GAN loss: 1.3435423374176025\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 626/700 GAN loss: 1.114119529724121\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 627/700 GAN loss: 1.074363112449646\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 628/700 GAN loss: 1.4130055904388428\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 629/700 GAN loss: 1.2161449193954468\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 630/700 GAN loss: 1.114654779434204\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 631/700 GAN loss: 0.9970493316650391\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 632/700 GAN loss: 0.9891215562820435\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 633/700 GAN loss: 1.304286003112793\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 634/700 GAN loss: 1.1266300678253174\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 635/700 GAN loss: 1.094555139541626\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 636/700 GAN loss: 0.9978208541870117\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 637/700 GAN loss: 1.0922932624816895\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 638/700 GAN loss: 1.07177734375\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 639/700 GAN loss: 1.0733342170715332\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 640/700 GAN loss: 1.0312360525131226\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 641/700 GAN loss: 1.1730308532714844\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 642/700 GAN loss: 1.1225717067718506\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 643/700 GAN loss: 0.8907936811447144\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 644/700 GAN loss: 0.9866222143173218\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 645/700 GAN loss: 1.2296687364578247\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 646/700 GAN loss: 1.1698658466339111\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 647/700 GAN loss: 1.1152185201644897\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 648/700 GAN loss: 0.9853749871253967\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 649/700 GAN loss: 1.1269962787628174\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 650/700 GAN loss: 1.1906476020812988\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 651/700 GAN loss: 1.1238781213760376\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 652/700 GAN loss: 1.0692154169082642\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 653/700 GAN loss: 1.0266485214233398\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 654/700 GAN loss: 1.0637001991271973\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 655/700 GAN loss: 1.149730920791626\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 656/700 GAN loss: 1.1723135709762573\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 657/700 GAN loss: 1.0878217220306396\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 658/700 GAN loss: 1.1727430820465088\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 659/700 GAN loss: 1.2142398357391357\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 660/700 GAN loss: 1.047467589378357\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 661/700 GAN loss: 1.0314350128173828\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 662/700 GAN loss: 1.0197482109069824\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 663/700 GAN loss: 1.0283043384552002\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 664/700 GAN loss: 1.024774432182312\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 665/700 GAN loss: 1.1246678829193115\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 666/700 GAN loss: 1.2213294506072998\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 667/700 GAN loss: 1.0531810522079468\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 668/700 GAN loss: 0.9138335585594177\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 669/700 GAN loss: 1.022580623626709\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 670/700 GAN loss: 1.0225000381469727\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 671/700 GAN loss: 1.0232328176498413\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 672/700 GAN loss: 0.9730175733566284\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 673/700 GAN loss: 0.928516149520874\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 674/700 GAN loss: 1.101367473602295\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 675/700 GAN loss: 1.2491792440414429\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 676/700 GAN loss: 1.1085600852966309\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 677/700 GAN loss: 1.0024185180664062\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 678/700 GAN loss: 1.0200159549713135\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 679/700 GAN loss: 1.020415186882019\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 680/700 GAN loss: 1.0663822889328003\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 681/700 GAN loss: 1.100595235824585\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 682/700 GAN loss: 1.0909748077392578\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 683/700 GAN loss: 1.0140128135681152\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 684/700 GAN loss: 1.0974828004837036\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 685/700 GAN loss: 1.170570731163025\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 686/700 GAN loss: 1.026465654373169\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 687/700 GAN loss: 0.9507436156272888\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 688/700 GAN loss: 1.0303163528442383\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 689/700 GAN loss: 0.9170137643814087\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 690/700 GAN loss: 1.0134572982788086\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 691/700 GAN loss: 1.0666933059692383\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 692/700 GAN loss: 1.074371099472046\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 693/700 GAN loss: 0.9474228620529175\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 694/700 GAN loss: 0.8577420711517334\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 695/700 GAN loss: 0.8306000828742981\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 696/700 GAN loss: 1.022403597831726\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 697/700 GAN loss: 1.008824348449707\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 698/700 GAN loss: 0.93144291639328\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 699/700 GAN loss: 0.7910913228988647\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 700/700 GAN loss: 0.9519736766815186\n"
     ]
    }
   ],
   "source": [
    "train(generator, discriminator, GAN, dataset_numpy_scaled, epochs=700, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0059ec67-69b1-4b32-968b-57fedae897bd",
   "metadata": {},
   "source": [
    "<h2>Erzeuge Bilder</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7a6ef3-a782-4b8a-ab54-57e78d1a4206",
   "metadata": {},
   "source": [
    "So, das Training ist beendet, wie können wir aber jetzt Bilder erzeugen? <br>\n",
    "Dazu geben wir dem Generator ein Startbild als Vektor, daraus soll dann Schritt für Schritt das Bild erzeugt werden. Später muss der Vektor durch das Netz oder Manuell in  die richtige Form gebracht werden.\n",
    "- Die Skalierung des Bildes sollte vor dem Plotten umgekehrt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8629f730-0ab8-4acb-a709-fc2f2ef9f96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeuge Bild und gebe als array zurück.\n",
    "def generate_img(noise, generator) -> np.array:\n",
    "    image = generator.predict(noise)  # Gebe Startbild => Netz => Prediction \n",
    "    image = 0.5 * image + 0.5  # Kehre die Skalierung um. \n",
    "    image = image.reshape((20,20,1))\n",
    "    return image\n",
    "\n",
    "# Plote Bild. \n",
    "def plot_image(img:np.array, gray=False):\n",
    "    plt.figure(figsize=(3,3))\n",
    "    if gray:\n",
    "        plt.imshow(img,  cmap='gray')\n",
    "    else:\n",
    "         plt.imshow(img)\n",
    "    plt.xlabel('X-Pixel')\n",
    "    plt.ylabel(\"Y-Pixel\")\n",
    "    plt.title(\"Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9f3c6ad1-1c3d-49b4-8838-23503a54e99d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Startbild.\n",
    "start_img = np.random.normal(0, 1, (1, 100)).reshape((10,10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "72918f47-d98a-4450-a7dd-d263e98caf2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Oder als schwarz/weiß.\n",
    "plot_image(start_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ed044e6e-bf77-469b-8b93-d3d575d0cf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_img_2 = np.random.normal(0, 0, (1, 100)).reshape((10,10, 1))\n",
    "plot_image(start_img_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cd0dc427-3b37-4dfe-bad8-ac6fe14f47a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_img = np.random.normal(0, 1, (1, 100))\n",
    "img = generate_img(start_img, gen_ann)\n",
    "plot_image(img, gray=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4e5594-68e2-4689-9fd5-3957e8f3e7e2",
   "metadata": {},
   "source": [
    "Was passiert wenn immer der gleiche Input gegeben wird? \n",
    "- Die Prediction-Funktion (Netz und Parameter) liefert immer dasselbe Ergebnis => Koeffizienten sind statisch genau wie Bias, daher kommt immer das gleiche heraus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "01bed838-5fc9-4a0d-9c92-1c6669de3694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Nehme selben Input.\n",
    "img = generate_img(start_img, gen_ann)\n",
    "plot_image(img, gray=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "76f17fba-7fbd-4f2c-bf42-4e965fa62793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "y_true = generate_img(start_img, gen_ann).reshape((400,))\n",
    "\n",
    "y_pred = [generate_img(start_img, gen_ann).reshape((400,)) for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ee0e3dbd-98f4-400b-8e7b-f47018d28634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(y_pred)):\n",
    "    print(np.array_equal(y_true, y_pred[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2986ccc-d3e4-457e-bf05-717f551182f4",
   "metadata": {},
   "source": [
    "Durch den Einbau von Seeds Dropouts und weitere Elementen kann eine Dynamik miteingebracht werden, damit jedes nachfolgende Bild sich von den vorherigen unterscheidet. \n",
    "- `np.random.normal` erzeugt immer einen anderen Input für das Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07c6d02-1db9-4078-9b31-f14f34f7fe15",
   "metadata": {},
   "source": [
    "<h2>Speichere Bilder während des Trainings</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1deb544-fee2-47d2-984f-fdbef3386e55",
   "metadata": {},
   "source": [
    "Während des Trainings können die Bilder nach n-Epochen gespeichert werden, um die Entwicklung sichtbar zu machen. <br>\n",
    "Auch Möglich: <br>\n",
    "- Vergleiche Vektoren: wie ähnlich sind diese am Ende?\n",
    "- Extrahiere Vektor jedes Layers des Models: Entwicklungsschritte Layer für Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "97ebae3a-2626-400f-b3f4-221d6a9e8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img(img, epoch):\n",
    "    img = 0.5 * img + 0.5\n",
    "    matimg.imsave(f'./data/data/1__GAN/img{epoch}.jpeg', img.reshape((20,20)))\n",
    "\n",
    "def train(generator, discriminator, gan, train_img, epochs, batch_size): \n",
    "    half_batch = int(batch_size / 2)  \n",
    "    for epoch in range(epochs):  \n",
    "        index = np.random.randint(0, train_img.shape[0], half_batch)  \n",
    "        real_images = train_img[index]  # Hole Samples.\n",
    "        noise       = np.random.normal(0, 1, (half_batch, 100)) \n",
    "        fake_images = generator.predict(noise)  # Erstelle Prediction. \n",
    "        # Berechne Loss. # Setze Labels.\n",
    "        loss_real = discriminator.train_on_batch(real_images, np.ones(  (half_batch, 1) ))  # Label 1 für n-Samples für echte Bilder. \n",
    "        loss_fake = discriminator.train_on_batch(fake_images, np.zeros( (half_batch, 1) ))  # Label 0 für n-Samples für UN-echte Bilder.\n",
    "        d_loss = 0.5 * np.add(loss_real, loss_fake)  # Schnitt der Beiden Losses. \n",
    "        # Generator # Wie Oben. \n",
    "        noise    = np.random.normal(0, 1, (batch_size, 100))\n",
    "        y        = np.ones(batch_size)\n",
    "        gan_loss = gan.train_on_batch(noise, y)\n",
    "        # Manuelle Ausgabe.:\n",
    "        print(f\"Epoche: {epoch + 1}/{epochs} GAN loss: {gan_loss}\")\n",
    "\n",
    "        if (epoch%200==0) | (epoch+1==epochs):\n",
    "            save_img(fake_images[0], epoch)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "85f7dd13-40da-4dd7-9ba1-6ac0d11674a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = create_discriminator()\n",
    "discriminator.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss      = 'binary_crossentropy',\n",
    "    metrics   = 'accuracy'\n",
    ")\n",
    "discriminator.trainable = False\n",
    "# Erstelle GAN\n",
    "generator = create_generator()\n",
    "gan_input = tf.keras.layers.Input(shape=(100,))  # 100 Startpixel.\n",
    "gen_image = generator(gan_input)\n",
    "net_output = discriminator(gen_image)\n",
    "GAN        = tf.keras.Model(gan_input, net_output)\n",
    "GAN.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "26dd3d04-fe1b-4397-8675-8099d36e4f8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step\n",
      "Epoche: 1/1200 GAN loss: 0.6330462694168091\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 2/1200 GAN loss: 0.9008914232254028\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 3/1200 GAN loss: 1.4039802551269531\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 4/1200 GAN loss: 2.2934913635253906\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 5/1200 GAN loss: 3.459859848022461\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 6/1200 GAN loss: 4.912616729736328\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 7/1200 GAN loss: 6.107210636138916\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 8/1200 GAN loss: 7.121273994445801\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 9/1200 GAN loss: 7.913349151611328\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 10/1200 GAN loss: 8.714920043945312\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 11/1200 GAN loss: 9.117280960083008\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 12/1200 GAN loss: 9.668832778930664\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 13/1200 GAN loss: 10.02971363067627\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 14/1200 GAN loss: 10.357820510864258\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 15/1200 GAN loss: 10.7017240524292\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 16/1200 GAN loss: 10.972935676574707\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 17/1200 GAN loss: 11.289938926696777\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 18/1200 GAN loss: 11.756820678710938\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 19/1200 GAN loss: 11.885259628295898\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 20/1200 GAN loss: 11.925607681274414\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 21/1200 GAN loss: 12.51010513305664\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 22/1200 GAN loss: 13.258755683898926\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 23/1200 GAN loss: 13.345620155334473\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 24/1200 GAN loss: 13.638751983642578\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 25/1200 GAN loss: 13.82319450378418\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 26/1200 GAN loss: 14.031973838806152\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 27/1200 GAN loss: 14.860153198242188\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 28/1200 GAN loss: 13.729991912841797\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 29/1200 GAN loss: 13.653818130493164\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 30/1200 GAN loss: 14.211989402770996\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 31/1200 GAN loss: 14.001249313354492\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 32/1200 GAN loss: 13.681350708007812\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 33/1200 GAN loss: 14.80032730102539\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 34/1200 GAN loss: 14.097219467163086\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 35/1200 GAN loss: 15.116413116455078\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 36/1200 GAN loss: 13.794171333312988\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 37/1200 GAN loss: 14.021451950073242\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 38/1200 GAN loss: 13.879140853881836\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 39/1200 GAN loss: 14.214170455932617\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 40/1200 GAN loss: 13.6533842086792\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 41/1200 GAN loss: 14.095791816711426\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 42/1200 GAN loss: 14.738024711608887\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 43/1200 GAN loss: 13.069442749023438\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 44/1200 GAN loss: 11.742183685302734\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 45/1200 GAN loss: 11.201948165893555\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 46/1200 GAN loss: 14.182422637939453\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 47/1200 GAN loss: 19.345184326171875\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 48/1200 GAN loss: 10.038726806640625\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 49/1200 GAN loss: 6.546813488006592\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 50/1200 GAN loss: 6.409512042999268\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 51/1200 GAN loss: 8.584779739379883\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 52/1200 GAN loss: 16.645183563232422\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 53/1200 GAN loss: 24.91088104248047\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 54/1200 GAN loss: 6.678999423980713\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 55/1200 GAN loss: 3.5586256980895996\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 56/1200 GAN loss: 4.434144973754883\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 57/1200 GAN loss: 4.212858200073242\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 58/1200 GAN loss: 4.501557350158691\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 59/1200 GAN loss: 4.969659805297852\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 60/1200 GAN loss: 17.586288452148438\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 61/1200 GAN loss: 27.667926788330078\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 62/1200 GAN loss: 38.70368194580078\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 63/1200 GAN loss: 18.067169189453125\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 64/1200 GAN loss: 6.643037796020508\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 65/1200 GAN loss: 4.026177883148193\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 66/1200 GAN loss: 3.9131808280944824\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 67/1200 GAN loss: 5.0192155838012695\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 68/1200 GAN loss: 4.67137336730957\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 69/1200 GAN loss: 5.950583457946777\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 70/1200 GAN loss: 9.54690933227539\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 71/1200 GAN loss: 21.904754638671875\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 72/1200 GAN loss: 29.101051330566406\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 73/1200 GAN loss: 38.946556091308594\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 74/1200 GAN loss: 24.347251892089844\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 75/1200 GAN loss: 11.067312240600586\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 76/1200 GAN loss: 8.997838020324707\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 77/1200 GAN loss: 9.39748764038086\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 78/1200 GAN loss: 10.143367767333984\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 79/1200 GAN loss: 9.5260648727417\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 80/1200 GAN loss: 8.619531631469727\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 81/1200 GAN loss: 7.331284523010254\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 82/1200 GAN loss: 13.138864517211914\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 83/1200 GAN loss: 19.435529708862305\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 84/1200 GAN loss: 25.464879989624023\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 85/1200 GAN loss: 12.876379013061523\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 86/1200 GAN loss: 5.998579978942871\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 87/1200 GAN loss: 4.74025821685791\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 88/1200 GAN loss: 4.553523540496826\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 89/1200 GAN loss: 3.754883050918579\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 90/1200 GAN loss: 6.363484859466553\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 91/1200 GAN loss: 4.829183101654053\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 92/1200 GAN loss: 7.199904918670654\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 93/1200 GAN loss: 8.568920135498047\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 94/1200 GAN loss: 8.556234359741211\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 95/1200 GAN loss: 6.886285781860352\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 96/1200 GAN loss: 6.911582946777344\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 97/1200 GAN loss: 6.520275115966797\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 98/1200 GAN loss: 6.6684370040893555\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 99/1200 GAN loss: 6.838249683380127\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 100/1200 GAN loss: 7.8261799812316895\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 101/1200 GAN loss: 8.255959510803223\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 102/1200 GAN loss: 7.762302398681641\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 103/1200 GAN loss: 7.994680404663086\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 104/1200 GAN loss: 7.872894287109375\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 105/1200 GAN loss: 7.430452346801758\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 106/1200 GAN loss: 8.05974292755127\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 107/1200 GAN loss: 7.077202796936035\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 108/1200 GAN loss: 6.704862594604492\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 109/1200 GAN loss: 7.433524131774902\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 110/1200 GAN loss: 7.400232315063477\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 111/1200 GAN loss: 7.425047874450684\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 112/1200 GAN loss: 6.888894081115723\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 113/1200 GAN loss: 7.928614139556885\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 114/1200 GAN loss: 7.093835830688477\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 115/1200 GAN loss: 7.996888160705566\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 116/1200 GAN loss: 6.286657810211182\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 117/1200 GAN loss: 6.6575775146484375\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 118/1200 GAN loss: 7.292400360107422\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 119/1200 GAN loss: 7.10474967956543\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 120/1200 GAN loss: 7.9164862632751465\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 121/1200 GAN loss: 7.308570384979248\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 122/1200 GAN loss: 6.85581111907959\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 123/1200 GAN loss: 7.59223747253418\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 124/1200 GAN loss: 8.047333717346191\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 125/1200 GAN loss: 7.962950706481934\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 126/1200 GAN loss: 7.536120414733887\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 127/1200 GAN loss: 7.822622776031494\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 128/1200 GAN loss: 7.76248836517334\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 129/1200 GAN loss: 6.440777778625488\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 130/1200 GAN loss: 6.722781181335449\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 131/1200 GAN loss: 7.110804557800293\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 132/1200 GAN loss: 7.155835151672363\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 133/1200 GAN loss: 5.24576997756958\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 134/1200 GAN loss: 6.562808513641357\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 135/1200 GAN loss: 8.684908866882324\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 136/1200 GAN loss: 8.415940284729004\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 137/1200 GAN loss: 7.456661224365234\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 138/1200 GAN loss: 6.932082653045654\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 139/1200 GAN loss: 7.495843887329102\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 140/1200 GAN loss: 7.724645614624023\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 141/1200 GAN loss: 8.924323081970215\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 142/1200 GAN loss: 6.7917680740356445\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 143/1200 GAN loss: 6.0717058181762695\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 144/1200 GAN loss: 6.837346076965332\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 145/1200 GAN loss: 8.517874717712402\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 146/1200 GAN loss: 6.734959602355957\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 147/1200 GAN loss: 6.547214508056641\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 148/1200 GAN loss: 6.802493095397949\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 149/1200 GAN loss: 7.915573596954346\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 150/1200 GAN loss: 9.048980712890625\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 151/1200 GAN loss: 8.932708740234375\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 152/1200 GAN loss: 9.252443313598633\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 153/1200 GAN loss: 8.083158493041992\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 154/1200 GAN loss: 7.418587684631348\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 155/1200 GAN loss: 7.775721549987793\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 156/1200 GAN loss: 8.631832122802734\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 157/1200 GAN loss: 8.64077091217041\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 158/1200 GAN loss: 8.919917106628418\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 159/1200 GAN loss: 8.636792182922363\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 160/1200 GAN loss: 8.0584077835083\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 161/1200 GAN loss: 7.9707512855529785\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 162/1200 GAN loss: 8.113912582397461\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 163/1200 GAN loss: 8.040816307067871\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 164/1200 GAN loss: 7.876589775085449\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 165/1200 GAN loss: 7.842996120452881\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 166/1200 GAN loss: 7.526246070861816\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 167/1200 GAN loss: 6.9815521240234375\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 168/1200 GAN loss: 6.635485649108887\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 169/1200 GAN loss: 6.889294624328613\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 170/1200 GAN loss: 7.188314914703369\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 171/1200 GAN loss: 6.609762668609619\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 172/1200 GAN loss: 6.563655853271484\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 173/1200 GAN loss: 6.255242347717285\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 174/1200 GAN loss: 7.208080291748047\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 175/1200 GAN loss: 7.724602222442627\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 176/1200 GAN loss: 6.764138698577881\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 177/1200 GAN loss: 6.866432189941406\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 178/1200 GAN loss: 7.876166343688965\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 179/1200 GAN loss: 8.114185333251953\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 180/1200 GAN loss: 8.163712501525879\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 181/1200 GAN loss: 7.750302314758301\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 182/1200 GAN loss: 7.383508682250977\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 183/1200 GAN loss: 7.555878639221191\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 184/1200 GAN loss: 7.782868385314941\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 185/1200 GAN loss: 7.102630138397217\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 186/1200 GAN loss: 7.171124458312988\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 187/1200 GAN loss: 7.12037467956543\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 188/1200 GAN loss: 7.380340576171875\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 189/1200 GAN loss: 7.476048469543457\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 190/1200 GAN loss: 7.4754228591918945\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 191/1200 GAN loss: 7.721980094909668\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 192/1200 GAN loss: 7.682490825653076\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 193/1200 GAN loss: 7.401941299438477\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 194/1200 GAN loss: 7.917817115783691\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 195/1200 GAN loss: 8.025394439697266\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 196/1200 GAN loss: 8.173685073852539\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 197/1200 GAN loss: 8.251579284667969\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 198/1200 GAN loss: 8.965103149414062\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 199/1200 GAN loss: 9.105961799621582\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 200/1200 GAN loss: 8.704972267150879\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 201/1200 GAN loss: 8.844050407409668\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 202/1200 GAN loss: 9.135599136352539\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 203/1200 GAN loss: 8.968649864196777\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 204/1200 GAN loss: 8.517326354980469\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 205/1200 GAN loss: 8.247672080993652\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 206/1200 GAN loss: 8.366483688354492\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 207/1200 GAN loss: 7.979848861694336\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 208/1200 GAN loss: 8.579353332519531\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 209/1200 GAN loss: 7.833390235900879\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 210/1200 GAN loss: 7.510876655578613\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 211/1200 GAN loss: 7.315765380859375\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 212/1200 GAN loss: 7.921927452087402\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 213/1200 GAN loss: 8.960442543029785\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 214/1200 GAN loss: 8.66719913482666\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 215/1200 GAN loss: 8.570035934448242\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 216/1200 GAN loss: 8.876103401184082\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 217/1200 GAN loss: 8.203323364257812\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 218/1200 GAN loss: 8.722477912902832\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 219/1200 GAN loss: 8.197065353393555\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 220/1200 GAN loss: 8.636670112609863\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 221/1200 GAN loss: 8.329069137573242\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 222/1200 GAN loss: 8.365462303161621\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 223/1200 GAN loss: 8.738482475280762\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 224/1200 GAN loss: 8.377241134643555\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 225/1200 GAN loss: 8.431722640991211\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 226/1200 GAN loss: 8.76877498626709\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 227/1200 GAN loss: 9.405860900878906\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 228/1200 GAN loss: 7.772044658660889\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 229/1200 GAN loss: 7.307994842529297\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 230/1200 GAN loss: 7.744997024536133\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 231/1200 GAN loss: 9.664928436279297\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 232/1200 GAN loss: 7.6919331550598145\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 233/1200 GAN loss: 7.28085994720459\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 234/1200 GAN loss: 8.241886138916016\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 235/1200 GAN loss: 8.92763614654541\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 236/1200 GAN loss: 8.929973602294922\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 237/1200 GAN loss: 7.971400737762451\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 238/1200 GAN loss: 7.282620906829834\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 239/1200 GAN loss: 7.643591403961182\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 240/1200 GAN loss: 7.61564826965332\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 241/1200 GAN loss: 7.408011436462402\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 242/1200 GAN loss: 7.691300392150879\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 243/1200 GAN loss: 8.062734603881836\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 244/1200 GAN loss: 8.725364685058594\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 245/1200 GAN loss: 8.206351280212402\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 246/1200 GAN loss: 7.469321250915527\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 247/1200 GAN loss: 7.818170547485352\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 248/1200 GAN loss: 8.192825317382812\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 249/1200 GAN loss: 8.821889877319336\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 250/1200 GAN loss: 7.871728897094727\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 251/1200 GAN loss: 7.326288223266602\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 252/1200 GAN loss: 8.482743263244629\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 253/1200 GAN loss: 7.694986343383789\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 254/1200 GAN loss: 7.541118621826172\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 255/1200 GAN loss: 7.784443378448486\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 256/1200 GAN loss: 6.6607160568237305\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 257/1200 GAN loss: 7.162131309509277\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 258/1200 GAN loss: 8.385763168334961\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 259/1200 GAN loss: 8.166059494018555\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 260/1200 GAN loss: 9.735832214355469\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 261/1200 GAN loss: 3.7643558979034424\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 262/1200 GAN loss: 11.627647399902344\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 263/1200 GAN loss: 1.437828779220581\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 264/1200 GAN loss: 2.303835868835449\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 265/1200 GAN loss: 10.31620979309082\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 266/1200 GAN loss: 24.77536392211914\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 267/1200 GAN loss: 6.484048843383789\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 268/1200 GAN loss: 1.187744140625\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 269/1200 GAN loss: 1.190402626991272\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 270/1200 GAN loss: 2.3286495208740234\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 271/1200 GAN loss: 5.822588920593262\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 272/1200 GAN loss: 11.458883285522461\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 273/1200 GAN loss: 9.294500350952148\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 274/1200 GAN loss: 5.203506946563721\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 275/1200 GAN loss: 2.3603625297546387\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 276/1200 GAN loss: 2.434323787689209\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 277/1200 GAN loss: 1.9201897382736206\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 278/1200 GAN loss: 2.9077610969543457\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 279/1200 GAN loss: 4.435585021972656\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 280/1200 GAN loss: 7.1632537841796875\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 281/1200 GAN loss: 8.887014389038086\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 282/1200 GAN loss: 6.897709846496582\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 283/1200 GAN loss: 5.753257751464844\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 284/1200 GAN loss: 4.478629112243652\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 285/1200 GAN loss: 3.507636547088623\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 286/1200 GAN loss: 5.065860271453857\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 287/1200 GAN loss: 5.796718597412109\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 288/1200 GAN loss: 6.570766448974609\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 289/1200 GAN loss: 5.795313835144043\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 290/1200 GAN loss: 4.591706275939941\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 291/1200 GAN loss: 3.9675817489624023\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 292/1200 GAN loss: 5.157262802124023\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 293/1200 GAN loss: 3.9485318660736084\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 294/1200 GAN loss: 3.3920209407806396\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 295/1200 GAN loss: 4.117463111877441\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 296/1200 GAN loss: 4.1066694259643555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 297/1200 GAN loss: 2.648930549621582\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 298/1200 GAN loss: 3.163172721862793\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 299/1200 GAN loss: 4.0611371994018555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 300/1200 GAN loss: 2.536067485809326\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 301/1200 GAN loss: 2.848034381866455\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 302/1200 GAN loss: 4.713226318359375\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 303/1200 GAN loss: 1.7452712059020996\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 304/1200 GAN loss: 2.8712000846862793\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 305/1200 GAN loss: 6.861828804016113\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 306/1200 GAN loss: 1.9910531044006348\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 307/1200 GAN loss: 0.7121304869651794\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 308/1200 GAN loss: 4.053701400756836\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 309/1200 GAN loss: 11.313594818115234\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 310/1200 GAN loss: 3.776500940322876\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 311/1200 GAN loss: 0.8958298563957214\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 312/1200 GAN loss: 1.0263264179229736\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 313/1200 GAN loss: 2.8721792697906494\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 314/1200 GAN loss: 4.766183853149414\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 315/1200 GAN loss: 3.019601345062256\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 316/1200 GAN loss: 2.0822224617004395\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 317/1200 GAN loss: 1.991628885269165\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 318/1200 GAN loss: 2.424372673034668\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 319/1200 GAN loss: 3.1200690269470215\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 320/1200 GAN loss: 2.220675468444824\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 321/1200 GAN loss: 1.4330493211746216\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 322/1200 GAN loss: 1.5976674556732178\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 323/1200 GAN loss: 2.3113303184509277\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 324/1200 GAN loss: 2.0698232650756836\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 325/1200 GAN loss: 1.702507495880127\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 326/1200 GAN loss: 1.59208345413208\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 327/1200 GAN loss: 1.9602546691894531\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 328/1200 GAN loss: 2.6805853843688965\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 329/1200 GAN loss: 1.6922900676727295\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 330/1200 GAN loss: 1.8590905666351318\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 331/1200 GAN loss: 1.81988525390625\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 332/1200 GAN loss: 2.278926372528076\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 333/1200 GAN loss: 2.056813955307007\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 334/1200 GAN loss: 2.2199220657348633\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 335/1200 GAN loss: 2.3679568767547607\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 336/1200 GAN loss: 1.9533125162124634\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 337/1200 GAN loss: 2.1882829666137695\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 338/1200 GAN loss: 2.669487476348877\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 339/1200 GAN loss: 2.57450008392334\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 340/1200 GAN loss: 2.1750259399414062\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 341/1200 GAN loss: 2.5568346977233887\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 342/1200 GAN loss: 3.166757583618164\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 343/1200 GAN loss: 2.5220370292663574\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 344/1200 GAN loss: 2.529393196105957\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 345/1200 GAN loss: 2.6436574459075928\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 346/1200 GAN loss: 2.4095520973205566\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 347/1200 GAN loss: 2.829519510269165\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 348/1200 GAN loss: 2.6480512619018555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 349/1200 GAN loss: 2.5701847076416016\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 350/1200 GAN loss: 2.9948976039886475\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 351/1200 GAN loss: 2.642673969268799\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 352/1200 GAN loss: 3.0863778591156006\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 353/1200 GAN loss: 3.0989842414855957\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 354/1200 GAN loss: 2.186008930206299\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 355/1200 GAN loss: 2.7714486122131348\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 356/1200 GAN loss: 3.8975324630737305\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 357/1200 GAN loss: 1.8609875440597534\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 358/1200 GAN loss: 2.1501388549804688\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 359/1200 GAN loss: 3.8883187770843506\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 360/1200 GAN loss: 1.3415846824645996\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 361/1200 GAN loss: 1.5013623237609863\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 362/1200 GAN loss: 2.732247829437256\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 363/1200 GAN loss: 3.085747241973877\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 364/1200 GAN loss: 1.1421582698822021\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 365/1200 GAN loss: 1.351019024848938\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 366/1200 GAN loss: 3.333603858947754\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 367/1200 GAN loss: 2.129749298095703\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 368/1200 GAN loss: 1.2587534189224243\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 369/1200 GAN loss: 2.614466428756714\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 370/1200 GAN loss: 3.4688327312469482\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 371/1200 GAN loss: 1.6658961772918701\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 372/1200 GAN loss: 1.4180129766464233\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 373/1200 GAN loss: 2.669703245162964\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 374/1200 GAN loss: 2.0843124389648438\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 375/1200 GAN loss: 1.8856112957000732\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 376/1200 GAN loss: 2.4056735038757324\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 377/1200 GAN loss: 1.9178552627563477\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 378/1200 GAN loss: 1.9147850275039673\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 379/1200 GAN loss: 2.0983848571777344\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 380/1200 GAN loss: 2.4455349445343018\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 381/1200 GAN loss: 1.6596205234527588\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 382/1200 GAN loss: 1.7127959728240967\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 383/1200 GAN loss: 2.3072359561920166\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 384/1200 GAN loss: 2.440401077270508\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 385/1200 GAN loss: 2.4481570720672607\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 386/1200 GAN loss: 1.9811203479766846\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 387/1200 GAN loss: 1.8358004093170166\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 388/1200 GAN loss: 2.3978323936462402\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 389/1200 GAN loss: 2.2252867221832275\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 390/1200 GAN loss: 2.8009085655212402\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 391/1200 GAN loss: 2.716038703918457\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 392/1200 GAN loss: 2.0905373096466064\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 393/1200 GAN loss: 2.5569796562194824\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 394/1200 GAN loss: 3.585645914077759\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 395/1200 GAN loss: 2.9689841270446777\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 396/1200 GAN loss: 2.710480213165283\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 397/1200 GAN loss: 2.5145435333251953\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 398/1200 GAN loss: 3.230210065841675\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 399/1200 GAN loss: 3.009425640106201\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 400/1200 GAN loss: 3.083754062652588\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 401/1200 GAN loss: 3.1910593509674072\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 402/1200 GAN loss: 2.116938352584839\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 403/1200 GAN loss: 2.4355571269989014\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 404/1200 GAN loss: 3.488558769226074\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 405/1200 GAN loss: 2.2752532958984375\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 406/1200 GAN loss: 2.309122085571289\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 407/1200 GAN loss: 2.8050479888916016\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 408/1200 GAN loss: 2.2750301361083984\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 409/1200 GAN loss: 2.616664171218872\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 410/1200 GAN loss: 2.8220534324645996\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 411/1200 GAN loss: 2.9218244552612305\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 412/1200 GAN loss: 2.215608835220337\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 413/1200 GAN loss: 2.0514416694641113\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 414/1200 GAN loss: 2.505873203277588\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 415/1200 GAN loss: 2.0458626747131348\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 416/1200 GAN loss: 1.4452511072158813\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 417/1200 GAN loss: 1.7105205059051514\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 418/1200 GAN loss: 2.407007932662964\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 419/1200 GAN loss: 1.5781240463256836\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 420/1200 GAN loss: 1.8132823705673218\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 421/1200 GAN loss: 1.8766499757766724\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 422/1200 GAN loss: 1.17913818359375\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 423/1200 GAN loss: 2.076223373413086\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 424/1200 GAN loss: 1.5602810382843018\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 425/1200 GAN loss: 1.4995415210723877\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 426/1200 GAN loss: 1.695509433746338\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 427/1200 GAN loss: 1.610483169555664\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 428/1200 GAN loss: 1.5294804573059082\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 429/1200 GAN loss: 1.9742989540100098\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 430/1200 GAN loss: 1.2283644676208496\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 431/1200 GAN loss: 1.8117038011550903\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 432/1200 GAN loss: 1.8140454292297363\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 433/1200 GAN loss: 1.8761016130447388\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 434/1200 GAN loss: 1.613419532775879\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 435/1200 GAN loss: 1.6477231979370117\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 436/1200 GAN loss: 1.7212555408477783\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 437/1200 GAN loss: 1.5485150814056396\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 438/1200 GAN loss: 2.1294045448303223\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 439/1200 GAN loss: 1.92245614528656\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 440/1200 GAN loss: 2.0295491218566895\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 441/1200 GAN loss: 1.8619129657745361\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 442/1200 GAN loss: 1.7363563776016235\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 443/1200 GAN loss: 1.4365432262420654\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 444/1200 GAN loss: 1.6362388134002686\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 445/1200 GAN loss: 1.602210283279419\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 446/1200 GAN loss: 1.3545987606048584\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 447/1200 GAN loss: 2.152794361114502\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 448/1200 GAN loss: 1.520467758178711\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 449/1200 GAN loss: 1.798109769821167\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 450/1200 GAN loss: 1.947858452796936\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 451/1200 GAN loss: 1.5489065647125244\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 452/1200 GAN loss: 1.3939043283462524\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 453/1200 GAN loss: 1.6170573234558105\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 454/1200 GAN loss: 1.5194783210754395\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 455/1200 GAN loss: 1.7865839004516602\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 456/1200 GAN loss: 1.468340277671814\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 457/1200 GAN loss: 1.614933967590332\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 458/1200 GAN loss: 1.545274257659912\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 459/1200 GAN loss: 1.3358339071273804\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 460/1200 GAN loss: 1.408733606338501\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 461/1200 GAN loss: 1.4148720502853394\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 462/1200 GAN loss: 1.1417369842529297\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 463/1200 GAN loss: 1.4670945405960083\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 464/1200 GAN loss: 1.7910653352737427\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 465/1200 GAN loss: 1.0539519786834717\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 466/1200 GAN loss: 1.8881499767303467\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 467/1200 GAN loss: 1.3986533880233765\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 468/1200 GAN loss: 1.306917428970337\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 469/1200 GAN loss: 1.2484869956970215\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 470/1200 GAN loss: 1.363702416419983\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 471/1200 GAN loss: 1.4394261837005615\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 472/1200 GAN loss: 1.178673505783081\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 473/1200 GAN loss: 1.2926779985427856\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 474/1200 GAN loss: 1.9051191806793213\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 475/1200 GAN loss: 1.2337161302566528\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 476/1200 GAN loss: 1.0271625518798828\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 477/1200 GAN loss: 1.2147661447525024\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 478/1200 GAN loss: 1.530301809310913\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 479/1200 GAN loss: 1.023578405380249\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 480/1200 GAN loss: 1.0953037738800049\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 481/1200 GAN loss: 1.3605921268463135\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 482/1200 GAN loss: 1.0108466148376465\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 483/1200 GAN loss: 0.9223932027816772\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 484/1200 GAN loss: 1.1873117685317993\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 485/1200 GAN loss: 1.0273466110229492\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 486/1200 GAN loss: 0.9078986644744873\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 487/1200 GAN loss: 0.9272300601005554\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 488/1200 GAN loss: 1.0148636102676392\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 489/1200 GAN loss: 1.0697784423828125\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 490/1200 GAN loss: 1.0115530490875244\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 491/1200 GAN loss: 0.900559663772583\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 492/1200 GAN loss: 1.029334306716919\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 493/1200 GAN loss: 1.1204214096069336\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 494/1200 GAN loss: 1.2470673322677612\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 495/1200 GAN loss: 0.964408278465271\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 496/1200 GAN loss: 0.9622360467910767\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 497/1200 GAN loss: 1.0016471147537231\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 498/1200 GAN loss: 1.0150014162063599\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 499/1200 GAN loss: 1.1411969661712646\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 500/1200 GAN loss: 1.0821365118026733\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 501/1200 GAN loss: 0.9913514852523804\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 502/1200 GAN loss: 0.9542583227157593\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 503/1200 GAN loss: 1.1011011600494385\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 504/1200 GAN loss: 1.1391425132751465\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 505/1200 GAN loss: 1.3976573944091797\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 506/1200 GAN loss: 0.9855842590332031\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 507/1200 GAN loss: 0.9641246795654297\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 508/1200 GAN loss: 1.0600155591964722\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 509/1200 GAN loss: 1.182120442390442\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 510/1200 GAN loss: 1.0855143070220947\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 511/1200 GAN loss: 0.98847895860672\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 512/1200 GAN loss: 0.9698599576950073\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 513/1200 GAN loss: 1.193195104598999\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 514/1200 GAN loss: 1.3832423686981201\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 515/1200 GAN loss: 1.1703161001205444\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 516/1200 GAN loss: 1.0911844968795776\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 517/1200 GAN loss: 0.9081012010574341\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 518/1200 GAN loss: 1.2923119068145752\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 519/1200 GAN loss: 1.1101405620574951\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 520/1200 GAN loss: 1.0081937313079834\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 521/1200 GAN loss: 0.9933271408081055\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 522/1200 GAN loss: 1.2008674144744873\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 523/1200 GAN loss: 1.0296858549118042\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 524/1200 GAN loss: 1.0526267290115356\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 525/1200 GAN loss: 0.9965561032295227\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 526/1200 GAN loss: 1.0167003870010376\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 527/1200 GAN loss: 1.1918601989746094\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 528/1200 GAN loss: 1.1207082271575928\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 529/1200 GAN loss: 1.0619913339614868\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 530/1200 GAN loss: 1.0818414688110352\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 531/1200 GAN loss: 1.1315422058105469\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 532/1200 GAN loss: 1.3568768501281738\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 533/1200 GAN loss: 0.9709545969963074\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 534/1200 GAN loss: 0.9176368117332458\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 535/1200 GAN loss: 1.086307168006897\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 536/1200 GAN loss: 1.2483930587768555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 537/1200 GAN loss: 1.0974669456481934\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 538/1200 GAN loss: 0.9566640853881836\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 539/1200 GAN loss: 1.0192055702209473\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 540/1200 GAN loss: 1.0812733173370361\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 541/1200 GAN loss: 1.0309460163116455\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 542/1200 GAN loss: 1.0642236471176147\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 543/1200 GAN loss: 1.0295897722244263\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 544/1200 GAN loss: 1.0263766050338745\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 545/1200 GAN loss: 1.111784815788269\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 546/1200 GAN loss: 0.9526546597480774\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 547/1200 GAN loss: 0.9459863901138306\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 548/1200 GAN loss: 0.9131144285202026\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 549/1200 GAN loss: 1.0340392589569092\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 550/1200 GAN loss: 1.0071254968643188\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 551/1200 GAN loss: 1.0459816455841064\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 552/1200 GAN loss: 0.9103097915649414\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 553/1200 GAN loss: 0.9695663452148438\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 554/1200 GAN loss: 0.9349659085273743\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 555/1200 GAN loss: 1.0200018882751465\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 556/1200 GAN loss: 1.0064963102340698\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 557/1200 GAN loss: 0.951189398765564\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 558/1200 GAN loss: 1.0955066680908203\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 559/1200 GAN loss: 1.0930839776992798\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 560/1200 GAN loss: 0.7692527770996094\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 561/1200 GAN loss: 0.911178469657898\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 562/1200 GAN loss: 1.0317721366882324\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 563/1200 GAN loss: 0.9283895492553711\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 564/1200 GAN loss: 0.9949090480804443\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 565/1200 GAN loss: 1.017229676246643\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 566/1200 GAN loss: 0.9935934543609619\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 567/1200 GAN loss: 0.8698107004165649\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 568/1200 GAN loss: 0.9620121121406555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 569/1200 GAN loss: 1.0475691556930542\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 570/1200 GAN loss: 0.7971445918083191\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 571/1200 GAN loss: 0.778547465801239\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 572/1200 GAN loss: 0.8708972930908203\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 573/1200 GAN loss: 1.0002647638320923\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 574/1200 GAN loss: 0.990918755531311\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 575/1200 GAN loss: 0.9000363349914551\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 576/1200 GAN loss: 0.8038191199302673\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 577/1200 GAN loss: 0.892519474029541\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 578/1200 GAN loss: 0.877020537853241\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 579/1200 GAN loss: 0.9000288844108582\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 580/1200 GAN loss: 0.8799275159835815\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 581/1200 GAN loss: 0.9005454778671265\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 582/1200 GAN loss: 0.8663122653961182\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 583/1200 GAN loss: 0.8184250593185425\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 584/1200 GAN loss: 0.8535908460617065\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 585/1200 GAN loss: 0.8497813940048218\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 586/1200 GAN loss: 0.9293833374977112\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 587/1200 GAN loss: 0.8603056073188782\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 588/1200 GAN loss: 0.8301904201507568\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 589/1200 GAN loss: 0.8685739040374756\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 590/1200 GAN loss: 0.9016048908233643\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 591/1200 GAN loss: 0.8524767756462097\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 592/1200 GAN loss: 0.8518459796905518\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 593/1200 GAN loss: 0.8102782964706421\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 594/1200 GAN loss: 0.7619680166244507\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 595/1200 GAN loss: 0.7779121398925781\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 596/1200 GAN loss: 0.8042911291122437\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 597/1200 GAN loss: 0.9322750568389893\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 598/1200 GAN loss: 0.9119129180908203\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 599/1200 GAN loss: 0.7579233646392822\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 600/1200 GAN loss: 0.7567697763442993\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 601/1200 GAN loss: 0.830854058265686\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 602/1200 GAN loss: 0.8331909775733948\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 603/1200 GAN loss: 0.9312007427215576\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 604/1200 GAN loss: 0.8191961050033569\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 605/1200 GAN loss: 0.6784911155700684\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 606/1200 GAN loss: 0.7904013395309448\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 607/1200 GAN loss: 0.8532025218009949\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 608/1200 GAN loss: 0.887607753276825\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 609/1200 GAN loss: 0.8431916236877441\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 610/1200 GAN loss: 0.8623156547546387\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 611/1200 GAN loss: 0.8465631008148193\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 612/1200 GAN loss: 0.8445168733596802\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 613/1200 GAN loss: 0.8456350564956665\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 614/1200 GAN loss: 0.8825680017471313\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 615/1200 GAN loss: 0.894598126411438\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 616/1200 GAN loss: 0.8423359394073486\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 617/1200 GAN loss: 0.8291342854499817\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 618/1200 GAN loss: 0.8690371513366699\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 619/1200 GAN loss: 0.8967956304550171\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 620/1200 GAN loss: 0.8882482051849365\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 621/1200 GAN loss: 0.7536066770553589\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 622/1200 GAN loss: 0.794872522354126\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 623/1200 GAN loss: 0.8346881866455078\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 624/1200 GAN loss: 0.8598315715789795\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 625/1200 GAN loss: 0.9470146894454956\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 626/1200 GAN loss: 0.8689396381378174\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 627/1200 GAN loss: 0.7731096744537354\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 628/1200 GAN loss: 0.7807458639144897\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 629/1200 GAN loss: 0.8001328110694885\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 630/1200 GAN loss: 0.8993741273880005\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 631/1200 GAN loss: 0.9044743776321411\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 632/1200 GAN loss: 0.814306378364563\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 633/1200 GAN loss: 0.7542288303375244\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 634/1200 GAN loss: 0.797302782535553\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 635/1200 GAN loss: 0.77118980884552\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 636/1200 GAN loss: 0.8491945266723633\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 637/1200 GAN loss: 0.8089175224304199\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 638/1200 GAN loss: 0.7924894094467163\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 639/1200 GAN loss: 0.8020374774932861\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 640/1200 GAN loss: 0.8051959276199341\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 641/1200 GAN loss: 0.8226836919784546\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 642/1200 GAN loss: 0.8152909874916077\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 643/1200 GAN loss: 0.8152337074279785\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 644/1200 GAN loss: 0.7858074903488159\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 645/1200 GAN loss: 0.8426216244697571\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 646/1200 GAN loss: 0.8173533082008362\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 647/1200 GAN loss: 0.825092077255249\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 648/1200 GAN loss: 0.832038402557373\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 649/1200 GAN loss: 0.7980612516403198\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 650/1200 GAN loss: 0.7985648512840271\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 651/1200 GAN loss: 0.8355981707572937\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 652/1200 GAN loss: 0.8514108657836914\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 653/1200 GAN loss: 0.8491425514221191\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 654/1200 GAN loss: 0.8572381734848022\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 655/1200 GAN loss: 0.8651933670043945\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 656/1200 GAN loss: 0.7895445823669434\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 657/1200 GAN loss: 0.7821528315544128\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 658/1200 GAN loss: 0.7639137506484985\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 659/1200 GAN loss: 0.7814640998840332\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 660/1200 GAN loss: 0.8338857293128967\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 661/1200 GAN loss: 0.8598409295082092\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 662/1200 GAN loss: 0.8199535608291626\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 663/1200 GAN loss: 0.7840808033943176\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 664/1200 GAN loss: 0.7766155004501343\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 665/1200 GAN loss: 0.7745009064674377\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 666/1200 GAN loss: 0.7535458207130432\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 667/1200 GAN loss: 0.7762597799301147\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 668/1200 GAN loss: 0.7785736918449402\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 669/1200 GAN loss: 0.7885770797729492\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 670/1200 GAN loss: 0.7784935235977173\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 671/1200 GAN loss: 0.800044059753418\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 672/1200 GAN loss: 0.7788609266281128\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 673/1200 GAN loss: 0.783791720867157\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 674/1200 GAN loss: 0.747995138168335\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 675/1200 GAN loss: 0.7425341606140137\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 676/1200 GAN loss: 0.7393088340759277\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 677/1200 GAN loss: 0.798914909362793\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 678/1200 GAN loss: 0.7955962419509888\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 679/1200 GAN loss: 0.7961407899856567\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 680/1200 GAN loss: 0.7637723684310913\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 681/1200 GAN loss: 0.7561427354812622\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 682/1200 GAN loss: 0.7702686190605164\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 683/1200 GAN loss: 0.7885153293609619\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 684/1200 GAN loss: 0.8742002248764038\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 685/1200 GAN loss: 0.8353051543235779\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 686/1200 GAN loss: 0.7868934869766235\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 687/1200 GAN loss: 0.7220702171325684\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 688/1200 GAN loss: 0.6915091276168823\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 689/1200 GAN loss: 0.7887654304504395\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 690/1200 GAN loss: 0.9027878046035767\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 691/1200 GAN loss: 0.9009344577789307\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 692/1200 GAN loss: 0.7833167314529419\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 693/1200 GAN loss: 0.8013193011283875\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 694/1200 GAN loss: 0.710577666759491\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 695/1200 GAN loss: 0.7798808217048645\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 696/1200 GAN loss: 0.7917491793632507\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 697/1200 GAN loss: 0.7967631816864014\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 698/1200 GAN loss: 0.7764912247657776\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 699/1200 GAN loss: 0.7681277990341187\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 700/1200 GAN loss: 0.7947492003440857\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 701/1200 GAN loss: 0.8189836144447327\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 702/1200 GAN loss: 0.8102301359176636\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 703/1200 GAN loss: 0.7812029123306274\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 704/1200 GAN loss: 0.8007184267044067\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 705/1200 GAN loss: 0.791236400604248\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 706/1200 GAN loss: 0.7770587205886841\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 707/1200 GAN loss: 0.7964344620704651\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 708/1200 GAN loss: 0.7905834913253784\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 709/1200 GAN loss: 0.7607834339141846\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 710/1200 GAN loss: 0.7594836354255676\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 711/1200 GAN loss: 0.7358587980270386\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 712/1200 GAN loss: 0.7977529168128967\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 713/1200 GAN loss: 0.7924935817718506\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 714/1200 GAN loss: 0.7720418572425842\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 715/1200 GAN loss: 0.7475780844688416\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 716/1200 GAN loss: 0.7353731989860535\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 717/1200 GAN loss: 0.7642362713813782\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 718/1200 GAN loss: 0.7894962430000305\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 719/1200 GAN loss: 0.7804520130157471\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 720/1200 GAN loss: 0.7786813378334045\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 721/1200 GAN loss: 0.7432419061660767\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 722/1200 GAN loss: 0.7225024700164795\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 723/1200 GAN loss: 0.7095808386802673\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 724/1200 GAN loss: 0.7335944771766663\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 725/1200 GAN loss: 0.7445595860481262\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 726/1200 GAN loss: 0.7783063054084778\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 727/1200 GAN loss: 0.7338018417358398\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 728/1200 GAN loss: 0.7079715728759766\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 729/1200 GAN loss: 0.7040195465087891\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 730/1200 GAN loss: 0.6870769262313843\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 731/1200 GAN loss: 0.7152402400970459\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 732/1200 GAN loss: 0.7341288924217224\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 733/1200 GAN loss: 0.7569977045059204\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 734/1200 GAN loss: 0.7532657384872437\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 735/1200 GAN loss: 0.7374204993247986\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 736/1200 GAN loss: 0.7150903940200806\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 737/1200 GAN loss: 0.7028498649597168\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 738/1200 GAN loss: 0.6943361759185791\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 739/1200 GAN loss: 0.7036136388778687\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 740/1200 GAN loss: 0.7235588431358337\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 741/1200 GAN loss: 0.7422800064086914\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 742/1200 GAN loss: 0.7504295706748962\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 743/1200 GAN loss: 0.7406589388847351\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 744/1200 GAN loss: 0.7110585570335388\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 745/1200 GAN loss: 0.6871423721313477\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 746/1200 GAN loss: 0.6862507462501526\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 747/1200 GAN loss: 0.691051721572876\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 748/1200 GAN loss: 0.7234463691711426\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 749/1200 GAN loss: 0.7403608560562134\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 750/1200 GAN loss: 0.7532036304473877\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 751/1200 GAN loss: 0.7464626431465149\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 752/1200 GAN loss: 0.7212547659873962\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 753/1200 GAN loss: 0.7265900373458862\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 754/1200 GAN loss: 0.7510574460029602\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 755/1200 GAN loss: 0.7478979229927063\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 756/1200 GAN loss: 0.775864839553833\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 757/1200 GAN loss: 0.7788416147232056\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 758/1200 GAN loss: 0.7969561815261841\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 759/1200 GAN loss: 0.8247897624969482\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 760/1200 GAN loss: 0.7707844972610474\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 761/1200 GAN loss: 0.7782716155052185\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 762/1200 GAN loss: 0.7442359924316406\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 763/1200 GAN loss: 0.7793256044387817\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 764/1200 GAN loss: 0.8144030570983887\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 765/1200 GAN loss: 0.7646869421005249\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 766/1200 GAN loss: 0.7329059839248657\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 767/1200 GAN loss: 0.759580135345459\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 768/1200 GAN loss: 0.7852548360824585\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 769/1200 GAN loss: 0.7771354913711548\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 770/1200 GAN loss: 0.7700490355491638\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 771/1200 GAN loss: 0.7816193699836731\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 772/1200 GAN loss: 0.7803319096565247\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 773/1200 GAN loss: 0.771869421005249\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 774/1200 GAN loss: 0.7409934997558594\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 775/1200 GAN loss: 0.7476544380187988\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 776/1200 GAN loss: 0.7210427522659302\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 777/1200 GAN loss: 0.762031078338623\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 778/1200 GAN loss: 0.7877262830734253\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 779/1200 GAN loss: 0.7773900032043457\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 780/1200 GAN loss: 0.7551893591880798\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 781/1200 GAN loss: 0.7569624185562134\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 782/1200 GAN loss: 0.7487810850143433\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 783/1200 GAN loss: 0.7524421215057373\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 784/1200 GAN loss: 0.7394455075263977\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 785/1200 GAN loss: 0.7437213659286499\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 786/1200 GAN loss: 0.7506176233291626\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 787/1200 GAN loss: 0.758074939250946\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 788/1200 GAN loss: 0.7644814252853394\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 789/1200 GAN loss: 0.7602220177650452\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 790/1200 GAN loss: 0.7454803586006165\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 791/1200 GAN loss: 0.700426459312439\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 792/1200 GAN loss: 0.7175391912460327\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 793/1200 GAN loss: 0.776055634021759\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 794/1200 GAN loss: 0.7938480377197266\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 795/1200 GAN loss: 0.7770359516143799\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 796/1200 GAN loss: 0.7510484457015991\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 797/1200 GAN loss: 0.7207030057907104\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 798/1200 GAN loss: 0.7170994281768799\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 799/1200 GAN loss: 0.7475563883781433\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 800/1200 GAN loss: 0.6947324872016907\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 801/1200 GAN loss: 0.6833019256591797\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 802/1200 GAN loss: 0.7025611400604248\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 803/1200 GAN loss: 0.7363930940628052\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 804/1200 GAN loss: 0.7426842451095581\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 805/1200 GAN loss: 0.7322657704353333\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 806/1200 GAN loss: 0.7190141081809998\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 807/1200 GAN loss: 0.7109912633895874\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 808/1200 GAN loss: 0.701292097568512\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 809/1200 GAN loss: 0.6954153776168823\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 810/1200 GAN loss: 0.7051605582237244\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 811/1200 GAN loss: 0.6977723240852356\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 812/1200 GAN loss: 0.7053983211517334\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 813/1200 GAN loss: 0.7280631065368652\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 814/1200 GAN loss: 0.7144575119018555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 815/1200 GAN loss: 0.7072696685791016\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 816/1200 GAN loss: 0.6979118585586548\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 817/1200 GAN loss: 0.7114379405975342\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 818/1200 GAN loss: 0.7345660924911499\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 819/1200 GAN loss: 0.7623218297958374\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 820/1200 GAN loss: 0.7686703205108643\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 821/1200 GAN loss: 0.7600202560424805\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 822/1200 GAN loss: 0.7497378587722778\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 823/1200 GAN loss: 0.7293493747711182\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 824/1200 GAN loss: 0.7162703275680542\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 825/1200 GAN loss: 0.7261989712715149\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 826/1200 GAN loss: 0.7491292953491211\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 827/1200 GAN loss: 0.7302889823913574\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 828/1200 GAN loss: 0.7580008506774902\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 829/1200 GAN loss: 0.7428104877471924\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 830/1200 GAN loss: 0.7532234191894531\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 831/1200 GAN loss: 0.7548500895500183\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 832/1200 GAN loss: 0.7430344223976135\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 833/1200 GAN loss: 0.7540103793144226\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 834/1200 GAN loss: 0.7494062185287476\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 835/1200 GAN loss: 0.7515493631362915\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 836/1200 GAN loss: 0.7518143057823181\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 837/1200 GAN loss: 0.7273602485656738\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 838/1200 GAN loss: 0.7232427000999451\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 839/1200 GAN loss: 0.7234352827072144\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 840/1200 GAN loss: 0.7372369766235352\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 841/1200 GAN loss: 0.7525472640991211\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 842/1200 GAN loss: 0.7708556056022644\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 843/1200 GAN loss: 0.7682381272315979\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 844/1200 GAN loss: 0.7517061829566956\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 845/1200 GAN loss: 0.7329963445663452\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 846/1200 GAN loss: 0.7280896902084351\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 847/1200 GAN loss: 0.7220551371574402\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 848/1200 GAN loss: 0.718031644821167\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 849/1200 GAN loss: 0.7307038307189941\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 850/1200 GAN loss: 0.7370951175689697\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 851/1200 GAN loss: 0.7540135383605957\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 852/1200 GAN loss: 0.7607226371765137\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 853/1200 GAN loss: 0.7664271593093872\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 854/1200 GAN loss: 0.745060384273529\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 855/1200 GAN loss: 0.7339102029800415\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 856/1200 GAN loss: 0.6959516406059265\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 857/1200 GAN loss: 0.6926960349082947\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 858/1200 GAN loss: 0.6997412443161011\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 859/1200 GAN loss: 0.7189662456512451\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 860/1200 GAN loss: 0.7226202487945557\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 861/1200 GAN loss: 0.7226194143295288\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 862/1200 GAN loss: 0.7274751663208008\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 863/1200 GAN loss: 0.7317649126052856\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 864/1200 GAN loss: 0.7306292057037354\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 865/1200 GAN loss: 0.7253001928329468\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 866/1200 GAN loss: 0.7293279767036438\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 867/1200 GAN loss: 0.7170689702033997\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 868/1200 GAN loss: 0.7117986083030701\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 869/1200 GAN loss: 0.7209327816963196\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 870/1200 GAN loss: 0.7193624973297119\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 871/1200 GAN loss: 0.7247059941291809\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 872/1200 GAN loss: 0.72157883644104\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 873/1200 GAN loss: 0.7181016206741333\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 874/1200 GAN loss: 0.7192299962043762\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 875/1200 GAN loss: 0.7213497161865234\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 876/1200 GAN loss: 0.7251196503639221\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 877/1200 GAN loss: 0.7334564924240112\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 878/1200 GAN loss: 0.7216359376907349\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 879/1200 GAN loss: 0.7302407026290894\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 880/1200 GAN loss: 0.7369099855422974\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 881/1200 GAN loss: 0.7355377674102783\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 882/1200 GAN loss: 0.7439550757408142\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 883/1200 GAN loss: 0.718212902545929\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 884/1200 GAN loss: 0.7138710618019104\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 885/1200 GAN loss: 0.7118610739707947\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 886/1200 GAN loss: 0.722274124622345\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 887/1200 GAN loss: 0.7350260019302368\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 888/1200 GAN loss: 0.7276633381843567\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 889/1200 GAN loss: 0.7285975813865662\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 890/1200 GAN loss: 0.7193829417228699\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 891/1200 GAN loss: 0.713473916053772\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 892/1200 GAN loss: 0.7133338451385498\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 893/1200 GAN loss: 0.7167972326278687\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 894/1200 GAN loss: 0.7209158539772034\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 895/1200 GAN loss: 0.7257611751556396\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 896/1200 GAN loss: 0.7207249999046326\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 897/1200 GAN loss: 0.7206850051879883\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 898/1200 GAN loss: 0.7211016416549683\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 899/1200 GAN loss: 0.7174118161201477\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 900/1200 GAN loss: 0.6998007297515869\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 901/1200 GAN loss: 0.6979312896728516\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 902/1200 GAN loss: 0.7052582502365112\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 903/1200 GAN loss: 0.7028746008872986\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 904/1200 GAN loss: 0.7160941362380981\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 905/1200 GAN loss: 0.7185105085372925\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 906/1200 GAN loss: 0.7201502323150635\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 907/1200 GAN loss: 0.7137422561645508\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 908/1200 GAN loss: 0.714840292930603\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 909/1200 GAN loss: 0.7208650708198547\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 910/1200 GAN loss: 0.7040690779685974\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 911/1200 GAN loss: 0.7053142189979553\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 912/1200 GAN loss: 0.7092733979225159\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 913/1200 GAN loss: 0.7114439606666565\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 914/1200 GAN loss: 0.7169018983840942\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 915/1200 GAN loss: 0.7180262804031372\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 916/1200 GAN loss: 0.718124270439148\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 917/1200 GAN loss: 0.7167215943336487\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 918/1200 GAN loss: 0.7149357795715332\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 919/1200 GAN loss: 0.708831250667572\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 920/1200 GAN loss: 0.7128003835678101\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 921/1200 GAN loss: 0.7064344882965088\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 922/1200 GAN loss: 0.7009618282318115\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 923/1200 GAN loss: 0.6992597579956055\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 924/1200 GAN loss: 0.6988201141357422\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 925/1200 GAN loss: 0.7027121782302856\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 926/1200 GAN loss: 0.7095702290534973\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 927/1200 GAN loss: 0.7258892059326172\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 928/1200 GAN loss: 0.7233608365058899\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 929/1200 GAN loss: 0.7201200127601624\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 930/1200 GAN loss: 0.7146206498146057\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 931/1200 GAN loss: 0.715130090713501\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 932/1200 GAN loss: 0.7031984329223633\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 933/1200 GAN loss: 0.7110884189605713\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 934/1200 GAN loss: 0.706590473651886\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 935/1200 GAN loss: 0.6959163546562195\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 936/1200 GAN loss: 0.7034580707550049\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 937/1200 GAN loss: 0.7083746194839478\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 938/1200 GAN loss: 0.7089554071426392\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 939/1200 GAN loss: 0.7104216814041138\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 940/1200 GAN loss: 0.7133357524871826\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 941/1200 GAN loss: 0.7188137769699097\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 942/1200 GAN loss: 0.7145019173622131\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 943/1200 GAN loss: 0.7073469161987305\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 944/1200 GAN loss: 0.7032510638237\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 945/1200 GAN loss: 0.6975207924842834\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 946/1200 GAN loss: 0.7046560049057007\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 947/1200 GAN loss: 0.7066870927810669\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 948/1200 GAN loss: 0.7064253687858582\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 949/1200 GAN loss: 0.7115869522094727\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 950/1200 GAN loss: 0.7207340002059937\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 951/1200 GAN loss: 0.718055248260498\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 952/1200 GAN loss: 0.7076458930969238\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 953/1200 GAN loss: 0.6996152400970459\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 954/1200 GAN loss: 0.700218141078949\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 955/1200 GAN loss: 0.6964115500450134\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 956/1200 GAN loss: 0.7000107765197754\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 957/1200 GAN loss: 0.7027319073677063\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 958/1200 GAN loss: 0.7051113247871399\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 959/1200 GAN loss: 0.7016251087188721\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 960/1200 GAN loss: 0.701381504535675\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 961/1200 GAN loss: 0.7025931477546692\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 962/1200 GAN loss: 0.7048218250274658\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 963/1200 GAN loss: 0.71121746301651\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 964/1200 GAN loss: 0.7103054523468018\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 965/1200 GAN loss: 0.706125020980835\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 966/1200 GAN loss: 0.7030412554740906\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 967/1200 GAN loss: 0.6994417905807495\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 968/1200 GAN loss: 0.7051701545715332\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 969/1200 GAN loss: 0.710145890712738\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 970/1200 GAN loss: 0.7152376174926758\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 971/1200 GAN loss: 0.7091015577316284\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 972/1200 GAN loss: 0.7012614011764526\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 973/1200 GAN loss: 0.6993530988693237\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 974/1200 GAN loss: 0.696582555770874\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 975/1200 GAN loss: 0.6945400238037109\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 976/1200 GAN loss: 0.693073034286499\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 977/1200 GAN loss: 0.6949310302734375\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 978/1200 GAN loss: 0.7006844282150269\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 979/1200 GAN loss: 0.7056746482849121\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 980/1200 GAN loss: 0.7054144144058228\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 981/1200 GAN loss: 0.7089731693267822\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 982/1200 GAN loss: 0.7131776809692383\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 983/1200 GAN loss: 0.7314783334732056\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 984/1200 GAN loss: 0.7356386184692383\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 985/1200 GAN loss: 0.7236097455024719\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 986/1200 GAN loss: 0.7111712694168091\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 987/1200 GAN loss: 0.6892648935317993\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 988/1200 GAN loss: 0.6828498244285583\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 989/1200 GAN loss: 0.6895449161529541\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 990/1200 GAN loss: 0.7028318047523499\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 991/1200 GAN loss: 0.7164719104766846\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 992/1200 GAN loss: 0.7368271946907043\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 993/1200 GAN loss: 0.7259730100631714\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 994/1200 GAN loss: 0.7148429751396179\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 995/1200 GAN loss: 0.7035245895385742\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 996/1200 GAN loss: 0.7037779092788696\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 997/1200 GAN loss: 0.6923351287841797\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 998/1200 GAN loss: 0.6955258250236511\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 999/1200 GAN loss: 0.7023220062255859\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1000/1200 GAN loss: 0.7596027255058289\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1001/1200 GAN loss: 0.7750356793403625\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1002/1200 GAN loss: 0.7606763243675232\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1003/1200 GAN loss: 0.7380738854408264\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1004/1200 GAN loss: 0.6961767673492432\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1005/1200 GAN loss: 0.678864598274231\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1006/1200 GAN loss: 0.6814988851547241\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1007/1200 GAN loss: 0.7011181116104126\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1008/1200 GAN loss: 0.7283244729042053\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1009/1200 GAN loss: 0.7455353140830994\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1010/1200 GAN loss: 0.7405768036842346\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1011/1200 GAN loss: 0.7299260497093201\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1012/1200 GAN loss: 0.7110673189163208\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1013/1200 GAN loss: 0.7019578814506531\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1014/1200 GAN loss: 0.700960099697113\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1015/1200 GAN loss: 0.7037162780761719\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1016/1200 GAN loss: 0.7170416116714478\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1017/1200 GAN loss: 0.7277514934539795\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1018/1200 GAN loss: 0.7245132923126221\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1019/1200 GAN loss: 0.7185207605361938\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1020/1200 GAN loss: 0.7051637172698975\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1021/1200 GAN loss: 0.7050984501838684\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1022/1200 GAN loss: 0.7039185166358948\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1023/1200 GAN loss: 0.699967086315155\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1024/1200 GAN loss: 0.696668267250061\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1025/1200 GAN loss: 0.7057832479476929\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1026/1200 GAN loss: 0.721583366394043\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1027/1200 GAN loss: 0.7299097180366516\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1028/1200 GAN loss: 0.7301987409591675\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1029/1200 GAN loss: 0.7238751649856567\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1030/1200 GAN loss: 0.7129793167114258\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1031/1200 GAN loss: 0.7066354751586914\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1032/1200 GAN loss: 0.6982800960540771\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1033/1200 GAN loss: 0.6989384889602661\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1034/1200 GAN loss: 0.7095341682434082\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1035/1200 GAN loss: 0.7063131332397461\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1036/1200 GAN loss: 0.711280882358551\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1037/1200 GAN loss: 0.706767737865448\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1038/1200 GAN loss: 0.7114092111587524\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1039/1200 GAN loss: 0.709470272064209\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1040/1200 GAN loss: 0.7124226689338684\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1041/1200 GAN loss: 0.7110518217086792\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1042/1200 GAN loss: 0.7086813449859619\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1043/1200 GAN loss: 0.7055490016937256\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1044/1200 GAN loss: 0.7222781777381897\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1045/1200 GAN loss: 0.7285976409912109\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1046/1200 GAN loss: 0.7284872531890869\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1047/1200 GAN loss: 0.7202993631362915\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1048/1200 GAN loss: 0.7140304446220398\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1049/1200 GAN loss: 0.7090951204299927\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1050/1200 GAN loss: 0.7026376724243164\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1051/1200 GAN loss: 0.7052079439163208\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1052/1200 GAN loss: 0.7023441791534424\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1053/1200 GAN loss: 0.7093645334243774\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1054/1200 GAN loss: 0.7089318037033081\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1055/1200 GAN loss: 0.7113025188446045\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1056/1200 GAN loss: 0.7128661274909973\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1057/1200 GAN loss: 0.7064933776855469\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1058/1200 GAN loss: 0.7043728232383728\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1059/1200 GAN loss: 0.7042382955551147\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1060/1200 GAN loss: 0.7011280059814453\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1061/1200 GAN loss: 0.7057880163192749\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1062/1200 GAN loss: 0.7123928070068359\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1063/1200 GAN loss: 0.7154446244239807\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1064/1200 GAN loss: 0.7177647948265076\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1065/1200 GAN loss: 0.716354250907898\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1066/1200 GAN loss: 0.7128221988677979\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1067/1200 GAN loss: 0.7127383947372437\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1068/1200 GAN loss: 0.7055197954177856\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1069/1200 GAN loss: 0.6963039040565491\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1070/1200 GAN loss: 0.6958970427513123\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1071/1200 GAN loss: 0.7042835354804993\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1072/1200 GAN loss: 0.7129435539245605\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1073/1200 GAN loss: 0.7139449119567871\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1074/1200 GAN loss: 0.7080453038215637\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1075/1200 GAN loss: 0.706567645072937\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1076/1200 GAN loss: 0.7064456939697266\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1077/1200 GAN loss: 0.7051828503608704\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1078/1200 GAN loss: 0.704953134059906\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1079/1200 GAN loss: 0.7094686031341553\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1080/1200 GAN loss: 0.707483172416687\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1081/1200 GAN loss: 0.7062095999717712\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1082/1200 GAN loss: 0.71234130859375\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1083/1200 GAN loss: 0.7162483930587769\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1084/1200 GAN loss: 0.7221437692642212\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1085/1200 GAN loss: 0.7179456949234009\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1086/1200 GAN loss: 0.7146565318107605\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1087/1200 GAN loss: 0.7107032537460327\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1088/1200 GAN loss: 0.704359769821167\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1089/1200 GAN loss: 0.7035211324691772\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1090/1200 GAN loss: 0.7028506994247437\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1091/1200 GAN loss: 0.708177924156189\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1092/1200 GAN loss: 0.7061406373977661\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1093/1200 GAN loss: 0.7079979777336121\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1094/1200 GAN loss: 0.7091197967529297\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1095/1200 GAN loss: 0.7098733186721802\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1096/1200 GAN loss: 0.7088533043861389\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1097/1200 GAN loss: 0.7102696895599365\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1098/1200 GAN loss: 0.7071918845176697\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1099/1200 GAN loss: 0.707218587398529\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1100/1200 GAN loss: 0.7077040672302246\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1101/1200 GAN loss: 0.7061553597450256\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1102/1200 GAN loss: 0.7079241275787354\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1103/1200 GAN loss: 0.7119584083557129\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1104/1200 GAN loss: 0.7129755616188049\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1105/1200 GAN loss: 0.7092664837837219\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1106/1200 GAN loss: 0.7078494429588318\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1107/1200 GAN loss: 0.7092239856719971\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1108/1200 GAN loss: 0.7106664776802063\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1109/1200 GAN loss: 0.7075693011283875\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1110/1200 GAN loss: 0.7107378840446472\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1111/1200 GAN loss: 0.7027265429496765\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1112/1200 GAN loss: 0.7036172151565552\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1113/1200 GAN loss: 0.7053517699241638\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1114/1200 GAN loss: 0.7094271183013916\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1115/1200 GAN loss: 0.7084897756576538\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1116/1200 GAN loss: 0.7087105512619019\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1117/1200 GAN loss: 0.7044039964675903\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1118/1200 GAN loss: 0.6986652612686157\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1119/1200 GAN loss: 0.6958814263343811\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1120/1200 GAN loss: 0.7019684314727783\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1121/1200 GAN loss: 0.7092869281768799\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1122/1200 GAN loss: 0.7124425172805786\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1123/1200 GAN loss: 0.7095993161201477\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1124/1200 GAN loss: 0.7091413736343384\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1125/1200 GAN loss: 0.7040496468544006\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1126/1200 GAN loss: 0.7024896740913391\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1127/1200 GAN loss: 0.7026003003120422\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1128/1200 GAN loss: 0.7026136517524719\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1129/1200 GAN loss: 0.702764630317688\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1130/1200 GAN loss: 0.7021383047103882\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1131/1200 GAN loss: 0.7030839323997498\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1132/1200 GAN loss: 0.7012056708335876\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1133/1200 GAN loss: 0.7018241882324219\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1134/1200 GAN loss: 0.7019511461257935\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1135/1200 GAN loss: 0.7041430473327637\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1136/1200 GAN loss: 0.7049407362937927\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1137/1200 GAN loss: 0.7051509022712708\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1138/1200 GAN loss: 0.7058151960372925\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1139/1200 GAN loss: 0.7053443193435669\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1140/1200 GAN loss: 0.7022683620452881\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1141/1200 GAN loss: 0.7032426595687866\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1142/1200 GAN loss: 0.7088467478752136\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1143/1200 GAN loss: 0.710820734500885\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1144/1200 GAN loss: 0.7148411870002747\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1145/1200 GAN loss: 0.7116649746894836\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1146/1200 GAN loss: 0.7072304487228394\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1147/1200 GAN loss: 0.7074123024940491\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1148/1200 GAN loss: 0.706357479095459\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1149/1200 GAN loss: 0.7021458148956299\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1150/1200 GAN loss: 0.7019590139389038\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1151/1200 GAN loss: 0.7015602588653564\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1152/1200 GAN loss: 0.706179141998291\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1153/1200 GAN loss: 0.709730863571167\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1154/1200 GAN loss: 0.7056254148483276\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1155/1200 GAN loss: 0.7042700052261353\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1156/1200 GAN loss: 0.7035249471664429\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1157/1200 GAN loss: 0.7014021277427673\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1158/1200 GAN loss: 0.6993834972381592\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1159/1200 GAN loss: 0.7000200748443604\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1160/1200 GAN loss: 0.7013843059539795\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1161/1200 GAN loss: 0.7025278806686401\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1162/1200 GAN loss: 0.7039949893951416\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1163/1200 GAN loss: 0.7059950828552246\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1164/1200 GAN loss: 0.7062544822692871\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1165/1200 GAN loss: 0.7052828073501587\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1166/1200 GAN loss: 0.7041597366333008\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1167/1200 GAN loss: 0.702556312084198\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1168/1200 GAN loss: 0.7020682692527771\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1169/1200 GAN loss: 0.6971753239631653\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1170/1200 GAN loss: 0.6985814571380615\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1171/1200 GAN loss: 0.6991336345672607\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1172/1200 GAN loss: 0.7012882828712463\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1173/1200 GAN loss: 0.7036395072937012\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1174/1200 GAN loss: 0.700537919998169\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1175/1200 GAN loss: 0.7042372822761536\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1176/1200 GAN loss: 0.7038785815238953\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1177/1200 GAN loss: 0.7049579620361328\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1178/1200 GAN loss: 0.7066014409065247\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1179/1200 GAN loss: 0.7074946165084839\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1180/1200 GAN loss: 0.7014616131782532\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1181/1200 GAN loss: 0.6993964910507202\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1182/1200 GAN loss: 0.693555474281311\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1183/1200 GAN loss: 0.6944904327392578\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1184/1200 GAN loss: 0.6964826583862305\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1185/1200 GAN loss: 0.6960654854774475\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1186/1200 GAN loss: 0.699006199836731\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1187/1200 GAN loss: 0.7008320093154907\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1188/1200 GAN loss: 0.7006557583808899\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1189/1200 GAN loss: 0.7009527087211609\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1190/1200 GAN loss: 0.7010678052902222\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1191/1200 GAN loss: 0.7010185122489929\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1192/1200 GAN loss: 0.7002825736999512\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1193/1200 GAN loss: 0.7015324831008911\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1194/1200 GAN loss: 0.6957631707191467\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1195/1200 GAN loss: 0.693472146987915\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1196/1200 GAN loss: 0.6946475505828857\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1197/1200 GAN loss: 0.6944913864135742\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1198/1200 GAN loss: 0.701262354850769\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1199/1200 GAN loss: 0.7044317722320557\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1200/1200 GAN loss: 0.7054157257080078\n"
     ]
    }
   ],
   "source": [
    "train(generator, discriminator, GAN, dataset_numpy_scaled, epochs=1200, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5b52e92b-0808-410d-9600-99fedbe8ab52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img0.jpeg',\n",
       " 'img1000.jpeg',\n",
       " 'img1199.jpeg',\n",
       " 'img200.jpeg',\n",
       " 'img400.jpeg',\n",
       " 'img600.jpeg',\n",
       " 'img800.jpeg']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path ='./data/data/1__GAN/'\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d0f47196-6124-4ea3-ab41-7c921550a027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = [np.asarray(Image.open(path+imgname)) for imgname in os.listdir(path)]\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "1f53ef2c-f847-4f37-a7c8-107ff0f63e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Füge optional weitere Inhalte zu.\n",
    "fig, axs = plt.subplots(1, 7, figsize=(10, 6))\n",
    "fig.tight_layout(pad=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "img_names = os.listdir(path)\n",
    "\n",
    "\n",
    "for i in range(len(images)):\n",
    "    axs[i].set_title(img_names[i])\n",
    "    axs[i].imshow(images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1cb142-38d2-46b5-ad68-8e3061174c94",
   "metadata": {},
   "source": [
    "<h1>Zweites Beispiel - 2 Verschiedene Formen</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8efc500-2565-4951-b551-c967e1d654db",
   "metadata": {},
   "source": [
    "Diesmal wollen wir 2 Formen und ein größeres Netz nutzen. Das Vorgehen ist ähnlich aber Umfangreicher.\n",
    "\n",
    "Um ein GAN zu erstellen, das verschiedene Klassen unterscheidet, nutzen wir Embeddings, um den Input des Generators zu verändern.<br>\n",
    "Zusätzlich können wir Dropouts nutzen. Bei komplexeren Formen und größeren Netzen nutzen wir auch CNN Layers. Weitere ist optional.\n",
    "- Hier wieder als ANN. CNN ist üblich bei GANs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "966624c5-563c-490e-8eb2-26d6188e5991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(num_classes: int = 2):\n",
    "    # Hier Nutzen wir zusätzlich Embeddings Layers.\n",
    "    \n",
    "    noise_input = tf.keras.Input(shape=(100,))  # Noise \n",
    "    label_input = tf.keras.Input(shape=(1,), dtype='int32')  # Klassen Label wie z. B. Form_A, Form_B, ... \n",
    "    \n",
    "    label_embedding = tf.keras.layers.Embedding(input_dim=num_classes, output_dim=100)(label_input)\n",
    "    label_embedding = tf.keras.layers.Flatten()(label_embedding)\n",
    "    \n",
    "    model_input = tf.keras.layers.multiply([noise_input, label_embedding])  # Label * Startbild, statt nur Startbild wie oben. \n",
    "    \n",
    "    # --------- #\n",
    "    \"\"\" \n",
    "    gen_ann = tf.keras.Sequential()\n",
    "    gen_ann.add( tf.keras.layers.Dense(units=300, activation='relu'))\n",
    "    gen_ann.add( tf.keras.layers.BatchNormalization())\n",
    "    gen_ann.add( tf.keras.layers.Dense(units=500, activation='relu'))\n",
    "\n",
    "    \"\"\"\n",
    "    # Nutze andere Herangehensweise. \n",
    "    x = tf.keras.layers.Dense(units=300, activation='relu')(model_input)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(units=500, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(units=800, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = tf.keras.layers.Dense(units=450, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(units=20*20, activation='tanh')(x)\n",
    "    output = tf.keras.layers.Reshape((20, 20, 1))(x)\n",
    "   \n",
    "    return tf.keras.Model([noise_input, label_input], output)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17684306-9288-4151-b69f-6daa1f05a722",
   "metadata": {},
   "source": [
    "# Teste, ob Aufbau funktioniert. \n",
    "generator = create_generator(2)\n",
    "noise     = np.random.normal(0, 1, (1, 100))\n",
    "\n",
    "fake_labels = np.random.randint(0, 2, 1)\n",
    "fake_images = generator.predict([noise, fake_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "35fedd6a-6b96-43ab-935c-36eb3c3a8eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator(num_classes: int = 2):\n",
    "    # Hier Nutzen wir zusätzlich Embeddings.\n",
    "    \n",
    "    image_input = tf.keras.Input(shape=(20, 20, 1))  # Bild Input. \n",
    "    label_input = tf.keras.Input(shape=(1,), dtype='int32')\n",
    "    \n",
    "    label_embedding = tf.keras.layers.Embedding(input_dim=num_classes, output_dim=20*20)(label_input)\n",
    "    label_embedding = tf.keras.layers.Flatten()(label_embedding)\n",
    "    \n",
    "    label_embedding = tf.keras.layers.Reshape((20, 20, 1))(label_embedding)\n",
    "    model_input = tf.keras.layers.concatenate([image_input, label_embedding])\n",
    "    # --------- #\n",
    "    x = tf.keras.layers.Flatten(input_shape=(20,20, 1))(model_input)\n",
    "    x = tf.keras.layers.Dense(500, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(700, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(550, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(320, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(150, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(75, activation='relu')(x)\n",
    "    output =  tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "   \n",
    "   \n",
    "    return tf.keras.Model([image_input, label_input], output)\n",
    "\n",
    "discriminator = create_discriminator()\n",
    "discriminator.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss      = 'binary_crossentropy',\n",
    "    metrics   = 'accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783401f5-ca8c-495c-8b35-5e6c212a6d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d398e467-8da2-4f5a-8f21-22585bd5740b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e409a518-82f6-4cc8-8d7e-be4164ee40f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
