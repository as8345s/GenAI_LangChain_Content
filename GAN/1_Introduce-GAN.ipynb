{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7680ebd-ae71-4fa5-80dc-626581270f03",
   "metadata": {},
   "source": [
    "<h1>GAN - Generative Adversarial Network</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc6292a-1179-40d0-bf92-55803f676e64",
   "metadata": {},
   "source": [
    "Ein GAN ist ein Netzwerk, das aus zwei verschiedenen Komponenten besteht. Das Ziel ist es Bilder zu generieren.\n",
    "\n",
    "Ein GAN besteht aus:<br>\n",
    "- Einem Generator, der ein Bild erzeugen soll. Durch Anpassung der Weights kann das Model in eine Richtung gelenkt werden, das am Ende ein Vektor ausgibt das als Bild angezeigt werden kann. Quasi das Gegenteil von einem CNN.\n",
    "- Ein Discriminator, der das Generatornetz evaluiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1864545-15f8-4e5b-89ca-1943d219ea55",
   "metadata": {},
   "source": [
    "Beide können aus einem ANN oder CNN erstellt werden. Je umfangreicher das Netz ist, desto mehr Features kann es besser Abdecken.\n",
    "\n",
    "Ein einfaches Netz kann aus zwei ANNs erstellt werden. \n",
    "\n",
    "GANs können in verschiedene Use-Cases eingesetzt werden. Um ein erstes einfaches Beispiel zu erstellen, ist die Aufgabe synthetische Bilder von einem Produkt herzustellen was für eine Qualitätskontrolle genutzt werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683e8617-f462-4df7-9285-96ec35405f3e",
   "metadata": {},
   "source": [
    "<i>Abb1</i>: [Coming soon]\n",
    "\n",
    "<img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e0c43d-3b28-4998-aab5-2385cf633b15",
   "metadata": {},
   "source": [
    "Als Komponente haben wir ein 20 x 20 Bild mit einem \"L\" darauf. Das L könnte ein L-förmiges Bauteil sein. Bei der Produktion werden viele dieser Komponenten hergestellt.Mit der Synthetisierung dieser Bilder können wir mehr Daten generieren, die für das Training eines CNN verwendet werden können, um Abweichungen besser abzudecken. \n",
    "\n",
    "Wir gehen davon aus das es viel mehr Bilder von guten Bauteilen gibt und sehr wenige von nicht guten Bauteilen. Mit den synthetischen Bildern kann die Lücke geschlossen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4dc49a5-c4c5-45fd-bc28-ccf5950b06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535c6f11-affe-4908-884b-a7cb7276d894",
   "metadata": {},
   "source": [
    "<h2> Dataset </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ebe31d-ca05-4f7e-8330-ffff85e4f841",
   "metadata": {},
   "source": [
    "Um so ein Bild zu erstellen, kann ein Zeichenprogramm oder Numpy verwendet werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b112d56e-d57d-4f55-a10a-d01ffd115867",
   "metadata": {},
   "source": [
    "<i>Abb2</i>: Zeichnung L-Objekt.\n",
    "\n",
    "<img src=\"./data/img/1_gan.PNG\" width=400, height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff631f0c-d1cd-4aa7-97f1-7923dae206c9",
   "metadata": {},
   "source": [
    "Alternativ kann auch mit Numpy eine einfache Form gezeichnet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b93abf1-525e-4c00-8e0e-ff81b8791410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle 1 Sample. \n",
    "def create_image(color:int=1) -> np.array:\n",
    "    image = np.zeros((20, 20))  # 2D Matrix, 20x20 Pixel.\n",
    "    # img [yloc, xloc]\n",
    "    image[1:12, 7] = 1  # Zeichne Feld.\n",
    "    image[1:12, 8] = 1  # Zeichne Feld.\n",
    "\n",
    "    image[11, 9:15]  = 1  \n",
    "    image[12, 7:15] = 1  \n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54c30e4a-4a7d-4574-b181-fa799441a3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = create_image()\n",
    "plt.matshow(img)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af5550-6c08-4661-9ec0-0e35e4275eb3",
   "metadata": {},
   "source": [
    "Schnell und einfach ist das Bild erstellt. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8ae06f-79ff-4fe7-894b-723cd201e7d2",
   "metadata": {},
   "source": [
    "<h3>Numpy Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ebb913-7b87-4430-ba91-debc3965e979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(950, 20, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Erstelle Dataset aus n-Samples \n",
    "def numpy_dataset(n:int):\n",
    "    return np.array([create_image() for x in range(n)])\n",
    "    \n",
    "size = 950\n",
    "dataset_numpy = numpy_dataset(size)\n",
    "dataset_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0a83280-1fc3-4939-8394-7974b399c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_numpy = dataset_numpy.reshape(size, 20, 20, 1).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c74cdfb-e749-4cd5-8f0d-3c9d1972dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dann können die Daten normalisiert werden.\n",
    "dataset_numpy_scaled = ( dataset_numpy - 0.5 ) / 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bdb104",
   "metadata": {},
   "source": [
    "Oder lade das Bild als numpy Array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ed2aa31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lade Bild mit OpenCV.\n",
    "# - Oder nutze Alternative wie PIL, ..., \n",
    "img = cv2.imread('./data/img/1_gan.PNG')\n",
    "type(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595d82b1",
   "metadata": {},
   "source": [
    "Danach kann das Bild in ein Dataframe geladen und ggf. Transformiert und angepasst werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c83382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f4a54d2",
   "metadata": {},
   "source": [
    "<h3>Tensorflow Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48baf7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d2cd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edd9447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Content coming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ace54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d854b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8cc139c-8c2d-4dc2-85d2-b0de1b051556",
   "metadata": {},
   "source": [
    "<h2>GAN Model - ANN</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e972ca2-75c2-4f35-9fd2-e22aa0317ebd",
   "metadata": {},
   "source": [
    "Dann erstellen wir zwei separate ANN Netze die verschiedene Aufgaben übernehmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f9dc5c8-be09-4c10-a80a-646cd8b490fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator ANN #\n",
    "gen_ann = tf.keras.Sequential([\n",
    "    # Input 100 Units, Output 128 Units.\n",
    "    tf.keras.layers.Dense(units=128, input_shape=(100,), activation='relu'),\n",
    "    \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(units=400, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(units=400, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    # Erstelle Vektor der dann als Bild 20x20 Pixel dargestellt wird.\n",
    "    tf.keras.layers.Dense(units=20*20, activation='tanh'),\n",
    "    tf.keras.layers.Reshape((20, 20, 1))\n",
    "])\n",
    "\n",
    "gen_ann.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss      = 'binary_crossentropy'\n",
    ")\n",
    "\n",
    "# Discriminator ANN # \n",
    "dis_ann = tf.keras.Sequential([\n",
    "    # Bild als Input. Netz soll Fake-Images erkennen. \n",
    "    tf.keras.layers.Flatten(input_shape=(20,20, 1)),\n",
    "    tf.keras.layers.Dense(350, activation='relu'),\n",
    "    tf.keras.layers.Dense(450, activation='relu'),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    # Als Output: Fake oder nicht.\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "dis_ann.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss      = 'binary_crossentropy',\n",
    "    metrics   = 'accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90306a96",
   "metadata": {},
   "source": [
    "Für einfache Formen sind die Netze ausreichend. Diese können später weiter optimiert werden.\n",
    "\n",
    "Der nächste wichtige Schritt ist das Netz zu trainieren. Dazu fügen wir beide Netze zusammen und trainieren vorerst nur den Generator. \n",
    "- Mit einem Parameter können die Weights eines Models eingefroren werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4964736-9676-4e61-8d1d-12d3200e19a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_ann.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ded1381b-ec02-42d8-8c0d-a718696c066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle GAN\n",
    "gan_input = tf.keras.layers.Input(shape=(100,))  # 100 Startpixel.\n",
    "gen_image   = gen_ann(gan_input)\n",
    "\n",
    "net_output = dis_ann(gen_image)\n",
    "GAN        = tf.keras.Model(gan_input, net_output)\n",
    "\n",
    "GAN.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb7b76-ad18-4d07-acca-914f71fd6417",
   "metadata": {},
   "source": [
    "Anders als sonst in Tensorflow schreiben wir eine detailreiche Trainingsschleife. \n",
    "- Batching möglich.\n",
    "\n",
    "Später werden wir uns weitere Details anschauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27712e9b-aa21-472c-bf93-f20d9fb0a559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Für das Batching: # \n",
    "# - Random-Index mit:\n",
    "np.random.randint(0, 3, 3)  #  (low, high, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df2680a0-b806-4902-89d2-f76b72efa305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02156837, -0.71190661,  1.36088468, -0.80407592,  0.13347914,\n",
       "         0.50984788, -1.80216675, -0.50818803, -0.70648184,  0.1854621 ,\n",
       "         0.31670522, -0.20302814, -0.77533357, -0.43206277, -0.23129412,\n",
       "         1.28562439, -0.97365041, -0.67258307, -1.23906337,  0.68102533,\n",
       "        -0.39392259,  0.31981078, -1.19549429,  1.81364233, -1.26484116,\n",
       "         2.21910654,  0.82968061,  0.70035338, -0.76756405, -0.97922583,\n",
       "        -0.93073212, -0.06020951,  1.22876206, -0.84197729, -0.66028986,\n",
       "        -0.25177895, -0.05467518,  0.92977739, -1.07999372, -0.00692581,\n",
       "         1.87825763, -0.80923744,  0.3823075 ,  0.53368414, -0.84705871,\n",
       "        -0.56732853, -0.09008819,  1.72397455,  1.03610675,  1.85866803,\n",
       "        -2.65799104,  0.45509704, -0.4620889 , -0.49524786, -0.59994832,\n",
       "         0.50960967,  0.0995081 , -0.08704069,  0.73630232,  1.46378351,\n",
       "         0.38085233,  0.45382795, -0.00835085,  1.2952008 , -2.32248931,\n",
       "        -1.67446841, -0.30481555, -0.98180995, -0.06918256, -0.68591911,\n",
       "        -0.01239205,  0.8967933 ,  1.38991169, -0.33075121, -2.13423932,\n",
       "         1.08951118,  0.5027539 ,  1.72906304, -1.09142002, -0.0137063 ,\n",
       "         0.02202788, -1.85239702,  0.86209276,  0.30745782,  1.06699976,\n",
       "         0.88645359, -0.71505386,  0.79156882, -1.4055631 ,  1.23812989,\n",
       "        -1.09000362, -0.76877476,  0.14138432,  0.44048854, -0.21229743,\n",
       "         0.9470664 ,  0.94894456,  0.06072918,  1.1691357 , -0.29066007],\n",
       "       [-1.20073326,  0.03499359, -0.17643692,  0.49025426, -0.70194003,\n",
       "        -1.42489355,  0.44542766,  0.19460612,  1.34823176,  0.89838321,\n",
       "        -1.19046753, -0.61889137,  1.54293194,  0.41102   ,  2.20798989,\n",
       "         0.11421301, -0.8772034 , -0.90650427, -0.88908155,  0.46127252,\n",
       "         0.63993292,  0.3489548 ,  0.43683804, -0.52634115,  0.34253635,\n",
       "         2.6614904 , -1.22904765,  3.16178675,  0.92865056,  0.61322676,\n",
       "         1.31264383,  0.49101219,  0.96322659,  0.0944654 ,  0.65416491,\n",
       "         0.32388426,  0.9448483 , -1.15914396, -0.13700279,  0.5899927 ,\n",
       "        -0.11670212, -0.32402697,  0.48372599,  1.50193356,  0.24630136,\n",
       "         0.21005626,  1.30636852,  0.96161075,  1.37375617,  0.02634458,\n",
       "         1.01019509, -1.98048262,  0.48240011,  0.20498559, -1.13533713,\n",
       "        -0.93297213, -0.18154675,  0.15764142,  1.12209877,  0.25457139,\n",
       "        -0.20703594, -0.88779304,  0.85161997,  0.18782638,  0.120986  ,\n",
       "         1.31962706, -0.59686729,  1.64289402,  0.25062188,  0.89983329,\n",
       "         0.48029243, -1.71901028, -0.54655251, -1.21255626, -1.13992521,\n",
       "         1.14043025,  0.03226904, -0.36169771,  0.80261557, -0.5802954 ,\n",
       "        -0.58036872, -0.74700819,  1.26887647, -2.12396652, -0.40853558,\n",
       "         0.39805478,  0.3473568 ,  0.48557402,  1.70150029, -0.81327754,\n",
       "        -0.92273649,  0.98178216, -0.26474022, -0.80073869, -0.63547259,\n",
       "        -1.54701791, -0.4221093 , -0.52854606, -0.62418198, -1.48751721]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generator Input # \n",
    "# - Üblich: Rauschen. Kann aber alles sein... \n",
    "#   => Aus dem Rauschen soll ein Bild entstehen. \n",
    "np.random.normal(0, 1, (2, 100))  # (loc, scale, size(x-Samples, shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b96b8b9e-df98-4b24-bc34-ab6deab850a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d44813c-48fb-4642-9e93-d09fe42e03f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsschleife # \n",
    "\n",
    "def train(generator, discriminator, gan, train_img, epochs, batch_size):\n",
    "    \n",
    "    half_batch = int(batch_size / 2)\n",
    "    \n",
    "    for epoch in range(epochs):  # Für jede Epoche mach das:\n",
    "        # Discriminator # \n",
    "        index = np.random.randint(0, train_img.shape[0], half_batch)  # Index für Samples. \n",
    "        real_images = train_img[index]  # Hole Samples.\n",
    "\n",
    "        noise       = np.random.normal(0, 1, (half_batch, 100))  # Erstelle Rauschen als Input. Kann aber auch komplett 0 sein. Üblich: Rauschen.\n",
    "        fake_images = generator.predict(noise)  # Erstelle Prediction. \n",
    "\n",
    "        # Berechne Loss. # Setze Labels.\n",
    "        # - train_on_batch(x, y), beide müssen n-Samples haben. \n",
    "        loss_real = discriminator.train_on_batch(real_images, np.ones(  (half_batch, 1) ))  # Label 1 für n-Samples für echte Bilder. \n",
    "        loss_fake = discriminator.train_on_batch(fake_images, np.zeros( (half_batch, 1) ))  # Label 0 für n-Samples für UN-echte Bilder.\n",
    "        d_loss = 0.5 * np.add(loss_real, loss_fake)  # Schnitt der Beiden Losses. \n",
    "\n",
    "        # Generator # \n",
    "        noise    = np.random.normal(0, 1, (batch_size, 100))\n",
    "        y        = np.ones(batch_size)\n",
    "        gan_loss = gan.train_on_batch(noise, y)\n",
    "\n",
    "        # Manuelle Ausgabe.:\n",
    "        print(f\"Epoche: {epoch + 1}/{epochs} GAN loss: {gan_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcd9e492-63b5-4219-8f76-004d9353c9cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 227ms/step\n",
      "Epoche: 1/500 GAN loss: 0.5209053158760071\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 2/500 GAN loss: 0.8491991758346558\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 3/500 GAN loss: 1.4610282182693481\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 4/500 GAN loss: 2.3235960006713867\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 5/500 GAN loss: 3.5769786834716797\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 6/500 GAN loss: 4.96592378616333\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 7/500 GAN loss: 6.143487930297852\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 8/500 GAN loss: 6.937300682067871\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 9/500 GAN loss: 7.73844051361084\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 10/500 GAN loss: 8.297172546386719\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 11/500 GAN loss: 8.816728591918945\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 12/500 GAN loss: 9.327449798583984\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 13/500 GAN loss: 9.78741455078125\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 14/500 GAN loss: 9.915300369262695\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 15/500 GAN loss: 10.103103637695312\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 16/500 GAN loss: 10.41774845123291\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 17/500 GAN loss: 10.437111854553223\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 18/500 GAN loss: 10.313410758972168\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 19/500 GAN loss: 10.148836135864258\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 20/500 GAN loss: 10.71707534790039\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 21/500 GAN loss: 11.216023445129395\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 22/500 GAN loss: 10.926786422729492\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 23/500 GAN loss: 11.112189292907715\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 24/500 GAN loss: 12.381813049316406\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 25/500 GAN loss: 12.549266815185547\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 26/500 GAN loss: 13.667200088500977\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 27/500 GAN loss: 14.525067329406738\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 28/500 GAN loss: 15.23069953918457\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 29/500 GAN loss: 15.9428129196167\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 30/500 GAN loss: 17.422260284423828\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 31/500 GAN loss: 18.674278259277344\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 32/500 GAN loss: 19.67269515991211\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 33/500 GAN loss: 20.170894622802734\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 34/500 GAN loss: 20.186290740966797\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 35/500 GAN loss: 19.922229766845703\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 36/500 GAN loss: 20.37238121032715\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 37/500 GAN loss: 20.704349517822266\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 38/500 GAN loss: 20.954444885253906\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 39/500 GAN loss: 20.681339263916016\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 40/500 GAN loss: 20.37104606628418\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 41/500 GAN loss: 20.47784423828125\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 42/500 GAN loss: 19.683481216430664\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 43/500 GAN loss: 21.287837982177734\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 44/500 GAN loss: 21.570785522460938\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 45/500 GAN loss: 21.70770835876465\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 46/500 GAN loss: 21.31524658203125\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 47/500 GAN loss: 21.41250991821289\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 48/500 GAN loss: 20.478700637817383\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 49/500 GAN loss: 19.512767791748047\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 50/500 GAN loss: 20.138832092285156\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 51/500 GAN loss: 18.9642391204834\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 52/500 GAN loss: 20.7160701751709\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 53/500 GAN loss: 17.609071731567383\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 54/500 GAN loss: 12.894774436950684\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 55/500 GAN loss: 11.571870803833008\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 56/500 GAN loss: 14.615198135375977\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 57/500 GAN loss: 21.031034469604492\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 58/500 GAN loss: 25.85442543029785\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 59/500 GAN loss: 14.407217979431152\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 60/500 GAN loss: 12.12833309173584\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 61/500 GAN loss: 8.235762596130371\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 62/500 GAN loss: 14.487430572509766\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 63/500 GAN loss: 23.222761154174805\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 64/500 GAN loss: 30.978174209594727\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 65/500 GAN loss: 34.13042449951172\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 66/500 GAN loss: 19.845470428466797\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 67/500 GAN loss: 10.467625617980957\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 68/500 GAN loss: 8.740250587463379\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 69/500 GAN loss: 7.318232536315918\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 70/500 GAN loss: 8.537227630615234\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 71/500 GAN loss: 9.304338455200195\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 72/500 GAN loss: 17.297306060791016\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 73/500 GAN loss: 25.976016998291016\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 74/500 GAN loss: 34.49462890625\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 75/500 GAN loss: 39.33506774902344\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 76/500 GAN loss: 15.748744010925293\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 77/500 GAN loss: 9.397504806518555\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 78/500 GAN loss: 11.06698226928711\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 79/500 GAN loss: 10.073556900024414\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 80/500 GAN loss: 6.649568557739258\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 81/500 GAN loss: 10.514289855957031\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 82/500 GAN loss: 15.031815528869629\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 83/500 GAN loss: 23.671524047851562\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 84/500 GAN loss: 31.218311309814453\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 85/500 GAN loss: 36.33668518066406\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 86/500 GAN loss: 24.856727600097656\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 87/500 GAN loss: 14.272270202636719\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 88/500 GAN loss: 10.575400352478027\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 89/500 GAN loss: 11.263834953308105\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 90/500 GAN loss: 11.722185134887695\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 91/500 GAN loss: 10.891183853149414\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 92/500 GAN loss: 17.062183380126953\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 93/500 GAN loss: 25.59507179260254\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 94/500 GAN loss: 15.150886535644531\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 95/500 GAN loss: 10.769577980041504\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 96/500 GAN loss: 9.300928115844727\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 97/500 GAN loss: 8.507364273071289\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 98/500 GAN loss: 8.224100112915039\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 99/500 GAN loss: 7.928261756896973\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 100/500 GAN loss: 9.08346176147461\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 101/500 GAN loss: 8.988290786743164\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 102/500 GAN loss: 12.047834396362305\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 103/500 GAN loss: 9.371820449829102\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 104/500 GAN loss: 6.314048767089844\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 105/500 GAN loss: 6.098576068878174\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 106/500 GAN loss: 6.945873260498047\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 107/500 GAN loss: 7.613341808319092\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 108/500 GAN loss: 7.086650371551514\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 109/500 GAN loss: 8.059636116027832\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 110/500 GAN loss: 7.950748920440674\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 111/500 GAN loss: 11.630571365356445\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 112/500 GAN loss: 6.753746032714844\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 113/500 GAN loss: 5.703393459320068\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 114/500 GAN loss: 5.799708366394043\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 115/500 GAN loss: 6.308348655700684\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 116/500 GAN loss: 6.817141532897949\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 117/500 GAN loss: 6.898704528808594\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 118/500 GAN loss: 7.57895565032959\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 119/500 GAN loss: 6.795642852783203\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 120/500 GAN loss: 7.219095230102539\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 121/500 GAN loss: 8.044515609741211\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 122/500 GAN loss: 7.047483921051025\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 123/500 GAN loss: 6.554491996765137\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 124/500 GAN loss: 5.704031467437744\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 125/500 GAN loss: 6.911093711853027\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 126/500 GAN loss: 9.420032501220703\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 127/500 GAN loss: 7.342898368835449\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 128/500 GAN loss: 6.423300743103027\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 129/500 GAN loss: 6.773040294647217\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 130/500 GAN loss: 6.5784759521484375\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 131/500 GAN loss: 8.571727752685547\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 132/500 GAN loss: 10.516040802001953\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 133/500 GAN loss: 9.998941421508789\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 134/500 GAN loss: 9.486685752868652\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 135/500 GAN loss: 7.806128978729248\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 136/500 GAN loss: 10.912955284118652\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 137/500 GAN loss: 7.0241546630859375\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 138/500 GAN loss: 4.54941463470459\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 139/500 GAN loss: 6.897324085235596\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 140/500 GAN loss: 6.412807941436768\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 141/500 GAN loss: 9.050874710083008\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 142/500 GAN loss: 6.500054836273193\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 143/500 GAN loss: 3.8324341773986816\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 144/500 GAN loss: 5.572858810424805\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 145/500 GAN loss: 8.360092163085938\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 146/500 GAN loss: 10.792123794555664\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 147/500 GAN loss: 7.001755714416504\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 148/500 GAN loss: 5.589404106140137\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 149/500 GAN loss: 4.053253173828125\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 150/500 GAN loss: 4.440809726715088\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 151/500 GAN loss: 6.554244041442871\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 152/500 GAN loss: 10.124761581420898\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 153/500 GAN loss: 9.99987506866455\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 154/500 GAN loss: 14.252185821533203\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 155/500 GAN loss: 10.099037170410156\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 156/500 GAN loss: 8.381543159484863\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 157/500 GAN loss: 6.721184730529785\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 158/500 GAN loss: 5.468494892120361\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 159/500 GAN loss: 7.070700645446777\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 160/500 GAN loss: 6.882992744445801\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 161/500 GAN loss: 7.4836745262146\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 162/500 GAN loss: 8.646258354187012\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 163/500 GAN loss: 6.867027282714844\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 164/500 GAN loss: 5.711089134216309\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 165/500 GAN loss: 4.823190689086914\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 166/500 GAN loss: 5.700938701629639\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 167/500 GAN loss: 6.548670291900635\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 168/500 GAN loss: 5.344033718109131\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 169/500 GAN loss: 5.17268180847168\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 170/500 GAN loss: 7.2375874519348145\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 171/500 GAN loss: 9.50438117980957\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 172/500 GAN loss: 5.927761554718018\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 173/500 GAN loss: 4.876642227172852\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 174/500 GAN loss: 4.912751197814941\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 175/500 GAN loss: 6.1423797607421875\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 176/500 GAN loss: 9.023818016052246\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 177/500 GAN loss: 9.567089080810547\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 178/500 GAN loss: 9.328445434570312\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 179/500 GAN loss: 8.121715545654297\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 180/500 GAN loss: 7.496960639953613\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 181/500 GAN loss: 7.023897171020508\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 182/500 GAN loss: 6.628134727478027\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 183/500 GAN loss: 7.16384744644165\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 184/500 GAN loss: 6.730987548828125\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 185/500 GAN loss: 6.840940952301025\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 186/500 GAN loss: 8.222307205200195\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 187/500 GAN loss: 7.147652626037598\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 188/500 GAN loss: 6.611162185668945\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 189/500 GAN loss: 7.223649501800537\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 190/500 GAN loss: 6.908806324005127\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 191/500 GAN loss: 6.8971967697143555\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 192/500 GAN loss: 6.401585578918457\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 193/500 GAN loss: 5.594374656677246\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 194/500 GAN loss: 7.277513027191162\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 195/500 GAN loss: 12.286521911621094\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 196/500 GAN loss: 3.6307120323181152\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 197/500 GAN loss: 2.1162497997283936\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 198/500 GAN loss: 1.2527146339416504\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 199/500 GAN loss: 2.3184051513671875\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 200/500 GAN loss: 5.065332412719727\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 201/500 GAN loss: 9.755720138549805\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 202/500 GAN loss: 8.647951126098633\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 203/500 GAN loss: 6.364376068115234\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 204/500 GAN loss: 7.246358871459961\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 205/500 GAN loss: 4.453411102294922\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 206/500 GAN loss: 4.78394079208374\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 207/500 GAN loss: 5.7507500648498535\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 208/500 GAN loss: 6.447953224182129\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 209/500 GAN loss: 7.533303737640381\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 210/500 GAN loss: 9.029301643371582\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 211/500 GAN loss: 8.193355560302734\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 212/500 GAN loss: 8.412792205810547\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 213/500 GAN loss: 7.752037525177002\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 214/500 GAN loss: 7.247673988342285\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 215/500 GAN loss: 5.7841339111328125\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 216/500 GAN loss: 5.5112833976745605\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 217/500 GAN loss: 5.346078872680664\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 218/500 GAN loss: 5.359697341918945\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 219/500 GAN loss: 5.547737121582031\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 220/500 GAN loss: 5.781322479248047\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 221/500 GAN loss: 5.524837970733643\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 222/500 GAN loss: 4.962442874908447\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 223/500 GAN loss: 4.249270439147949\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 224/500 GAN loss: 5.072945594787598\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 225/500 GAN loss: 4.785800933837891\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 226/500 GAN loss: 4.325283050537109\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 227/500 GAN loss: 3.8471388816833496\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 228/500 GAN loss: 4.129067897796631\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 229/500 GAN loss: 3.643202781677246\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 230/500 GAN loss: 4.3255510330200195\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 231/500 GAN loss: 4.055963516235352\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 232/500 GAN loss: 4.721980094909668\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 233/500 GAN loss: 4.1553144454956055\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 234/500 GAN loss: 3.7627310752868652\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 235/500 GAN loss: 5.3882832527160645\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 236/500 GAN loss: 4.788190841674805\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 237/500 GAN loss: 4.628201484680176\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 238/500 GAN loss: 4.470387935638428\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 239/500 GAN loss: 5.736264228820801\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 240/500 GAN loss: 5.630634784698486\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 241/500 GAN loss: 4.627636432647705\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 242/500 GAN loss: 5.009529113769531\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 243/500 GAN loss: 5.477329254150391\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 244/500 GAN loss: 3.7579305171966553\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 245/500 GAN loss: 4.010868072509766\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 246/500 GAN loss: 6.236058235168457\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 247/500 GAN loss: 4.703139781951904\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 248/500 GAN loss: 4.160330772399902\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 249/500 GAN loss: 5.052248001098633\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 250/500 GAN loss: 6.060680389404297\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 251/500 GAN loss: 4.972084999084473\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 252/500 GAN loss: 5.076913833618164\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 253/500 GAN loss: 5.538570404052734\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 254/500 GAN loss: 5.084132194519043\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 255/500 GAN loss: 4.696524620056152\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 256/500 GAN loss: 5.174429416656494\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 257/500 GAN loss: 4.931766986846924\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 258/500 GAN loss: 5.0266242027282715\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 259/500 GAN loss: 6.578884601593018\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 260/500 GAN loss: 4.134239196777344\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 261/500 GAN loss: 5.872235298156738\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 262/500 GAN loss: 6.466651439666748\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 263/500 GAN loss: 4.630478382110596\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 264/500 GAN loss: 5.362157821655273\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 265/500 GAN loss: 7.686121940612793\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 266/500 GAN loss: 3.2045679092407227\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 267/500 GAN loss: 4.786619186401367\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 268/500 GAN loss: 10.587818145751953\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 269/500 GAN loss: 1.2225613594055176\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 270/500 GAN loss: 0.6266326904296875\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 271/500 GAN loss: 0.5947588682174683\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 272/500 GAN loss: 5.3500518798828125\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 273/500 GAN loss: 12.923025131225586\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 274/500 GAN loss: 5.7893595695495605\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 275/500 GAN loss: 2.170523166656494\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 276/500 GAN loss: 1.3468241691589355\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 277/500 GAN loss: 1.9458239078521729\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 278/500 GAN loss: 3.25728178024292\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 279/500 GAN loss: 4.812537670135498\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 280/500 GAN loss: 3.45171856880188\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 281/500 GAN loss: 2.441129207611084\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 282/500 GAN loss: 2.4792256355285645\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 283/500 GAN loss: 2.131535530090332\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 284/500 GAN loss: 3.3289754390716553\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 285/500 GAN loss: 4.265620231628418\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 286/500 GAN loss: 4.287309646606445\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 287/500 GAN loss: 2.9449615478515625\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 288/500 GAN loss: 3.028486967086792\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 289/500 GAN loss: 2.6242799758911133\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 290/500 GAN loss: 3.3470892906188965\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 291/500 GAN loss: 3.5747907161712646\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 292/500 GAN loss: 3.3132643699645996\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 293/500 GAN loss: 2.860227108001709\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 294/500 GAN loss: 2.479526996612549\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 295/500 GAN loss: 3.1157093048095703\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 296/500 GAN loss: 3.2491607666015625\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 297/500 GAN loss: 2.253889560699463\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 298/500 GAN loss: 2.0732693672180176\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 299/500 GAN loss: 3.219918966293335\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 300/500 GAN loss: 3.0567374229431152\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 301/500 GAN loss: 2.925006866455078\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 302/500 GAN loss: 3.585702419281006\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 303/500 GAN loss: 2.551323413848877\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 304/500 GAN loss: 3.948401927947998\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 305/500 GAN loss: 3.3623485565185547\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 306/500 GAN loss: 2.1194519996643066\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 307/500 GAN loss: 1.7008655071258545\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 308/500 GAN loss: 4.176589488983154\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 309/500 GAN loss: 5.004291534423828\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 310/500 GAN loss: 1.405440092086792\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 311/500 GAN loss: 3.136016368865967\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 312/500 GAN loss: 8.661067962646484\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 313/500 GAN loss: 0.9087598323822021\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 314/500 GAN loss: 0.12912580370903015\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 315/500 GAN loss: 0.8145869970321655\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 316/500 GAN loss: 6.528256893157959\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 317/500 GAN loss: 5.881789207458496\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 318/500 GAN loss: 1.9599733352661133\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 319/500 GAN loss: 1.0670589208602905\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 320/500 GAN loss: 2.4827213287353516\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 321/500 GAN loss: 4.285012245178223\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 322/500 GAN loss: 4.681883811950684\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 323/500 GAN loss: 2.175767421722412\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 324/500 GAN loss: 1.9616281986236572\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 325/500 GAN loss: 1.968985915184021\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 326/500 GAN loss: 3.291660785675049\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 327/500 GAN loss: 3.762406587600708\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 328/500 GAN loss: 3.1982126235961914\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 329/500 GAN loss: 2.590486764907837\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 330/500 GAN loss: 2.296207904815674\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 331/500 GAN loss: 2.7843050956726074\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 332/500 GAN loss: 3.2311525344848633\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 333/500 GAN loss: 2.7405524253845215\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 334/500 GAN loss: 2.8780722618103027\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 335/500 GAN loss: 2.55188250541687\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 336/500 GAN loss: 3.1008121967315674\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 337/500 GAN loss: 3.328941822052002\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 338/500 GAN loss: 2.2747108936309814\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 339/500 GAN loss: 2.21890926361084\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 340/500 GAN loss: 3.0857856273651123\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 341/500 GAN loss: 2.8700013160705566\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 342/500 GAN loss: 2.686563491821289\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 343/500 GAN loss: 2.663188934326172\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 344/500 GAN loss: 1.7591438293457031\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 345/500 GAN loss: 2.5084526538848877\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 346/500 GAN loss: 2.766648054122925\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 347/500 GAN loss: 2.7368922233581543\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 348/500 GAN loss: 3.2418651580810547\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 349/500 GAN loss: 2.0106539726257324\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 350/500 GAN loss: 2.9245376586914062\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 351/500 GAN loss: 3.865023136138916\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 352/500 GAN loss: 2.9751031398773193\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 353/500 GAN loss: 5.187958717346191\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 354/500 GAN loss: 2.483949899673462\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 355/500 GAN loss: 2.4472129344940186\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 356/500 GAN loss: 4.4867472648620605\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 357/500 GAN loss: 1.125885248184204\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 358/500 GAN loss: 2.3525638580322266\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 359/500 GAN loss: 6.224373817443848\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 360/500 GAN loss: 0.44630149006843567\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 361/500 GAN loss: 0.3498643636703491\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 362/500 GAN loss: 3.0727386474609375\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 363/500 GAN loss: 7.505192279815674\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 364/500 GAN loss: 1.3865342140197754\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 365/500 GAN loss: 0.33347779512405396\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 366/500 GAN loss: 1.2580430507659912\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 367/500 GAN loss: 4.528700828552246\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 368/500 GAN loss: 3.5077924728393555\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 369/500 GAN loss: 1.437909483909607\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 370/500 GAN loss: 1.1532164812088013\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 371/500 GAN loss: 2.051952838897705\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 372/500 GAN loss: 3.377776622772217\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 373/500 GAN loss: 2.351363182067871\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 374/500 GAN loss: 1.4833040237426758\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 375/500 GAN loss: 1.4172282218933105\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 376/500 GAN loss: 2.571610450744629\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 377/500 GAN loss: 3.5656638145446777\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 378/500 GAN loss: 1.4669076204299927\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 379/500 GAN loss: 1.2165391445159912\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 380/500 GAN loss: 1.4823086261749268\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 381/500 GAN loss: 2.687854766845703\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 382/500 GAN loss: 2.203505516052246\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 383/500 GAN loss: 1.4542763233184814\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 384/500 GAN loss: 2.325843334197998\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 385/500 GAN loss: 2.553530693054199\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 386/500 GAN loss: 3.5716357231140137\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 387/500 GAN loss: 1.6932733058929443\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 388/500 GAN loss: 2.015188455581665\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 389/500 GAN loss: 2.124089241027832\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 390/500 GAN loss: 1.256577968597412\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 391/500 GAN loss: 1.6873512268066406\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 392/500 GAN loss: 2.160860538482666\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 393/500 GAN loss: 2.179291248321533\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 394/500 GAN loss: 1.849531888961792\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 395/500 GAN loss: 2.1281118392944336\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 396/500 GAN loss: 1.7370696067810059\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 397/500 GAN loss: 1.5718733072280884\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 398/500 GAN loss: 2.234957695007324\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 399/500 GAN loss: 2.8346893787384033\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 400/500 GAN loss: 2.3559441566467285\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 401/500 GAN loss: 2.7040762901306152\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 402/500 GAN loss: 1.8526948690414429\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 403/500 GAN loss: 2.3722212314605713\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 404/500 GAN loss: 1.8702799081802368\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 405/500 GAN loss: 2.490572929382324\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 406/500 GAN loss: 2.536165475845337\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 407/500 GAN loss: 2.0930335521698\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 408/500 GAN loss: 2.963111400604248\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 409/500 GAN loss: 2.1247875690460205\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 410/500 GAN loss: 2.0241987705230713\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 411/500 GAN loss: 2.0835952758789062\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 412/500 GAN loss: 1.8142502307891846\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 413/500 GAN loss: 2.6862778663635254\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 414/500 GAN loss: 1.9259576797485352\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 415/500 GAN loss: 2.5860257148742676\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 416/500 GAN loss: 2.745879888534546\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 417/500 GAN loss: 1.6011731624603271\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 418/500 GAN loss: 1.7076033353805542\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 419/500 GAN loss: 2.566049575805664\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 420/500 GAN loss: 2.2110440731048584\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 421/500 GAN loss: 1.7864007949829102\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 422/500 GAN loss: 1.74923574924469\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 423/500 GAN loss: 2.2933521270751953\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 424/500 GAN loss: 1.3524634838104248\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 425/500 GAN loss: 2.49574613571167\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 426/500 GAN loss: 1.593602180480957\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 427/500 GAN loss: 1.6169240474700928\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 428/500 GAN loss: 2.8027729988098145\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 429/500 GAN loss: 1.4326140880584717\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 430/500 GAN loss: 1.3383145332336426\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 431/500 GAN loss: 2.4777886867523193\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 432/500 GAN loss: 1.4265223741531372\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 433/500 GAN loss: 1.0449326038360596\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 434/500 GAN loss: 2.155606985092163\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 435/500 GAN loss: 2.0386016368865967\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 436/500 GAN loss: 1.6910786628723145\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 437/500 GAN loss: 2.3204522132873535\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 438/500 GAN loss: 1.8714888095855713\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 439/500 GAN loss: 1.7799888849258423\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 440/500 GAN loss: 2.1580564975738525\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 441/500 GAN loss: 1.3582940101623535\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 442/500 GAN loss: 2.575199604034424\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 443/500 GAN loss: 1.8538060188293457\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 444/500 GAN loss: 1.4761451482772827\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 445/500 GAN loss: 2.409315347671509\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 446/500 GAN loss: 1.586338758468628\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 447/500 GAN loss: 1.927812099456787\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 448/500 GAN loss: 2.7359540462493896\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 449/500 GAN loss: 1.2127526998519897\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 450/500 GAN loss: 1.4263954162597656\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 451/500 GAN loss: 2.6948022842407227\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 452/500 GAN loss: 1.1864467859268188\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 453/500 GAN loss: 1.1016966104507446\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 454/500 GAN loss: 2.448293924331665\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 455/500 GAN loss: 2.8241963386535645\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 456/500 GAN loss: 1.102686882019043\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 457/500 GAN loss: 1.0616339445114136\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 458/500 GAN loss: 2.693134069442749\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 459/500 GAN loss: 2.469322443008423\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 460/500 GAN loss: 1.2779996395111084\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 461/500 GAN loss: 1.7295581102371216\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 462/500 GAN loss: 2.189502000808716\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 463/500 GAN loss: 1.6445250511169434\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 464/500 GAN loss: 1.724151849746704\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 465/500 GAN loss: 2.6978225708007812\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 466/500 GAN loss: 2.529282331466675\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 467/500 GAN loss: 1.631503939628601\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 468/500 GAN loss: 1.5126309394836426\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 469/500 GAN loss: 2.2962098121643066\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 470/500 GAN loss: 1.8668508529663086\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 471/500 GAN loss: 1.6266638040542603\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 472/500 GAN loss: 1.8487098217010498\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 473/500 GAN loss: 2.350705146789551\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 474/500 GAN loss: 2.1373543739318848\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 475/500 GAN loss: 1.6374210119247437\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 476/500 GAN loss: 1.4181041717529297\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 477/500 GAN loss: 1.8934342861175537\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 478/500 GAN loss: 2.054743766784668\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 479/500 GAN loss: 1.5213268995285034\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 480/500 GAN loss: 1.653148889541626\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 481/500 GAN loss: 1.9063317775726318\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 482/500 GAN loss: 2.0196104049682617\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 483/500 GAN loss: 1.841827630996704\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 484/500 GAN loss: 1.7194082736968994\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 485/500 GAN loss: 1.6270147562026978\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 486/500 GAN loss: 2.4869275093078613\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 487/500 GAN loss: 1.9041966199874878\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 488/500 GAN loss: 1.284188985824585\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 489/500 GAN loss: 1.9510838985443115\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 490/500 GAN loss: 1.6535805463790894\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 491/500 GAN loss: 1.661913275718689\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 492/500 GAN loss: 2.1498403549194336\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 493/500 GAN loss: 0.7863811254501343\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 494/500 GAN loss: 1.305124282836914\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 495/500 GAN loss: 2.7184064388275146\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 496/500 GAN loss: 0.9680087566375732\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 497/500 GAN loss: 0.8798433542251587\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 498/500 GAN loss: 2.0704550743103027\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 499/500 GAN loss: 1.829465627670288\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 500/500 GAN loss: 1.1643133163452148\n"
     ]
    }
   ],
   "source": [
    "train(gen_ann, dis_ann, GAN, dataset_numpy_scaled, epochs=500, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83990de7-7421-4e80-abed-d94b8b48fbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
