{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7680ebd-ae71-4fa5-80dc-626581270f03",
   "metadata": {},
   "source": [
    "<h1>GAN - Generative Adversarial Network - from Scratch</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc6292a-1179-40d0-bf92-55803f676e64",
   "metadata": {},
   "source": [
    "Ein GAN ist ein Netzwerk, das aus zwei verschiedenen Komponenten besteht. Das Ziel ist es Bilder zu generieren.\n",
    "\n",
    "Ein GAN besteht aus:<br>\n",
    "- Einem Generator, der ein Bild erzeugen soll. Durch Anpassung der Weights kann das Model in eine Richtung gelenkt werden, das am Ende ein Vektor ausgibt das als Bild angezeigt werden kann. Quasi das Gegenteil von einem CNN.\n",
    "- Ein Discriminator, der das Generatornetz evaluiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1864545-15f8-4e5b-89ca-1943d219ea55",
   "metadata": {},
   "source": [
    "Beide können aus einem ANN oder CNN erstellt werden. Je umfangreicher das Netz ist, desto mehr Features kann es besser Abdecken.\n",
    "\n",
    "Ein einfaches Netz kann aus zwei ANNs erstellt werden. \n",
    "\n",
    "GANs können in verschiedene Use-Cases eingesetzt werden. Um ein erstes einfaches Beispiel zu erstellen, ist die Aufgabe synthetische Bilder von einem Produkt herzustellen was für eine Qualitätskontrolle genutzt werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683e8617-f462-4df7-9285-96ec35405f3e",
   "metadata": {},
   "source": [
    "<i>Abb1</i>: [Coming soon]\n",
    "\n",
    "<img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e0c43d-3b28-4998-aab5-2385cf633b15",
   "metadata": {},
   "source": [
    "Als Komponente haben wir ein 20 x 20 Bild mit einem \"L\" darauf. Das L könnte ein L-förmiges Bauteil sein. Bei der Produktion werden viele dieser Komponenten hergestellt.Mit der Synthetisierung dieser Bilder können wir mehr Daten generieren, die für das Training eines CNN verwendet werden können, um Abweichungen besser abzudecken. \n",
    "\n",
    "Wir gehen davon aus das es viel mehr Bilder von guten Bauteilen gibt und sehr wenige von nicht guten Bauteilen. Mit den synthetischen Bildern kann die Lücke geschlossen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4dc49a5-c4c5-45fd-bc28-ccf5950b06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image  as matimg\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535c6f11-affe-4908-884b-a7cb7276d894",
   "metadata": {},
   "source": [
    "<h2> Dataset </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ebe31d-ca05-4f7e-8330-ffff85e4f841",
   "metadata": {},
   "source": [
    "Um so ein Bild zu erstellen, kann ein Zeichenprogramm oder Numpy verwendet werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b112d56e-d57d-4f55-a10a-d01ffd115867",
   "metadata": {},
   "source": [
    "<i>Abb2</i>: Zeichnung L-Objekt.\n",
    "\n",
    "<img src=\"./data/img/1_gan.PNG\" width=400, height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff631f0c-d1cd-4aa7-97f1-7923dae206c9",
   "metadata": {},
   "source": [
    "Alternativ kann auch mit Numpy eine einfache Form gezeichnet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b93abf1-525e-4c00-8e0e-ff81b8791410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle 1 Sample. \n",
    "def create_image(color:int=1) -> np.array:\n",
    "    image = np.zeros((20, 20))  # 2D Matrix, 20x20 Pixel.\n",
    "    # img [yloc, xloc]\n",
    "    image[1:12, 7] = 1  # Zeichne Feld.\n",
    "    image[1:12, 8] = 1  # Zeichne Feld.\n",
    "\n",
    "    image[11, 9:15]  = 1  \n",
    "    image[12, 7:15] = 1  \n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54c30e4a-4a7d-4574-b181-fa799441a3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = create_image()\n",
    "plt.matshow(img)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af5550-6c08-4661-9ec0-0e35e4275eb3",
   "metadata": {},
   "source": [
    "Schnell und einfach ist das Bild erstellt. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8ae06f-79ff-4fe7-894b-723cd201e7d2",
   "metadata": {},
   "source": [
    "<h3>Numpy Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ebb913-7b87-4430-ba91-debc3965e979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(950, 20, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Erstelle Dataset aus n-Samples \n",
    "def numpy_dataset(n:int):\n",
    "    return np.array([create_image() for x in range(n)])\n",
    "    \n",
    "size = 950\n",
    "dataset_numpy = numpy_dataset(size)\n",
    "dataset_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0a83280-1fc3-4939-8394-7974b399c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_numpy = dataset_numpy.reshape(size, 20, 20, 1).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c74cdfb-e749-4cd5-8f0d-3c9d1972dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dann können die Daten normalisiert werden.\n",
    "dataset_numpy_scaled = ( dataset_numpy - 0.5 ) / 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bdb104",
   "metadata": {},
   "source": [
    "Oder lade das Bild als numpy Array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed2aa31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lade Bild mit OpenCV.\n",
    "# - Oder nutze Alternative wie PIL, ..., \n",
    "img = cv2.imread('./data/datasets/L__shape/lshape.jpg')\n",
    "type(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595d82b1",
   "metadata": {},
   "source": [
    "Danach kann das Bild in ein Dataframe geladen und ggf. Transformiert und angepasst werden. Oder nutze andere Methoden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a54d2",
   "metadata": {},
   "source": [
    "<h3>Tensorflow Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "9edd9447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20, 20, 3), dtype=uint8, numpy=\n",
       "array([[[248, 248, 248],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[246, 246, 246],\n",
       "        [255, 255, 255],\n",
       "        [253, 253, 253],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [247, 247, 247],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8)>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lade Bild\n",
    "img = tf.io.read_file('./data/datasets/L__shape/lshape.jpg')\n",
    "img = tf.image.decode_jpeg(img)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "9aa14c41-33d9-41b0-b3b8-5f6272471358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorDataset element_spec=TensorSpec(shape=(20, 20, 3), dtype=tf.uint8, name=None)>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Erstelle Dataset\n",
    "tf_dataset = tf.data.Dataset.from_tensors(img)\n",
    "tf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf9c9f8-c8a5-4aaf-a83b-1d6d162a351f",
   "metadata": {},
   "source": [
    "Danach kann das TF-Dataset beliebig genutzt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc139c-8c2d-4dc2-85d2-b0de1b051556",
   "metadata": {},
   "source": [
    "<h2>GAN Model - ANN</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e972ca2-75c2-4f35-9fd2-e22aa0317ebd",
   "metadata": {},
   "source": [
    "Dann erstellen wir zwei separate ANN Netze die verschiedene Aufgaben übernehmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0f9dc5c8-be09-4c10-a80a-646cd8b490fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator ANN #\n",
    "\n",
    "def create_generator():\n",
    "    gen_ann = tf.keras.Sequential([\n",
    "        # Input 100 Units, Output 128 Units.\n",
    "        tf.keras.layers.Dense(units=128, input_shape=(100,), activation='relu'),\n",
    "    \n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(units=400, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(units=400, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        # Erstelle Vektor der dann als Bild 20x20 Pixel dargestellt wird.\n",
    "        tf.keras.layers.Dense(units=20*20, activation='tanh'),\n",
    "        tf.keras.layers.Reshape((20, 20, 1))\n",
    "    ])\n",
    "    return gen_ann\n",
    "\n",
    "\n",
    "# Discriminator ANN # \n",
    "def create_discriminator():\n",
    "    dis_ann = tf.keras.Sequential([\n",
    "        # Bild als Input. Netz soll Fake-Images erkennen. \n",
    "        tf.keras.layers.Flatten(input_shape=(20,20, 1)),\n",
    "        tf.keras.layers.Dense(350, activation='relu'),\n",
    "        tf.keras.layers.Dense(450, activation='relu'),\n",
    "        tf.keras.layers.Dense(200, activation='relu'),\n",
    "        # Als Output: Fake oder nicht.\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return dis_ann\n",
    "\n",
    "discriminator = create_discriminator()\n",
    "discriminator.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss      = 'binary_crossentropy',\n",
    "    metrics   = 'accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90306a96",
   "metadata": {},
   "source": [
    "Für einfache Formen sind die Netze ausreichend. Diese können später weiter optimiert werden.\n",
    "\n",
    "Der nächste wichtige Schritt ist das Netz zu trainieren. Dazu fügen wir beide Netze zusammen und trainieren vorerst nur den Generator. \n",
    "- Mit einem Parameter können die Weights eines Models eingefroren werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b4964736-9676-4e61-8d1d-12d3200e19a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ded1381b-ec02-42d8-8c0d-a718696c066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle GAN\n",
    "generator = create_generator()\n",
    "gan_input = tf.keras.layers.Input(shape=(100,))  # 100 Startpixel.\n",
    "gen_image = generator(gan_input)\n",
    "\n",
    "net_output = discriminator(gen_image)\n",
    "GAN        = tf.keras.Model(gan_input, net_output)\n",
    "\n",
    "GAN.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb7b76-ad18-4d07-acca-914f71fd6417",
   "metadata": {},
   "source": [
    "Anders als sonst in Tensorflow schreiben wir eine detailreiche Trainingsschleife. \n",
    "- Batching möglich.\n",
    "\n",
    "Später werden wir uns weitere Details anschauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27712e9b-aa21-472c-bf93-f20d9fb0a559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Für das Batching: # \n",
    "# - Random-Index mit:\n",
    "np.random.randint(0, 3, 3)  #  (low, high, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df2680a0-b806-4902-89d2-f76b72efa305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.39782962e-01, -3.10202128e-01,  1.65800969e+00,\n",
       "        -4.97675987e-01,  7.78550346e-01,  9.68748206e-01,\n",
       "        -3.04415937e-01, -1.89076281e-02, -3.73261651e-01,\n",
       "        -1.55525828e+00,  4.70532909e-01, -2.68442098e-01,\n",
       "        -1.15237504e+00, -9.63809818e-01, -1.48104211e-01,\n",
       "        -6.57777960e-02,  2.70712605e-02,  1.17791695e+00,\n",
       "         5.52461789e-01,  1.40414667e+00, -1.60979634e+00,\n",
       "         5.92170840e-01,  7.01905012e-01,  3.40010321e-01,\n",
       "        -6.62022982e-01,  1.40517590e+00, -7.16884546e-01,\n",
       "         1.49486669e+00, -1.70991389e-01,  5.32584580e-01,\n",
       "        -1.19370327e+00, -1.58983268e-01, -4.51101165e-01,\n",
       "        -4.53239770e-01,  1.61885635e-01, -1.50889754e+00,\n",
       "         3.99815155e-01,  1.85668892e+00, -2.36656145e-03,\n",
       "        -1.49685538e+00,  2.73424970e+00,  1.58790819e+00,\n",
       "        -9.51698690e-01, -1.02370542e+00, -6.01330298e-01,\n",
       "         3.47095996e-01,  1.06514052e+00, -1.82129192e+00,\n",
       "        -1.62315857e+00, -1.10836805e+00,  3.65105948e-01,\n",
       "        -1.65580833e+00,  9.70527651e-01, -1.42109158e+00,\n",
       "         4.26893489e-01,  5.15048873e-01,  1.99678915e-01,\n",
       "        -1.89662671e+00, -2.43110055e+00, -7.09174954e-01,\n",
       "         2.42780321e-01, -3.16882610e-01, -3.22476650e-01,\n",
       "        -5.74503843e-01, -9.09318497e-01, -3.36459511e-01,\n",
       "         1.07549768e+00, -2.03303585e+00, -8.05449264e-02,\n",
       "        -7.68992401e-01,  6.98442832e-02,  5.35634406e-01,\n",
       "         5.73389662e-01,  1.06873556e+00, -1.67317315e+00,\n",
       "         9.20891833e-01,  2.14963552e-01,  8.68800974e-01,\n",
       "         1.27901833e+00, -5.98611172e-02, -1.92970022e-01,\n",
       "         3.22698171e-01,  9.24731891e-01, -2.10417447e-01,\n",
       "         9.03481373e-01, -2.77285329e-01,  1.94739436e+00,\n",
       "        -1.29771856e+00,  7.04967495e-01, -6.62550371e-01,\n",
       "        -1.18324899e+00,  8.44586781e-01, -2.20748725e-01,\n",
       "        -4.71454432e-01,  1.57467369e-01, -4.07884123e-02,\n",
       "         6.02944987e-01, -1.62363087e+00, -1.38680913e+00,\n",
       "         2.76806775e+00],\n",
       "       [-1.45292525e+00, -3.39507900e-02,  6.79737009e-01,\n",
       "        -1.38931875e-01, -2.24041062e-01, -1.21580271e+00,\n",
       "         1.82789707e+00, -2.37639077e+00,  1.01074824e+00,\n",
       "        -1.45658021e+00,  9.13291427e-01, -4.21154408e-02,\n",
       "        -7.13763333e-01,  3.92767106e-01, -1.56946330e+00,\n",
       "         6.76323191e-01, -2.33751843e+00, -1.23529285e+00,\n",
       "        -2.76723745e-01, -9.50270176e-02, -3.21085244e-01,\n",
       "         4.47645275e-01,  1.12109965e+00,  1.57179856e+00,\n",
       "         4.63971280e-01,  1.30033846e+00, -7.67976480e-01,\n",
       "         7.32598519e-01, -1.26794935e+00,  2.39155025e+00,\n",
       "         4.01811670e-01, -9.52522167e-01, -7.72162684e-01,\n",
       "         4.27661658e-01, -1.08888886e+00, -4.20157096e-01,\n",
       "         4.59203560e-01, -3.44721751e-01,  1.96386750e+00,\n",
       "        -1.61340990e+00,  6.40123358e-01, -4.55898959e-01,\n",
       "        -1.19291293e+00,  1.54716688e+00,  7.49124601e-01,\n",
       "         1.26876476e-01,  1.21561587e+00, -4.75418351e-01,\n",
       "        -2.94905371e-01,  1.22774194e+00, -9.56640379e-02,\n",
       "        -3.08472538e-01,  3.42534251e-01, -9.35115950e-02,\n",
       "        -9.57929656e-01,  5.57636812e-01, -2.77897398e-01,\n",
       "         1.07891956e+00, -2.09651630e-01,  8.96333951e-01,\n",
       "         1.74612561e+00, -6.72143690e-01, -9.55794590e-01,\n",
       "         1.45595696e+00,  3.88214093e-01,  6.70713854e-01,\n",
       "        -9.97635070e-01,  4.48251980e-01,  2.12521641e+00,\n",
       "        -1.00833935e+00,  1.79509160e+00,  1.05868415e+00,\n",
       "        -1.11277214e+00,  5.94837927e-01, -6.13204506e-01,\n",
       "        -3.00734774e-01, -1.20130198e+00, -6.31409462e-01,\n",
       "         7.75579796e-01, -1.01829871e+00,  5.05807211e-01,\n",
       "         2.77019301e-01,  1.17978409e+00, -8.43800341e-01,\n",
       "        -6.17458718e-01,  1.89334230e+00, -1.02724537e+00,\n",
       "         2.25773418e-01, -6.87663591e-01,  1.35685834e+00,\n",
       "         1.93181201e+00,  9.50508233e-01, -1.28284954e+00,\n",
       "         2.47505719e+00, -4.34701463e-01,  3.59555983e-01,\n",
       "         7.75163800e-01,  1.47431257e+00, -4.93163145e-02,\n",
       "        -5.13494837e-01]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generator Input # \n",
    "# - Üblich: Rauschen. Kann aber alles sein... \n",
    "#   => Aus dem Rauschen soll ein Bild entstehen. \n",
    "np.random.normal(0, 1, (2, 100))  # (loc, scale, size(x-Samples, shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b96b8b9e-df98-4b24-bc34-ab6deab850a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8d44813c-48fb-4642-9e93-d09fe42e03f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsschleife # \n",
    "\n",
    "def train(generator, discriminator, gan, train_img, epochs, batch_size):\n",
    "    \n",
    "    half_batch = int(batch_size / 2)  # Ausgleich an Samples für beide Netze. \n",
    "    \n",
    "    for epoch in range(epochs):  # Für jede Epoche mach das:\n",
    "        # Discriminator # \n",
    "        index = np.random.randint(0, train_img.shape[0], half_batch)  # Index für Samples. \n",
    "        real_images = train_img[index]  # Hole Samples.\n",
    "        noise       = np.random.normal(0, 1, (half_batch, 100))  # Erstelle Rauschen als Input. Kann aber auch komplett 0 sein. Üblich: Rauschen.\n",
    "        fake_images = generator.predict(noise)  # Erstelle Prediction. \n",
    "\n",
    "        # Berechne Loss. # Setze Labels.\n",
    "        # - train_on_batch(x, y), beide müssen n-Samples haben. \n",
    "        loss_real = discriminator.train_on_batch(real_images, np.ones(  (half_batch, 1) ))  # Label 1 für n-Samples für echte Bilder. \n",
    "        loss_fake = discriminator.train_on_batch(fake_images, np.zeros( (half_batch, 1) ))  # Label 0 für n-Samples für UN-echte Bilder.\n",
    "        d_loss = 0.5 * np.add(loss_real, loss_fake)  # Schnitt der Beiden Losses. \n",
    "\n",
    "        # Generator # Wie Oben. \n",
    "        noise    = np.random.normal(0, 1, (batch_size, 100))\n",
    "        y        = np.ones(batch_size)\n",
    "        gan_loss = gan.train_on_batch(noise, y)\n",
    "\n",
    "        # Manuelle Ausgabe.:\n",
    "        print(f\"Epoche: {epoch + 1}/{epochs} GAN loss: {gan_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fcd9e492-63b5-4219-8f76-004d9353c9cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step\n",
      "Epoche: 1/700 GAN loss: 0.6848864555358887\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 2/700 GAN loss: 0.9235652685165405\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 3/700 GAN loss: 1.4462690353393555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 4/700 GAN loss: 2.27596116065979\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 5/700 GAN loss: 3.2589735984802246\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 6/700 GAN loss: 4.243983268737793\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 7/700 GAN loss: 5.2005934715271\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 8/700 GAN loss: 6.154271602630615\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 9/700 GAN loss: 6.726434707641602\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 10/700 GAN loss: 7.356412887573242\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 11/700 GAN loss: 7.763110160827637\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 12/700 GAN loss: 8.093952178955078\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 13/700 GAN loss: 8.403820991516113\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 14/700 GAN loss: 8.815652847290039\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 15/700 GAN loss: 9.330961227416992\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 16/700 GAN loss: 9.861953735351562\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 17/700 GAN loss: 10.452150344848633\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 18/700 GAN loss: 11.451362609863281\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 19/700 GAN loss: 12.147927284240723\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 20/700 GAN loss: 12.805093765258789\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 21/700 GAN loss: 13.786515235900879\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 22/700 GAN loss: 14.559585571289062\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 23/700 GAN loss: 14.957928657531738\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 24/700 GAN loss: 15.717094421386719\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 25/700 GAN loss: 16.335716247558594\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 26/700 GAN loss: 18.29189109802246\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 27/700 GAN loss: 17.007469177246094\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 28/700 GAN loss: 16.75322914123535\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 29/700 GAN loss: 16.929798126220703\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 30/700 GAN loss: 16.395408630371094\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 31/700 GAN loss: 16.411815643310547\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 32/700 GAN loss: 16.52595329284668\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 33/700 GAN loss: 17.525493621826172\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 34/700 GAN loss: 19.835674285888672\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 35/700 GAN loss: 17.221633911132812\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 36/700 GAN loss: 15.139193534851074\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 37/700 GAN loss: 13.715166091918945\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 38/700 GAN loss: 16.033906936645508\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 39/700 GAN loss: 19.387508392333984\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 40/700 GAN loss: 22.320592880249023\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 41/700 GAN loss: 24.808574676513672\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 42/700 GAN loss: 13.473068237304688\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 43/700 GAN loss: 11.673587799072266\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 44/700 GAN loss: 9.953415870666504\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 45/700 GAN loss: 12.396557807922363\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 46/700 GAN loss: 19.958776473999023\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 47/700 GAN loss: 29.732919692993164\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 48/700 GAN loss: 36.79058837890625\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 49/700 GAN loss: 28.64609718322754\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 50/700 GAN loss: 19.734970092773438\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 51/700 GAN loss: 14.712992668151855\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 52/700 GAN loss: 14.107247352600098\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 53/700 GAN loss: 15.938132286071777\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 54/700 GAN loss: 24.228260040283203\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 55/700 GAN loss: 13.825467109680176\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 56/700 GAN loss: 13.955058097839355\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 57/700 GAN loss: 12.33902359008789\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 58/700 GAN loss: 11.890623092651367\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 59/700 GAN loss: 14.238059997558594\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 60/700 GAN loss: 15.847075462341309\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 61/700 GAN loss: 27.617103576660156\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 62/700 GAN loss: 39.87827682495117\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 63/700 GAN loss: 44.14763259887695\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 64/700 GAN loss: 52.16448211669922\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 65/700 GAN loss: 51.91902160644531\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 66/700 GAN loss: 33.55675506591797\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 67/700 GAN loss: 18.461729049682617\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 68/700 GAN loss: 9.454638481140137\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 69/700 GAN loss: 6.6774091720581055\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 70/700 GAN loss: 7.074187278747559\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 71/700 GAN loss: 7.3665266036987305\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 72/700 GAN loss: 6.186069488525391\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 73/700 GAN loss: 8.26076889038086\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 74/700 GAN loss: 9.546489715576172\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 75/700 GAN loss: 13.490345001220703\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 76/700 GAN loss: 17.953857421875\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 77/700 GAN loss: 23.06615447998047\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 78/700 GAN loss: 15.808881759643555\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 79/700 GAN loss: 9.072612762451172\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 80/700 GAN loss: 8.614302635192871\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 81/700 GAN loss: 7.456640243530273\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 82/700 GAN loss: 6.917603492736816\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 83/700 GAN loss: 8.498662948608398\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 84/700 GAN loss: 8.20305061340332\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 85/700 GAN loss: 13.742181777954102\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 86/700 GAN loss: 17.337291717529297\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 87/700 GAN loss: 17.82362937927246\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 88/700 GAN loss: 8.962325096130371\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 89/700 GAN loss: 5.718550682067871\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 90/700 GAN loss: 5.511441230773926\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 91/700 GAN loss: 4.5987420082092285\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 92/700 GAN loss: 4.289431571960449\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 93/700 GAN loss: 4.154730319976807\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 94/700 GAN loss: 4.798032760620117\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 95/700 GAN loss: 6.004870414733887\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 96/700 GAN loss: 8.80510139465332\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 97/700 GAN loss: 12.172431945800781\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 98/700 GAN loss: 8.343605041503906\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 99/700 GAN loss: 5.943718910217285\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 100/700 GAN loss: 4.620296478271484\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 101/700 GAN loss: 4.308602333068848\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 102/700 GAN loss: 4.3958659172058105\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 103/700 GAN loss: 4.274954795837402\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 104/700 GAN loss: 5.498208999633789\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 105/700 GAN loss: 7.235762596130371\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 106/700 GAN loss: 5.93559455871582\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 107/700 GAN loss: 5.086176872253418\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 108/700 GAN loss: 4.700897216796875\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 109/700 GAN loss: 4.838034629821777\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 110/700 GAN loss: 5.657942771911621\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 111/700 GAN loss: 6.7685160636901855\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 112/700 GAN loss: 4.8478288650512695\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 113/700 GAN loss: 4.753075122833252\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 114/700 GAN loss: 5.227439880371094\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 115/700 GAN loss: 6.5481462478637695\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 116/700 GAN loss: 5.5216593742370605\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 117/700 GAN loss: 6.083105087280273\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 118/700 GAN loss: 6.545401573181152\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 119/700 GAN loss: 7.4122700691223145\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 120/700 GAN loss: 5.985316276550293\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 121/700 GAN loss: 6.351287841796875\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 122/700 GAN loss: 7.698529243469238\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 123/700 GAN loss: 9.587669372558594\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 124/700 GAN loss: 6.68502140045166\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 125/700 GAN loss: 5.502832412719727\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 126/700 GAN loss: 7.374368667602539\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 127/700 GAN loss: 10.05405044555664\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 128/700 GAN loss: 10.374885559082031\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 129/700 GAN loss: 8.649325370788574\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 130/700 GAN loss: 8.160274505615234\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 131/700 GAN loss: 8.178879737854004\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 132/700 GAN loss: 8.190349578857422\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 133/700 GAN loss: 6.924114227294922\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 134/700 GAN loss: 6.939800262451172\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 135/700 GAN loss: 7.533277988433838\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 136/700 GAN loss: 3.9919915199279785\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 137/700 GAN loss: 4.196048736572266\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 138/700 GAN loss: 4.3835649490356445\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 139/700 GAN loss: 8.115449905395508\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 140/700 GAN loss: 11.674382209777832\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 141/700 GAN loss: 5.679590702056885\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 142/700 GAN loss: 3.5728211402893066\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 143/700 GAN loss: 3.7092559337615967\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 144/700 GAN loss: 4.801525115966797\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 145/700 GAN loss: 8.816672325134277\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 146/700 GAN loss: 11.265199661254883\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 147/700 GAN loss: 11.144604682922363\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 148/700 GAN loss: 10.574520111083984\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 149/700 GAN loss: 8.855388641357422\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 150/700 GAN loss: 8.585959434509277\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 151/700 GAN loss: 8.386653900146484\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 152/700 GAN loss: 8.47491455078125\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 153/700 GAN loss: 8.72637939453125\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 154/700 GAN loss: 9.420341491699219\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 155/700 GAN loss: 9.570456504821777\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 156/700 GAN loss: 9.039734840393066\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 157/700 GAN loss: 7.1151442527771\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 158/700 GAN loss: 6.927902698516846\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 159/700 GAN loss: 6.272957801818848\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 160/700 GAN loss: 7.400373935699463\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 161/700 GAN loss: 7.595269203186035\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 162/700 GAN loss: 6.9689531326293945\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 163/700 GAN loss: 6.494719505310059\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 164/700 GAN loss: 6.298135757446289\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 165/700 GAN loss: 6.407501220703125\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 166/700 GAN loss: 6.829466819763184\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 167/700 GAN loss: 6.346194744110107\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 168/700 GAN loss: 5.993758678436279\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 169/700 GAN loss: 5.819904327392578\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 170/700 GAN loss: 5.923416614532471\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 171/700 GAN loss: 6.294100761413574\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 172/700 GAN loss: 6.128492832183838\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 173/700 GAN loss: 5.274738311767578\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 174/700 GAN loss: 6.0323052406311035\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 175/700 GAN loss: 6.329678535461426\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 176/700 GAN loss: 6.59760856628418\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 177/700 GAN loss: 5.6775031089782715\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 178/700 GAN loss: 5.976290702819824\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 179/700 GAN loss: 5.95972204208374\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 180/700 GAN loss: 6.022268772125244\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 181/700 GAN loss: 6.388745307922363\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 182/700 GAN loss: 6.092168807983398\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 183/700 GAN loss: 5.845605850219727\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 184/700 GAN loss: 5.915683269500732\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 185/700 GAN loss: 5.836647987365723\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 186/700 GAN loss: 6.384652137756348\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 187/700 GAN loss: 6.659918785095215\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 188/700 GAN loss: 6.666696071624756\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 189/700 GAN loss: 6.638806343078613\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 190/700 GAN loss: 6.516841888427734\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 191/700 GAN loss: 6.675111770629883\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 192/700 GAN loss: 6.899492263793945\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 193/700 GAN loss: 6.793239116668701\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 194/700 GAN loss: 6.631356239318848\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 195/700 GAN loss: 7.254270553588867\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 196/700 GAN loss: 7.200162887573242\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 197/700 GAN loss: 6.5318708419799805\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 198/700 GAN loss: 6.409685134887695\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 199/700 GAN loss: 6.327808856964111\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 200/700 GAN loss: 7.061127662658691\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 201/700 GAN loss: 6.007372856140137\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 202/700 GAN loss: 6.643689155578613\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 203/700 GAN loss: 7.2543721199035645\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 204/700 GAN loss: 6.04090690612793\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 205/700 GAN loss: 6.440610408782959\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 206/700 GAN loss: 7.555131912231445\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 207/700 GAN loss: 6.965683460235596\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 208/700 GAN loss: 6.362462043762207\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 209/700 GAN loss: 6.619128704071045\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 210/700 GAN loss: 7.0491766929626465\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 211/700 GAN loss: 6.460575103759766\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 212/700 GAN loss: 6.559420108795166\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 213/700 GAN loss: 7.771331787109375\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 214/700 GAN loss: 3.4721198081970215\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 215/700 GAN loss: 3.4758403301239014\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 216/700 GAN loss: 7.215496063232422\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 217/700 GAN loss: 12.547547340393066\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 218/700 GAN loss: 2.2628490924835205\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 219/700 GAN loss: 0.9914628267288208\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 220/700 GAN loss: 1.1834197044372559\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 221/700 GAN loss: 2.2951855659484863\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 222/700 GAN loss: 8.016702651977539\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 223/700 GAN loss: 14.690787315368652\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 224/700 GAN loss: 11.962201118469238\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 225/700 GAN loss: 9.832006454467773\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 226/700 GAN loss: 7.935732841491699\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 227/700 GAN loss: 7.85527229309082\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 228/700 GAN loss: 8.598930358886719\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 229/700 GAN loss: 8.806520462036133\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 230/700 GAN loss: 12.070486068725586\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 231/700 GAN loss: 14.234644889831543\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 232/700 GAN loss: 14.695340156555176\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 233/700 GAN loss: 12.848808288574219\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 234/700 GAN loss: 10.107580184936523\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 235/700 GAN loss: 7.857265472412109\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 236/700 GAN loss: 7.607516765594482\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 237/700 GAN loss: 6.351706504821777\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 238/700 GAN loss: 7.271566867828369\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 239/700 GAN loss: 8.131799697875977\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 240/700 GAN loss: 8.08652114868164\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 241/700 GAN loss: 6.141772270202637\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 242/700 GAN loss: 6.043698310852051\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 243/700 GAN loss: 6.867480278015137\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 244/700 GAN loss: 7.56334114074707\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 245/700 GAN loss: 4.335806846618652\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 246/700 GAN loss: 3.901892900466919\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 247/700 GAN loss: 6.154580116271973\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 248/700 GAN loss: 8.689573287963867\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 249/700 GAN loss: 3.061464548110962\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 250/700 GAN loss: 1.569135069847107\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 251/700 GAN loss: 3.6075572967529297\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 252/700 GAN loss: 10.17386245727539\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 253/700 GAN loss: 12.74525260925293\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 254/700 GAN loss: 3.5697407722473145\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 255/700 GAN loss: 1.3282124996185303\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 256/700 GAN loss: 1.6926970481872559\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 257/700 GAN loss: 6.080650329589844\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 258/700 GAN loss: 10.44565486907959\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 259/700 GAN loss: 9.469240188598633\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 260/700 GAN loss: 6.418617248535156\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 261/700 GAN loss: 4.942958354949951\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 262/700 GAN loss: 4.545916557312012\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 263/700 GAN loss: 4.169506072998047\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 264/700 GAN loss: 6.462635517120361\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 265/700 GAN loss: 7.377744197845459\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 266/700 GAN loss: 3.2811973094940186\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 267/700 GAN loss: 2.5598807334899902\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 268/700 GAN loss: 3.8213443756103516\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 269/700 GAN loss: 6.339676856994629\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 270/700 GAN loss: 2.370560884475708\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 271/700 GAN loss: 1.210496425628662\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 272/700 GAN loss: 2.9383623600006104\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 273/700 GAN loss: 5.910724639892578\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 274/700 GAN loss: 8.370157241821289\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 275/700 GAN loss: 3.129056692123413\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 276/700 GAN loss: 1.970184326171875\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 277/700 GAN loss: 2.027360677719116\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 278/700 GAN loss: 4.232169151306152\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 279/700 GAN loss: 7.312441825866699\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 280/700 GAN loss: 4.216395378112793\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 281/700 GAN loss: 2.6102395057678223\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 282/700 GAN loss: 2.971034526824951\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 283/700 GAN loss: 4.7522172927856445\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 284/700 GAN loss: 5.44746208190918\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 285/700 GAN loss: 2.6231069564819336\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 286/700 GAN loss: 2.6856977939605713\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 287/700 GAN loss: 4.530421257019043\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 288/700 GAN loss: 4.681040287017822\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 289/700 GAN loss: 2.132396936416626\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 290/700 GAN loss: 2.734372615814209\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 291/700 GAN loss: 6.239696502685547\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 292/700 GAN loss: 1.1310440301895142\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 293/700 GAN loss: 0.732447624206543\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 294/700 GAN loss: 2.971479892730713\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 295/700 GAN loss: 10.334095001220703\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 296/700 GAN loss: 2.870631217956543\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 297/700 GAN loss: 1.3085594177246094\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 298/700 GAN loss: 1.6597189903259277\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 299/700 GAN loss: 4.249872207641602\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 300/700 GAN loss: 8.646869659423828\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 301/700 GAN loss: 5.496110916137695\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 302/700 GAN loss: 2.8885037899017334\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 303/700 GAN loss: 2.3493549823760986\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 304/700 GAN loss: 2.4347879886627197\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 305/700 GAN loss: 3.8535776138305664\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 306/700 GAN loss: 4.7509284019470215\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 307/700 GAN loss: 3.797049045562744\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 308/700 GAN loss: 2.787632465362549\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 309/700 GAN loss: 2.356179714202881\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 310/700 GAN loss: 3.4208831787109375\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 311/700 GAN loss: 3.3537631034851074\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 312/700 GAN loss: 3.1921751499176025\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 313/700 GAN loss: 2.640072822570801\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 314/700 GAN loss: 2.970287322998047\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 315/700 GAN loss: 1.9931390285491943\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 316/700 GAN loss: 2.4223177433013916\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 317/700 GAN loss: 3.206310987472534\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 318/700 GAN loss: 1.9527535438537598\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 319/700 GAN loss: 2.4788060188293457\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 320/700 GAN loss: 4.4402618408203125\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 321/700 GAN loss: 2.059028148651123\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 322/700 GAN loss: 2.7381653785705566\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 323/700 GAN loss: 5.996251106262207\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 324/700 GAN loss: 1.338374137878418\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 325/700 GAN loss: 2.536661148071289\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 326/700 GAN loss: 8.517162322998047\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 327/700 GAN loss: 1.6385018825531006\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 328/700 GAN loss: 1.4419318437576294\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 329/700 GAN loss: 4.5751752853393555\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 330/700 GAN loss: 11.74276351928711\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 331/700 GAN loss: 2.6874876022338867\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 332/700 GAN loss: 1.103926658630371\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 333/700 GAN loss: 2.3252105712890625\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 334/700 GAN loss: 6.884838104248047\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 335/700 GAN loss: 10.502218246459961\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 336/700 GAN loss: 2.7470269203186035\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 337/700 GAN loss: 1.089829921722412\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 338/700 GAN loss: 2.152956962585449\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 339/700 GAN loss: 5.102973937988281\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 340/700 GAN loss: 8.399124145507812\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 341/700 GAN loss: 6.202235698699951\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 342/700 GAN loss: 3.6698291301727295\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 343/700 GAN loss: 2.264749050140381\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 344/700 GAN loss: 2.747666835784912\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 345/700 GAN loss: 3.8312480449676514\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 346/700 GAN loss: 5.119260787963867\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 347/700 GAN loss: 5.54817008972168\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 348/700 GAN loss: 3.7862777709960938\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 349/700 GAN loss: 3.0476417541503906\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 350/700 GAN loss: 2.9540576934814453\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 351/700 GAN loss: 3.8995606899261475\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 352/700 GAN loss: 3.9373233318328857\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 353/700 GAN loss: 2.6783218383789062\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 354/700 GAN loss: 3.0383853912353516\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 355/700 GAN loss: 3.833158493041992\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 356/700 GAN loss: 1.796386957168579\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 357/700 GAN loss: 3.3980612754821777\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 358/700 GAN loss: 3.5937724113464355\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 359/700 GAN loss: 2.3530211448669434\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 360/700 GAN loss: 3.4736199378967285\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 361/700 GAN loss: 2.161391258239746\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 362/700 GAN loss: 3.83772611618042\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 363/700 GAN loss: 2.3320319652557373\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 364/700 GAN loss: 3.36818265914917\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 365/700 GAN loss: 3.2039265632629395\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 366/700 GAN loss: 2.6178760528564453\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 367/700 GAN loss: 3.182424545288086\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 368/700 GAN loss: 2.8436121940612793\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 369/700 GAN loss: 3.9772212505340576\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 370/700 GAN loss: 2.8394622802734375\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 371/700 GAN loss: 3.33423113822937\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 372/700 GAN loss: 3.3736648559570312\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 373/700 GAN loss: 2.8029322624206543\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 374/700 GAN loss: 2.801701068878174\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 375/700 GAN loss: 2.577789545059204\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 376/700 GAN loss: 2.506560802459717\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 377/700 GAN loss: 3.7886874675750732\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 378/700 GAN loss: 2.1882553100585938\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 379/700 GAN loss: 2.9880928993225098\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 380/700 GAN loss: 3.397023916244507\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 381/700 GAN loss: 2.8368735313415527\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 382/700 GAN loss: 3.852414131164551\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 383/700 GAN loss: 2.420466423034668\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 384/700 GAN loss: 3.9729421138763428\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 385/700 GAN loss: 3.259706974029541\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 386/700 GAN loss: 3.895991325378418\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 387/700 GAN loss: 4.262989521026611\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 388/700 GAN loss: 3.8906848430633545\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 389/700 GAN loss: 4.591060161590576\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 390/700 GAN loss: 3.8151512145996094\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 391/700 GAN loss: 4.634757041931152\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 392/700 GAN loss: 2.7264254093170166\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 393/700 GAN loss: 4.392443656921387\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 394/700 GAN loss: 3.38871431350708\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 395/700 GAN loss: 3.59633731842041\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 396/700 GAN loss: 3.8699591159820557\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 397/700 GAN loss: 3.4948995113372803\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 398/700 GAN loss: 4.771611213684082\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 399/700 GAN loss: 3.937300682067871\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 400/700 GAN loss: 4.912715435028076\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 401/700 GAN loss: 2.485581874847412\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 402/700 GAN loss: 5.964143753051758\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 403/700 GAN loss: 1.9162366390228271\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 404/700 GAN loss: 3.233776569366455\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 405/700 GAN loss: 6.374483108520508\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 406/700 GAN loss: 0.9792425632476807\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 407/700 GAN loss: 0.9275796413421631\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 408/700 GAN loss: 2.3941450119018555\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 409/700 GAN loss: 6.100395202636719\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 410/700 GAN loss: 2.376094341278076\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 411/700 GAN loss: 1.1011143922805786\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 412/700 GAN loss: 1.068263292312622\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 413/700 GAN loss: 2.313199043273926\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 414/700 GAN loss: 2.4817311763763428\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 415/700 GAN loss: 1.4063466787338257\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 416/700 GAN loss: 1.0542199611663818\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 417/700 GAN loss: 1.3468972444534302\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 418/700 GAN loss: 2.250932216644287\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 419/700 GAN loss: 2.6519594192504883\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 420/700 GAN loss: 1.7216166257858276\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 421/700 GAN loss: 1.364999771118164\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 422/700 GAN loss: 1.6502054929733276\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 423/700 GAN loss: 2.2597639560699463\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 424/700 GAN loss: 2.528271436691284\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 425/700 GAN loss: 1.9226394891738892\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 426/700 GAN loss: 1.9071877002716064\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 427/700 GAN loss: 2.2448158264160156\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 428/700 GAN loss: 2.3082573413848877\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 429/700 GAN loss: 2.085275650024414\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 430/700 GAN loss: 2.1455085277557373\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 431/700 GAN loss: 2.0529417991638184\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 432/700 GAN loss: 2.1967949867248535\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 433/700 GAN loss: 2.38731050491333\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 434/700 GAN loss: 2.3560948371887207\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 435/700 GAN loss: 2.0417888164520264\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 436/700 GAN loss: 2.059971332550049\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 437/700 GAN loss: 2.415910482406616\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 438/700 GAN loss: 2.2003164291381836\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 439/700 GAN loss: 2.052389621734619\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 440/700 GAN loss: 2.1513993740081787\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 441/700 GAN loss: 2.1620864868164062\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 442/700 GAN loss: 2.1764698028564453\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 443/700 GAN loss: 2.390766143798828\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 444/700 GAN loss: 2.351170063018799\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 445/700 GAN loss: 1.948186993598938\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 446/700 GAN loss: 1.9130444526672363\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 447/700 GAN loss: 3.020575523376465\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 448/700 GAN loss: 2.173522710800171\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 449/700 GAN loss: 1.866520881652832\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 450/700 GAN loss: 2.2151219844818115\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 451/700 GAN loss: 2.7092175483703613\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 452/700 GAN loss: 1.8113529682159424\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 453/700 GAN loss: 2.009462833404541\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 454/700 GAN loss: 2.6471118927001953\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 455/700 GAN loss: 1.5950860977172852\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 456/700 GAN loss: 2.2094600200653076\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 457/700 GAN loss: 2.593031883239746\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 458/700 GAN loss: 1.759778618812561\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 459/700 GAN loss: 2.1089110374450684\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 460/700 GAN loss: 2.5136098861694336\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 461/700 GAN loss: 1.5128201246261597\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 462/700 GAN loss: 2.1157190799713135\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 463/700 GAN loss: 2.849817991256714\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 464/700 GAN loss: 1.6097745895385742\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 465/700 GAN loss: 2.2744884490966797\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 466/700 GAN loss: 2.3919737339019775\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 467/700 GAN loss: 2.0861291885375977\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 468/700 GAN loss: 2.538917064666748\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 469/700 GAN loss: 1.7452348470687866\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 470/700 GAN loss: 1.9938760995864868\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 471/700 GAN loss: 2.203097343444824\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 472/700 GAN loss: 2.1959028244018555\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 473/700 GAN loss: 2.5207979679107666\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 474/700 GAN loss: 2.0356674194335938\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 475/700 GAN loss: 2.7080962657928467\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 476/700 GAN loss: 2.0421454906463623\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 477/700 GAN loss: 2.637171506881714\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 478/700 GAN loss: 2.706908702850342\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 479/700 GAN loss: 2.3152832984924316\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 480/700 GAN loss: 2.3631839752197266\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 481/700 GAN loss: 2.6540284156799316\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 482/700 GAN loss: 1.9935100078582764\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 483/700 GAN loss: 2.4610610008239746\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 484/700 GAN loss: 2.1284093856811523\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 485/700 GAN loss: 2.067319393157959\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 486/700 GAN loss: 2.0311126708984375\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 487/700 GAN loss: 2.065181255340576\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 488/700 GAN loss: 2.068347692489624\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 489/700 GAN loss: 2.007742166519165\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 490/700 GAN loss: 2.040405511856079\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 491/700 GAN loss: 2.2712242603302\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 492/700 GAN loss: 2.1034317016601562\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 493/700 GAN loss: 2.0683815479278564\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 494/700 GAN loss: 1.7593705654144287\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 495/700 GAN loss: 1.82053804397583\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 496/700 GAN loss: 1.744517207145691\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 497/700 GAN loss: 1.7524687051773071\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 498/700 GAN loss: 1.9632679224014282\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 499/700 GAN loss: 1.4984755516052246\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 500/700 GAN loss: 1.5353924036026\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 501/700 GAN loss: 2.643234968185425\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 502/700 GAN loss: 1.2440452575683594\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 503/700 GAN loss: 2.2298243045806885\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 504/700 GAN loss: 1.613105297088623\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 505/700 GAN loss: 1.1803045272827148\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 506/700 GAN loss: 1.6956106424331665\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 507/700 GAN loss: 1.9515607357025146\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 508/700 GAN loss: 1.2564274072647095\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 509/700 GAN loss: 1.7793364524841309\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 510/700 GAN loss: 2.4807071685791016\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 511/700 GAN loss: 1.5770756006240845\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 512/700 GAN loss: 2.019184112548828\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 513/700 GAN loss: 2.366591453552246\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 514/700 GAN loss: 1.676119089126587\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 515/700 GAN loss: 1.5244953632354736\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 516/700 GAN loss: 2.0192031860351562\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 517/700 GAN loss: 1.5672255754470825\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 518/700 GAN loss: 1.7171509265899658\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 519/700 GAN loss: 1.607839584350586\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 520/700 GAN loss: 1.7629003524780273\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 521/700 GAN loss: 1.4910203218460083\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 522/700 GAN loss: 1.902326226234436\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 523/700 GAN loss: 1.8021756410598755\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 524/700 GAN loss: 1.6298084259033203\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 525/700 GAN loss: 1.7430665493011475\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 526/700 GAN loss: 1.972074270248413\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 527/700 GAN loss: 1.9841563701629639\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 528/700 GAN loss: 1.9671472311019897\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 529/700 GAN loss: 1.9026250839233398\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 530/700 GAN loss: 2.3533949851989746\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 531/700 GAN loss: 1.4665297269821167\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 532/700 GAN loss: 1.313744068145752\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 533/700 GAN loss: 1.6238971948623657\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 534/700 GAN loss: 1.3893024921417236\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 535/700 GAN loss: 1.668742299079895\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 536/700 GAN loss: 1.855509638786316\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 537/700 GAN loss: 1.7176308631896973\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 538/700 GAN loss: 1.7944862842559814\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 539/700 GAN loss: 1.7093498706817627\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 540/700 GAN loss: 1.797994613647461\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 541/700 GAN loss: 1.4755403995513916\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 542/700 GAN loss: 1.9127689599990845\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 543/700 GAN loss: 1.7625455856323242\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 544/700 GAN loss: 1.635810375213623\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 545/700 GAN loss: 1.6845965385437012\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 546/700 GAN loss: 1.8345918655395508\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 547/700 GAN loss: 1.8096784353256226\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 548/700 GAN loss: 1.5399340391159058\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 549/700 GAN loss: 1.272071361541748\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 550/700 GAN loss: 1.860695719718933\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 551/700 GAN loss: 1.9273602962493896\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 552/700 GAN loss: 1.406595230102539\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 553/700 GAN loss: 1.6814498901367188\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 554/700 GAN loss: 1.8476369380950928\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 555/700 GAN loss: 1.4612798690795898\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 556/700 GAN loss: 2.034381866455078\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 557/700 GAN loss: 1.2830630540847778\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 558/700 GAN loss: 1.355177640914917\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 559/700 GAN loss: 1.7774856090545654\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 560/700 GAN loss: 0.8198575377464294\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 561/700 GAN loss: 1.434277057647705\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 562/700 GAN loss: 1.8443138599395752\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 563/700 GAN loss: 1.014073371887207\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 564/700 GAN loss: 1.3502347469329834\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 565/700 GAN loss: 1.524772047996521\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 566/700 GAN loss: 1.2767727375030518\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 567/700 GAN loss: 1.264995813369751\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 568/700 GAN loss: 1.4832409620285034\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 569/700 GAN loss: 1.426401972770691\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 570/700 GAN loss: 1.109987735748291\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 571/700 GAN loss: 1.5570423603057861\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 572/700 GAN loss: 1.2424532175064087\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 573/700 GAN loss: 1.1840183734893799\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 574/700 GAN loss: 1.5303785800933838\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 575/700 GAN loss: 1.3596711158752441\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 576/700 GAN loss: 0.9813545942306519\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 577/700 GAN loss: 1.307197093963623\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 578/700 GAN loss: 1.4440945386886597\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 579/700 GAN loss: 1.3256454467773438\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 580/700 GAN loss: 1.0088155269622803\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 581/700 GAN loss: 1.4270612001419067\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 582/700 GAN loss: 1.3736658096313477\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 583/700 GAN loss: 1.366044521331787\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 584/700 GAN loss: 1.1555535793304443\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 585/700 GAN loss: 1.3270678520202637\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 586/700 GAN loss: 1.7274112701416016\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 587/700 GAN loss: 1.290618896484375\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 588/700 GAN loss: 1.2801172733306885\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 589/700 GAN loss: 1.7339422702789307\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 590/700 GAN loss: 1.5315439701080322\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 591/700 GAN loss: 1.2548675537109375\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 592/700 GAN loss: 1.3207674026489258\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 593/700 GAN loss: 1.4021987915039062\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 594/700 GAN loss: 1.579996109008789\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 595/700 GAN loss: 0.9912340641021729\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 596/700 GAN loss: 1.1867766380310059\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 597/700 GAN loss: 1.2648189067840576\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 598/700 GAN loss: 1.2538294792175293\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 599/700 GAN loss: 1.1744557619094849\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 600/700 GAN loss: 1.319286584854126\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 601/700 GAN loss: 1.360168695449829\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 602/700 GAN loss: 1.219531774520874\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 603/700 GAN loss: 1.2125791311264038\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 604/700 GAN loss: 1.2547178268432617\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 605/700 GAN loss: 1.1925251483917236\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 606/700 GAN loss: 1.3325974941253662\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 607/700 GAN loss: 1.2962148189544678\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 608/700 GAN loss: 1.2666294574737549\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 609/700 GAN loss: 1.2084333896636963\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 610/700 GAN loss: 1.3261927366256714\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 611/700 GAN loss: 1.3176686763763428\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 612/700 GAN loss: 1.2737617492675781\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 613/700 GAN loss: 1.2752677202224731\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 614/700 GAN loss: 1.0957380533218384\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 615/700 GAN loss: 1.2189998626708984\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 616/700 GAN loss: 1.281294584274292\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 617/700 GAN loss: 1.30625581741333\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 618/700 GAN loss: 1.1621249914169312\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 619/700 GAN loss: 1.1685305833816528\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 620/700 GAN loss: 1.356693983078003\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 621/700 GAN loss: 1.3990670442581177\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 622/700 GAN loss: 1.1314876079559326\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 623/700 GAN loss: 1.0630154609680176\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 624/700 GAN loss: 1.216726303100586\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 625/700 GAN loss: 1.3435423374176025\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 626/700 GAN loss: 1.114119529724121\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 627/700 GAN loss: 1.074363112449646\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 628/700 GAN loss: 1.4130055904388428\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 629/700 GAN loss: 1.2161449193954468\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 630/700 GAN loss: 1.114654779434204\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 631/700 GAN loss: 0.9970493316650391\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 632/700 GAN loss: 0.9891215562820435\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 633/700 GAN loss: 1.304286003112793\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 634/700 GAN loss: 1.1266300678253174\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 635/700 GAN loss: 1.094555139541626\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 636/700 GAN loss: 0.9978208541870117\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 637/700 GAN loss: 1.0922932624816895\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 638/700 GAN loss: 1.07177734375\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 639/700 GAN loss: 1.0733342170715332\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 640/700 GAN loss: 1.0312360525131226\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 641/700 GAN loss: 1.1730308532714844\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 642/700 GAN loss: 1.1225717067718506\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 643/700 GAN loss: 0.8907936811447144\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 644/700 GAN loss: 0.9866222143173218\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 645/700 GAN loss: 1.2296687364578247\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 646/700 GAN loss: 1.1698658466339111\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 647/700 GAN loss: 1.1152185201644897\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 648/700 GAN loss: 0.9853749871253967\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 649/700 GAN loss: 1.1269962787628174\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 650/700 GAN loss: 1.1906476020812988\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 651/700 GAN loss: 1.1238781213760376\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 652/700 GAN loss: 1.0692154169082642\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 653/700 GAN loss: 1.0266485214233398\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 654/700 GAN loss: 1.0637001991271973\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 655/700 GAN loss: 1.149730920791626\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 656/700 GAN loss: 1.1723135709762573\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 657/700 GAN loss: 1.0878217220306396\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 658/700 GAN loss: 1.1727430820465088\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 659/700 GAN loss: 1.2142398357391357\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 660/700 GAN loss: 1.047467589378357\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 661/700 GAN loss: 1.0314350128173828\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 662/700 GAN loss: 1.0197482109069824\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 663/700 GAN loss: 1.0283043384552002\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 664/700 GAN loss: 1.024774432182312\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 665/700 GAN loss: 1.1246678829193115\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 666/700 GAN loss: 1.2213294506072998\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 667/700 GAN loss: 1.0531810522079468\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 668/700 GAN loss: 0.9138335585594177\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 669/700 GAN loss: 1.022580623626709\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 670/700 GAN loss: 1.0225000381469727\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 671/700 GAN loss: 1.0232328176498413\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 672/700 GAN loss: 0.9730175733566284\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 673/700 GAN loss: 0.928516149520874\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 674/700 GAN loss: 1.101367473602295\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 675/700 GAN loss: 1.2491792440414429\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 676/700 GAN loss: 1.1085600852966309\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 677/700 GAN loss: 1.0024185180664062\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 678/700 GAN loss: 1.0200159549713135\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoche: 679/700 GAN loss: 1.020415186882019\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 680/700 GAN loss: 1.0663822889328003\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 681/700 GAN loss: 1.100595235824585\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 682/700 GAN loss: 1.0909748077392578\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 683/700 GAN loss: 1.0140128135681152\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 684/700 GAN loss: 1.0974828004837036\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 685/700 GAN loss: 1.170570731163025\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 686/700 GAN loss: 1.026465654373169\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 687/700 GAN loss: 0.9507436156272888\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 688/700 GAN loss: 1.0303163528442383\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 689/700 GAN loss: 0.9170137643814087\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 690/700 GAN loss: 1.0134572982788086\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 691/700 GAN loss: 1.0666933059692383\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 692/700 GAN loss: 1.074371099472046\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 693/700 GAN loss: 0.9474228620529175\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 694/700 GAN loss: 0.8577420711517334\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 695/700 GAN loss: 0.8306000828742981\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 696/700 GAN loss: 1.022403597831726\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 697/700 GAN loss: 1.008824348449707\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 698/700 GAN loss: 0.93144291639328\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 699/700 GAN loss: 0.7910913228988647\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 700/700 GAN loss: 0.9519736766815186\n"
     ]
    }
   ],
   "source": [
    "train(generator, discriminator, GAN, dataset_numpy_scaled, epochs=700, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0059ec67-69b1-4b32-968b-57fedae897bd",
   "metadata": {},
   "source": [
    "<h2>Erzeuge Bilder</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7a6ef3-a782-4b8a-ab54-57e78d1a4206",
   "metadata": {},
   "source": [
    "So, das Training ist beendet, wie können wir aber jetzt Bilder erzeugen? <br>\n",
    "Dazu geben wir dem Generator ein Startbild als Vektor, daraus soll dann Schritt für Schritt das Bild erzeugt werden. Später muss der Vektor durch das Netz oder Manuell in  die richtige Form gebracht werden.\n",
    "- Die Skalierung des Bildes sollte vor dem Plotten umgekehrt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8629f730-0ab8-4acb-a709-fc2f2ef9f96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeuge Bild und gebe als array zurück.\n",
    "def generate_img(noise, generator) -> np.array:\n",
    "    image = generator.predict(noise)  # Gebe Startbild => Netz => Prediction \n",
    "    image = 0.5 * image + 0.5  # Kehre die Skalierung um. \n",
    "    image = image.reshape((20,20,1))\n",
    "    return image\n",
    "\n",
    "# Plote Bild. \n",
    "def plot_image(img:np.array, gray=False):\n",
    "    plt.figure(figsize=(3,3))\n",
    "    if gray:\n",
    "        plt.imshow(img,  cmap='gray')\n",
    "    else:\n",
    "         plt.imshow(img)\n",
    "    plt.xlabel('X-Pixel')\n",
    "    plt.ylabel(\"Y-Pixel\")\n",
    "    plt.title(\"Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9f3c6ad1-1c3d-49b4-8838-23503a54e99d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Startbild.\n",
    "start_img = np.random.normal(0, 1, (1, 100)).reshape((10,10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "72918f47-d98a-4450-a7dd-d263e98caf2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Oder als schwarz/weiß.\n",
    "plot_image(start_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ed044e6e-bf77-469b-8b93-d3d575d0cf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_img_2 = np.random.normal(0, 0, (1, 100)).reshape((10,10, 1))\n",
    "plot_image(start_img_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cd0dc427-3b37-4dfe-bad8-ac6fe14f47a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATcAAAE8CAYAAACl5fbxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvV0lEQVR4nO3de1xUdf4/8NcMyKBcBo274l3xCiqupOmqQcKUptnXjHUTzcx1szLWLCvFS1/JLLUN0t1SyZ+a2q6LlX0xxdsaqKFS6pYBIXgBDBRGUG4z5/dH6+TExc9HwRmOr+fjcR4P5sz7fOZzGHl55sz5nI9GURQFREQqo7V1B4iImgLDjYhUieFGRKrEcCMiVWK4EZEqMdyISJUYbkSkSgw3IlIlhhsRqRLDjYhUieFGNpeYmAiNRoP09HRbd4VUhOFGRKrEcCMiVWK4kd2ZMmUKXF1dkZeXh9GjR8PV1RVt27ZFQkICAODkyZN48MEH4eLigg4dOmDz5s1W21++fBlz5sxB37594erqCnd3dxgMBnz77be1Xis3NxePPvooXFxc4O3tjZdeegm7du2CRqPB/v37rWqPHDmCyMhI6PV6tGrVCsOHD8fXX3/dZL8HujMMN7JLJpMJBoMBAQEBePvtt9GxY0fMmjULiYmJiIyMxMCBA7Fs2TK4ublh8uTJyMnJsWz7008/ISkpCaNHj8aKFSvw8ssv4+TJkxg+fDguXrxoqSsvL8eDDz6IPXv24IUXXsDrr7+O1NRUvPLKK7X6s3fvXvz+97+H0WhEbGwsli5dipKSEjz44IM4evToXfmdkCSFyMbWr1+vAFC++eYbRVEUJTo6WgGgLF261FJz5coVpWXLlopGo1G2bNliWf/DDz8oAJTY2FjLuoqKCsVkMlm9Rk5OjqLT6ZTFixdb1r377rsKACUpKcmy7vr160qPHj0UAMq+ffsURVEUs9msdOvWTYmIiFDMZrOl9tq1a0qnTp2Uhx56qFF+D9S4eORGduuZZ56x/Ozh4YHAwEC4uLjgiSeesKwPDAyEh4cHfvrpJ8s6nU4HrfaXf9omkwnFxcVwdXVFYGAgjh8/bqlLTk5G27Zt8eijj1rWOTs7Y/r06Vb9yMjIQGZmJv7whz+guLgYRUVFKCoqQnl5OcLCwnDw4EGYzeZG33+6M4627gBRXZydneHl5WW1Tq/Xo127dtBoNLXWX7lyxfLYbDbjvffewwcffICcnByYTCbLc/fdd5/l59zcXHTp0qVWe127drV6nJmZCQCIjo6ut7+lpaVo3bq14N7R3cBwI7vk4OAgtV656W75S5cuxfz58/H0009jyZIlaNOmDbRaLWbPnn1bR1g3tlm+fDn69etXZ42rq6t0u9S0GG6kOv/4xz8wcuRIrF271mp9SUkJPD09LY87dOiA//znP1AUxeroLSsry2q7Ll26AADc3d0RHh7ehD2nxsRzbqQ6Dg4OVkdyAPDpp5/iwoULVusiIiJw4cIFfPbZZ5Z1FRUV+PDDD63qQkJC0KVLF7zzzjsoKyur9Xo///xzI/aeGguP3Eh1Ro8ejcWLF2Pq1KkYMmQITp48iU2bNqFz585WdTNmzEB8fDyioqLw4osvws/PD5s2bYKzszMAWI7mtFotPvroIxgMBvTu3RtTp05F27ZtceHCBezbtw/u7u74/PPP7/p+UsMYbqQ6r732GsrLy7F582Zs3boVAwYMwM6dO/Hqq69a1bm6umLv3r14/vnn8d5778HV1RWTJ0/GkCFD8Pjjj1tCDgBGjBiBtLQ0LFmyBPHx8SgrK4Ovry9CQ0MxY8aMu72LJECj/Pb4neget2rVKrz00ks4f/482rZta+vu0G1iuNE97fr162jZsqXlcUVFBfr37w+TyYQff/zRhj2jO8WPpXRPGz9+PNq3b49+/fqhtLQUGzduxA8//IBNmzbZumt0hxhudE+LiIjARx99hE2bNsFkMqFXr17YsmULJk6caOuu0R3ix1IiUiVe50ZEqsRwIyJV4jm3OpjNZly8eBFubm61BlUTke0oioKrV6/C39/fcueX+jDc6nDx4kUEBATYuhtEVI9z586hXbt2DdYw3Org5uYGABiKh+GIFo3/Atq672xRH2VgT/Gmj/8g1bbGSXz/NDddsS/C3NFXoiNyR8ja3EvCtabiYqm2ldA+cn1J/168uG83ubZzC8SL/59Oqm38ReJOJkUlUk0rvm2Ea2vcxPtdU1OJ1G+WW/5GG9Iswi0hIQHLly9HQUEBgoOD8f7772PQoEH11n/66aeYP38+zp49i27dumHZsmV4+OGHhV/vxkdRR7SAo6YJwk0jGW6O4qGileyvRuMkXqsVrwUAs4NEGMqGm0RfNJK/E5nfNyD5O3eQCyCZ/YSLZLjJ9EXyvVdk2pb8fQMQOl1k918obN26FTExMYiNjcXx48cRHByMiIgIXLpU9//cqampiIqKwrRp03DixAmMGzcO48aNw6lTp+5yz4nIluw+3FasWIHp06dj6tSp6NWrF9asWYNWrVph3bp1dda/9957iIyMxMsvv4yePXtiyZIlGDBgAOLj4+t9jcrKShiNRquFiJo3uw63qqoqHDt2zOoGgVqtFuHh4UhLS6tzm7S0tFo3FIyIiKi3HgDi4uKg1+stC79MIGr+7DrcioqKYDKZ4OPjY7Xex8cHBQV1n2gtKCiQqgeAefPmobS01LKcO3fuzjtPRDbVLL5QaGo6nQ46neTJWCKya3Z95Obp6QkHBwcUFhZarS8sLISvb92XGfj6+krVE5E62XW4OTk5ISQkBCkpKZZ1ZrMZKSkpGDx4cJ3bDB482KoeAHbv3l1vPRGpk91/LI2JiUF0dDQGDhyIQYMGYdWqVSgvL8fUqVMBAJMnT0bbtm0RFxcHAHjxxRcxfPhwvPvuu3jkkUewZcsWpKen4+9//7std4OI7jK7D7eJEyfi559/xoIFC1BQUIB+/fohOTnZ8qVBXl6e1RizIUOGYPPmzXjjjTfw2muvoVu3bkhKSkKfPnJXnRNR88b7udXBaDRCr9cj7L6pcBS9MrueyYLrkjW7i1R/uq05L1xrvlwi1bb56lXhWscOcpfIFA8Tn3/gyphrUm13jDotXmw23brmDpiH9xeuLfOX++LK/ZPDwrUOgV2l2oZWfFSIOStXqmmlplq4dlPeIeHaq1fN6NqzEKWlpXB3d2+w1q7PuRER3S6GGxGpEsONiFSJ4UZEqsRwIyJVYrgRkSox3IhIlRhuRKRKDDciUiWGGxGpEodf1eHG8KsRGCs8QUx1eIhw+04llVL90Z6TmOmpULwWALQSM1qZKyqk2v5QYliN7DQ860vEf98HgltJtX32zful6jvOPypcq5WYbQwAlJoaqXoZ/zgr/v4MWREj1bbfyvrvfF2LRATVKNXYjx0cfkVE9y6GGxGpEsONiFSJ4UZEqsRwIyJVYrgRkSrZdbjFxcXhd7/7Hdzc3ODt7Y1x48bhzJkzDW6TmJgIjUZjtThLXO5AROpg1+F24MABPPfcczh8+DB2796N6upqjBo1CuXl5Q1u5+7ujvz8fMuSmyt3i2Qiav7seoKY5ORkq8eJiYnw9vbGsWPH8Pvf/77e7TQaDecpJbrH2fWR22+VlpYCANq0adNgXVlZGTp06ICAgACMHTsWp083PJlIZWUljEaj1UJEzVuzCTez2YzZs2fjgQceaHCavsDAQKxbtw47duzAxo0bYTabMWTIEJw/X/8MUnFxcdDr9ZYlIEBulicisj/NZmzpzJkz8X//9384dOgQ2rVrJ7xddXU1evbsiaioKCxZsqTOmsrKSlRW/jre02g0IiAgAMPvfwOOjmJfRmjTvxfuk8ZJcLrA/1KuXxcvDg6Ualt7Nl+41txZfKo+ACjq5ypcO/xPR6TaPhViFi/WiE9hBwBandz0e2ghPl50xvETUk0HOF4Wrn1xzvNSbbtsFx8TK0sb1EO41hioF66tqa5A+vY3hMaW2vU5txtmzZqFL774AgcPHpQKNgBo0aIF+vfvj6ysrHprdDoddLL/oInIrtn1x1JFUTBr1iz861//wt69e9GpUyfpNkwmE06ePAk/P78m6CER2Su7PnJ77rnnsHnzZuzYsQNubm4oKCgAAOj1erRs2RIAMHnyZLRt2xZxcXEAgMWLF+P+++9H165dUVJSguXLlyM3NxfPPPOMzfaDiO4+uw631atXAwBGjBhhtX79+vWYMmUKACAvLw9a7a8HoFeuXMH06dNRUFCA1q1bIyQkBKmpqejVq9fd6jYR2QG7DjeR7zr2799v9XjlypVYuXJlE/WIiJoLuz7nRkR0uxhuRKRKDDciUiWGGxGpEsONiFSp2Qy/uptuZ2o/jaP4F8+hxySGUwE4HCw78Z0EiaFJ3Y7KDRuLbys+pGpq3jCptgufFr8oW1NaJtV2UVgHqXp95jXh2gofuZEwLrsbvunDzcy3uBXYndC6uEjVy0xJqFRVCdfWKNXYryRxaj8iuncx3IhIlRhuRKRKDDciUiWGGxGpEsONiFSJ4UZEqsRwIyJVYrgRkSox3IhIlRhuRKRKHFtahxtjS8M8p8FRKzae0vTzz8LtO3h5yXXopmkHb9mPMrnxhQ5dOwrXKq3kxkU+tPGwcO1U/SmptqM6jxCuVWqqpdqG7J+ExPhcjaPkOGFFfApDTe9uck23cBAv/vZHqba1ruJjUacdOSZce+2qCVMGfNv8x5YuXLgQGo3GaunRo+H5ED/99FP06NEDzs7O6Nu3L7788su71Fsisid2HW4A0Lt3b+Tn51uWQ4cO1VubmpqKqKgoTJs2DSdOnMC4ceMwbtw4nDold1RARM2f3Yebo6MjfH19LYunp2e9te+99x4iIyPx8ssvo2fPnliyZAkGDBiA+Pj4u9hjIrIHdh9umZmZ8Pf3R+fOnTFp0iTk5eXVW5uWlobw8HCrdREREUhLS2vwNSorK2E0Gq0WImre7DrcQkNDkZiYiOTkZKxevRo5OTkYNmwYrl69Wmd9QUEBfHx8rNb5+PhYJnOuT1xcHPR6vWUJCAhotH0gItuw63AzGAyYMGECgoKCEBERgS+//BIlJSXYtm1bo77OvHnzUFpaalnOnTvXqO0T0d1n15My/5aHhwe6d++OrKysOp/39fVFYWGh1brCwkL4+vo22K5Op4NOJ3eZAxHZN7s+cvutsrIyZGdnw8+v7vvnDx48GCkpKVbrdu/ejcGDB9+N7hGRHbHrcJszZw4OHDiAs2fPIjU1FY899hgcHBwQFRUFAJg8eTLmzZtnqX/xxReRnJyMd999Fz/88AMWLlyI9PR0zJo1y1a7QEQ2YtcfS8+fP4+oqCgUFxfDy8sLQ4cOxeHDh+H13yv88/LyoNX+ms9DhgzB5s2b8cYbb+C1115Dt27dkJSUhD59+thqF4jIRjj8qg6W4Veto+GoERt+VTmgs3D7LQ6elOqPYjKJF5slagE4dhD/ZvhM3H1SbWeNSBSuLTXLTXf4ZM9RwrXmcvGp937ZQO53CK34MCbzkL5STTscFr8AXWZ6SQDIea2/cO2Rp1dItb31ahfh2n/2Fp+msUapxn7z9uY//IqI6HYx3IhIlRhuRKRKDDciUiWGGxGpEsONiFSJ4UZEqsRwIyJVYrgRkSox3IhIlRhuRKRKdj1w3tauDewMxxbOQrVORvHp45TqKrmOSEwd5+Chl2r6/HiJuw5fFJ9mDgBMEtPSyYxFBACtvuFxhTcz13Pn5vobl5jyDoDbgdbCtdejxKeABACTRvz4IztWfKwoAHSNOy1cu/iRB6Tafsv3G+Haogw34dqKsmrsF7yDGY/ciEiVGG5EpEoMNyJSJYYbEakSw42IVInhRkSqZPfh1rFjR2g0mlrLc889V2d9YmJirVpnZ7HLOYhIPez+OrdvvvkGppvmEDh16hQeeughTJgwod5t3N3dcebMGctjjcR1YkSkDnYfbjdmurrhrbfeQpcuXTB8+PB6t9FoNLeciJmI1M3uP5berKqqChs3bsTTTz/d4NFYWVkZOnTogICAAIwdOxanTzd8JXZlZSWMRqPVQkTNW7Oa2m/btm34wx/+gLy8PPj7+9dZk5aWhszMTAQFBaG0tBTvvPMODh48iNOnT6Ndu3Z1brNw4UIsWrSo1voRGAtHTQuhvmVv7ie8H12nfi9cCwCZy8SH1fRYnifVdk1+oXix5JR3S3LEh+D0d5L7f7b3waeFazuvkBs2pjjIncbQHPtBuNb4+ACptt22HhGudfTxlmrbbBQflqZxEvs7sPD2FC41Zf4kXFujVGO/kqS+qf3Wrl0Lg8FQb7ABwODBgzF58mT069cPw4cPx/bt2+Hl5YW//e1v9W4zb948lJaWWpZz5841RfeJ6C6y+3NuN+Tm5mLPnj3Yvn271HYtWrRA//79kZWVVW+NTqeDTqe70y4SkR1pNkdu69evh7e3Nx555BGp7UwmE06ePAk/P/FZrYmo+RM6couJiRFucMWKFbfdmfqYzWasX78e0dHRcHS07vLkyZPRtm1bxMXFAQAWL16M+++/H127dkVJSQmWL1+O3NxcPPPMM43eLyKyX0LhduLECaHGmup6sj179iAvLw9PP137JHJeXh602l8PQK9cuYLp06ejoKAArVu3RkhICFJTU9GrV68m6RsR2SehcNu3b19T96NBo0aNQn1f6u7fv9/q8cqVK7Fy5cq70Csisme3fc4tKysLu3btwvXr1wGg3vAhIrIF6XArLi5GWFgYunfvjocffhj5+fkAgGnTpuEvf/lLo3eQiOh2SIfbSy+9hBYtWiAvLw+tWrWyrJ84cSKSk5MbtXNERLdL+jq3r776Crt27ap1tX+3bt2Qm5vbaB0jIroT0kdu5eXlVkdsN1y+fJkXwhKR3ZA+chs2bBg2bNiAJUuWAPjl8g+z2Yy3334bI0eObPQO2pLWpRW0Gieh2hY/1g78etttKXd/uW4by4RrSwdLTNUHwGW7+NjSkqcE51T7rxnf9RCu3T1grVTbnSeLj8/NWhoi1Xa3+WKXPt2gcXcVrpUZKwoA2pYtpeplmCsqhWsvPd1Pqm3v+FTxYqmpFLWA4HeX0uH29ttvIywsDOnp6aiqqsLcuXNx+vRpXL58GV9//bVsc0RETUL6Y2mfPn3w448/YujQoRg7dizKy8sxfvx4nDhxAl26yE2sS0TUVKSP3CoqKqDX6/H666/Xei4/P59jOInILkgfuQ0YMAAZGRm11v/zn/9EUFBQY/SJiOiOSYfbiBEjcP/992PZsmUAfvn2dMqUKXjqqafw2muvNXoHiYhuh/TH0g8++ACPPPIInnnmGXzxxRfIz8+Hq6srjh49ij59+jRFH4mIpN3WzSoNBgPGjx+P1atXw9HREZ9//jmDjYjsivTH0uzsbAwePBhffPEFdu3ahblz5+LRRx/F3LlzUV1d3RR9JCKSJh1u/fr1Q6dOnfDtt9/ioYcewptvvol9+/Zh+/btGDRoUFP0kYhImnS4ffDBB9iyZQs8PDws64YMGYITJ05gwAC5mX2IiJpKs5ra724xGo3Q6/UYoRknPLWfw01hfyuln7SW6k/+JfG2H+8jN3ToO4mRSY7t2kq1vTntU+FavVZumFFk+4HCtZpeXaXaVr4Xn2oOALQeeuFaczu56fcqvcV/Ly0z5KZ11LiIDxk0F/4s1fbF6cHCtX4J6cK1NUo19lV/KjS1n9AXCp999hkMBgNatGiBzz77rN46jUaDMWPGCHeUiKipCH0sHTduHK5cuWL5uaFFxsGDBzFmzBj4+/tDo9EgKSnJ6nlFUbBgwQL4+fmhZcuWCA8PR2Zm5i3bTUhIQMeOHeHs7IzQ0FAcPXpUql9E1PwJhZvZbIa3t7fl5/oWk0luRvLy8nIEBwcjISGhzufffvtt/PWvf8WaNWtw5MgRuLi4ICIiAhUVFfW2uXXrVsTExCA2NhbHjx9HcHAwIiIicOnSJam+EVHzJnWd29mzZ7F7925UV1dj+PDh6N279x29uMFggMFgqPM5RVGwatUqvPHGGxg7diwAYMOGDfDx8UFSUhKefPLJOrdbsWIFpk+fjqlTpwIA1qxZg507d2LdunV49dVX76i/RNR8CIfbvn37MHr0aMuEMI6Ojli3bh3++Mc/NknHcnJyUFBQgPDwcMs6vV6P0NBQpKWl1RluVVVVOHbsGObNm2dZp9VqER4ejrS0tHpfq7KyEpWVv97bymg0NtJeEJGtCF8KMn/+fDz00EO4cOECiouLMX36dMydO7fJOlZQUAAA8PHxsVrv4+Njee63ioqKYDKZpLYBgLi4OOj1essSECB3w0cisj/C4Xbq1CksXboUfn5+aN26NZYvX45Lly6huLi4Kft3V8ybNw+lpaWW5dy5c7buEhHdIeFwMxqN8PT0tDxu1aoVWrZsidLS0ibpmK+vLwCgsND6NtiFhYWW537L09MTDg4OUtsAgE6ng7u7u9VCRM2b1BcKu3btgl7/6wWLZrMZKSkpOHXqlGXdo48+2igd69SpE3x9fZGSkoJ+/foB+CVgjxw5gpkzZ9a5jZOTE0JCQpCSkmK5LOVGH2fNmtUo/SKi5kEq3KKjo2utmzFjhuVnjUYjdTlIWVkZsrKyLI9zcnKQkZGBNm3aoH379pg9ezbefPNNdOvWDZ06dcL8+fPh7+9vdT1dWFgYHnvsMUt4xcTEIDo6GgMHDsSgQYOwatUqlJeXW749JaJ7g3C4mc3mRn/x9PR0qxmzYmJiAPwSoomJiZg7dy7Ky8vx7LPPoqSkBEOHDkVycjKcnX+dPSo7OxtFRUWWxxMnTsTPP/+MBQsWoKCgAP369UNycnKtLxmISN04trQON8aWjmwxQXhsqSJxxKp1EmvzBo1e4hzg9fovcK5TgMScF4VFt665yY5vvxKubaGRmd5NztS8YVL18/ySpeq/LBO/3nOi26lbF91kR1mgeO0AuW/5a37XU7jWKStfqm3oxKbEBADTOvG/nZrySuwbvUZobKn0XUFu5u7ujp9+khtkTER0NwiH28WLF2ut40EfEdkr4XDr3bs3Nm/e3JR9ISJqNMLh9r//+7+YMWMGJkyYgMuXLwMA/vjHP/KaMCKyS8Lh9uc//xnfffcdiouL0atXL3z++edYvXq11YW9RET2Quo6t06dOmHv3r2Ij4/H+PHj0bNnTzg6Wjdx/PjxRu0gEdHtkJ7aLzc3F9u3b0fr1q0xduzYWuFGRGQPpJLpww8/xF/+8heEh4fj9OnT8PLyaqp+ERHdEeFwi4yMxNGjRxEfH4/Jkyc3ZZ+IiO6YcLiZTCZ89913aNeuXVP2h4ioUQiH2+7du5uyH0REjYrfBjRA6+IMrUZwjJxGfCRbTY/2Uv1w/El8XF91UGeptrWHMoRrNZJfHhWZrgvXtnHQSbV91VwlXLuqnfgYVwBw1cjNoTqk1a1nZLvBz9FVqu29l3sI12rc5EZTOmXWHnVUL8n33nRevG3NGPH3XqOIv+93NLaUiMheMdyISJUYbkSkSgw3IlIlhhsRqRLDjYhUyabhdvDgQYwZMwb+/v7QaDRISkqyPFddXY1XXnkFffv2hYuLC/z9/TF58uQ6b5p5s4ULF0Kj0VgtPXqIf51OROpg03ArLy9HcHAwEhISaj137do1HD9+HPPnz8fx48exfft2nDlzRmjqwN69eyM/P9+yHDp0qCm6T0R2zKYX8RoMBhgMhjqf0+v1tUZFxMfHY9CgQcjLy0P79vVfCOvo6NjgJMxEpH7N6pxbaWkpNBoNPDw8GqzLzMyEv78/OnfujEmTJiEvL6/B+srKShiNRquFiJq3ZjP8qqKiAq+88gqioqIavLV5aGgoEhMTERgYiPz8fCxatAjDhg3DqVOn4ObmVuc2cXFxWLRoUa31BRN6wsHJuY4tavNenSa2IwCu+XcXrgUAt6tthGtbnM6VatusEx/6olSJD30BgCkdxKfU0wbJnRfVnC8Urq3u00Gq7RanG/7PsHZnxI8RTMWXpZrWOpUL18pO2CTzfjrcJ/5vEAC0XToK1+ZEeQvXmioqgLhPxPog3KoNVVdX44knnoCiKFi9enWDtQaDARMmTEBQUBAiIiLw5ZdfoqSkBNu2bat3m3nz5qG0tNSynDt3rrF3gYjuMrs/crsRbLm5udi7d6/0hDQeHh7o3r07srKy6q3R6XTQSRzBEJH9s+sjtxvBlpmZiT179uC+++6TbqOsrAzZ2dnw85OYWZ2Imj2bhltZWRkyMjKQkZEBAMjJyUFGRgby8vJQXV2N//mf/0F6ejo2bdoEk8mEgoICFBQUoOqmcwVhYWGIj4+3PJ4zZw4OHDiAs2fPIjU1FY899hgcHBwQFRV1t3ePiGzIph9L09PTMXLkSMvjmJgYAEB0dDQWLlyIzz77DADQr18/q+327duHESNGAACys7NRVFRkee78+fOIiopCcXExvLy8MHToUBw+fJjzPRDdY2wabiNGjGjwGx6Rb3/Onj1r9XjLli132i0iUgG7PudGRHS7GG5EpEoMNyJSJYYbEakSw42IVMnuRyjYku++S3AUnHKueo/4ZNWur16T6kelr4twbYvTJVJtbzuXKlw7sdNwqbYVk0m41vzdD1JtQ2IcpfbfpVJNa7w95bpSUyNc66CXG2FTNFZ8zG3rjw9Lta1t1Uq49mJUoFTblRLX23eKPyNcW2OuQrZgLY/ciEiVGG5EpEoMNyJSJYYbEakSw42IVInhRkSqxHAjIlViuBGRKjHciEiVGG5EpEocftUAU1YONJoWQrXaMPF2FcjNruXkKP42aVq2lGpbZkiVUi03tZ8Mx3ZtpepNBeJT+2nrmdKxPjWXim5ddBOHNh7CtaZSuTlx7/v0O+Fas1TLQNb8IOHaLm8clWpbIzHhkrmqWrxWEa/lkRsRqZJNw+3gwYMYM2YM/P39odFokJSUZPX8lClToNForJbIyMhbtpuQkICOHTvC2dkZoaGhOHpU7n8dImr+bBpu5eXlCA4ORkJCQr01kZGRyM/PtyyffNLwbNNbt25FTEwMYmNjcfz4cQQHByMiIgKXLl1q7O4TkR2z6Tk3g8EAg8HQYI1Op4Ovr69wmytWrMD06dMxdepUAMCaNWuwc+dOrFu3Dq+++uod9ZeImg+7P+e2f/9+eHt7IzAwEDNnzkRxcXG9tVVVVTh27BjCw8Mt67RaLcLDw5GWllbvdpWVlTAajVYLETVvdh1ukZGR2LBhA1JSUrBs2TIcOHAABoMBpnpuglhUVASTyQQfHx+r9T4+PigoKKj3deLi4qDX6y1LQEBAo+4HEd19dn0pyJNPPmn5uW/fvggKCkKXLl2wf/9+hIVJXHtxC/PmzbNMCA0ARqORAUfUzNn1kdtvde7cGZ6ensjKyqrzeU9PTzg4OKCw0PoaqMLCwgbP2+l0Ori7u1stRNS8NatwO3/+PIqLi+Hn51fn805OTggJCUFKSoplndlsRkpKCgYPHny3uklEdsCm4VZWVoaMjAxkZGQAAHJycpCRkYG8vDyUlZXh5ZdfxuHDh3H27FmkpKRg7Nix6Nq1KyIiIixthIWFIT4+3vI4JiYGH374IT7++GN8//33mDlzJsrLyy3fnhLRvcGm59zS09MxcuRIy+Mb572io6OxevVqfPfdd/j4449RUlICf39/jBo1CkuWLIHupqEd2dnZKCr6dbjMxIkT8fPPP2PBggUoKChAv379kJycXOtLBiJSN42iSMyRdo8wGo3Q6/Xo+vJSOOichbYx68R/jX6p4lPBAYBun/j4Qm2yxJxqAMyjJMZRKrKjF8VdHT9Qqt5950nh2sy/d5dqO3D+Fan6q0HewrWVbg5Sbbf+5BvhWpkpBgEAWvG+OHYQn7oSAGpycoVrHSTOcdcoVUgxbkRpaektz403q3NuRESiGG5EpEoMNyJSJYYbEakSw42IVInhRkSqxHAjIlViuBGRKjHciEiVGG5EpEp2fT83Wwv4awYcBaf2u/T0AOF2nfeLDx0CAHOV+JR6V9+Xuw9dqxBP4VqHH8SH1ACAqaRUuLbF1bpvQNoYuj79H6l6xc1V7gUU8eFXHhsPyzUd2le8+IjcvyttUKBwbc2338u13aqVcO3fT30pXHv1qhl9egn2QbhVIqJmhOFGRKrEcCMiVWK4EZEqMdyISJUYbkSkSgw3IlIlm4bbwYMHMWbMGPj7+0Oj0SApKcnqeY1GU+eyfPnyettcuHBhrfoePXo08Z4Qkb2xabiVl5cjODgYCQkJdT6fn59vtaxbtw4ajQaPP/54g+327t3bartDhw41RfeJyI7ZdISCwWCAwWCo9/nfTqS8Y8cOjBw5Ep07d26wXUdHxwYnYSYi9Ws259wKCwuxc+dOTJs27Za1mZmZ8Pf3R+fOnTFp0iTk5eU1WF9ZWQmj0Wi1EFHz1mzGln788cdwc3PD+PHjG6wLDQ1FYmIiAgMDkZ+fj0WLFmHYsGE4deoU3Nzc6twmLi4OixYtqrW+JrQH4Cg2tZ/X6jShOgAwazTCtQCQvTxUuDbw/QtSbZsuFgrXVg3tI9W2LveyePGu41Jtl074nXCtS0GlVNvX3cTGE99Q5Sp+jODiKjduVakUH3P7WvYJqbaXDfMTrv3xXfF/gwDQdY74lITT2g8Vrq1RqgHsEKptNkdu69atw6RJk+Ds3HDYGAwGTJgwAUFBQYiIiMCXX36JkpISbNu2rd5t5s2bh9LSUsty7ty5xu4+Ed1lzeLI7d///jfOnDmDrVu3Sm/r4eGB7t27Iysrq94anU5nNYs9ETV/zeLIbe3atQgJCUFwcLD0tmVlZcjOzoafn/ghOBE1fzYNt7KyMmRkZCAjIwMAkJOTg4yMDKsvAIxGIz799FM888wzdbYRFhaG+Ph4y+M5c+bgwIEDOHv2LFJTU/HYY4/BwcEBUVFRTbovRGRfbPqxND09HSNHjrQ8jomJAQBER0cjMTERALBlyxYoilJvOGVnZ6OoqMjy+Pz584iKikJxcTG8vLwwdOhQHD58GF5eXk23I0Rkd2wabiNGjICiKA3WPPvss3j22Wfrff7s2bNWj7ds2dIYXSOiZq5ZnHMjIpLFcCMiVWK4EZEqMdyISJU0yq3O6N+DjEYj9Ho9Rnw+E44uYhf3aseIDzVSTHLT2CkSU/tpnJzk2q6UGJokOWzMsWN74dqHvvhWqu2vHuwuXKuUlUu1LeuV78SH3j3gXC3V9sEK8fdzxdCHpNqu6i5+7afjN2ek2ta61z3UsS6KySxcW2OuQkrRWpSWlsLd3b3hPgi3SkTUjDDciEiVGG5EpEoMNyJSJYYbEakSw42IVInhRkSqxHAjIlViuBGRKjHciEiVmsUcCnfbjRFpNdfEhz1pFfFaRREfbvJLvfiQHY0iN0RKpm1Arm2YxYd2VZTVSDVdY5b5fYvX3o7yq+LD6YzVcu99eYV42zK/EwCoqakQL5b8HWpl3h+z3PArALe8DyTAsaV1On/+PAICAmzdDSKqx7lz59CuXbsGaxhudTCbzbh48SLc3NyguWmwuNFoREBAAM6dO3fLQbvN2b2wn/fCPgLq209FUXD16lX4+/tDq234rBo/ltZBq9U2+L+Cu7u7Kv6h3Mq9sJ/3wj4C6tpPvV4vVMcvFIhIlRhuRKRKDDcJOp0OsbGxqp+d/l7Yz3thH4F7Zz/rwi8UiEiVeORGRKrEcCMiVWK4EZEqMdyISJUYboISEhLQsWNHODs7IzQ0FEePHrV1lxrVwoULodForJYePXrYult37ODBgxgzZgz8/f2h0WiQlJRk9byiKFiwYAH8/PzQsmVLhIeHIzMz0zadvQO32s8pU6bUen8jIyNt09m7hOEmYOvWrYiJiUFsbCyOHz+O4OBgRERE4NKlS7buWqPq3bs38vPzLcuhQ4ds3aU7Vl5ejuDgYCQkJNT5/Ntvv42//vWvWLNmDY4cOQIXFxdERESgokJiULkduNV+AkBkZKTV+/vJJ5/cxR7agEK3NGjQIOW5556zPDaZTIq/v78SFxdnw141rtjYWCU4ONjW3WhSAJR//etflsdms1nx9fVVli9fbllXUlKi6HQ65ZNPPrFBDxvHb/dTURQlOjpaGTt2rE36Yys8cruFqqoqHDt2DOHh4ZZ1Wq0W4eHhSEsTn2m8OcjMzIS/vz86d+6MSZMmIS8vz9ZdalI5OTkoKCiwem/1ej1CQ0NV994CwP79++Ht7Y3AwEDMnDkTxcXFtu5Sk2K43UJRURFMJhN8fHys1vv4+KCgoMBGvWp8oaGhSExMRHJyMlavXo2cnBwMGzYMV69etXXXmsyN90/t7y3wy0fSDRs2ICUlBcuWLcOBAwdgMBhgMonfL6654V1BCABgMBgsPwcFBSE0NBQdOnTAtm3bMG3aNBv2jBrDk08+afm5b9++CAoKQpcuXbB//36EhYXZsGdNh0dut+Dp6QkHBwcUFhZarS8sLISvr6+NetX0PDw80L17d2RlZdm6K03mxvt3r723ANC5c2d4enqq+v1luN2Ck5MTQkJCkJKSYllnNpuRkpKCwYMH27BnTausrAzZ2dnw8/OzdVeaTKdOneDr62v13hqNRhw5ckTV7y3wy92mi4uLVf3+8mOpgJiYGERHR2PgwIEYNGgQVq1ahfLyckydOtXWXWs0c+bMwZgxY9ChQwdcvHgRsbGxcHBwQFRUlK27dkfKysqsjk5ycnKQkZGBNm3aoH379pg9ezbefPNNdOvWDZ06dcL8+fPh7++PcePG2a7Tt6Gh/WzTpg0WLVqExx9/HL6+vsjOzsbcuXPRtWtXRERE2LDXTczWX9c2F++//77Svn17xcnJSRk0aJBy+PBhW3epUU2cOFHx8/NTnJyclLZt2yoTJ05UsrKybN2tO7Zv3z4FQK0lOjpaUZRfLgeZP3++4uPjo+h0OiUsLEw5c+aMbTt9Gxraz2vXrimjRo1SvLy8lBYtWigdOnRQpk+frhQUFNi6202KtzwiIlXiOTciUiWGGxGpEsONiFSJ4UZEqsRwIyJVYrgRkSox3IhIlRhuRKRKDDdSvbpuu30nRowYgdmzZzdae9Q0GG5kN0wmE4YMGYLx48dbrS8tLUVAQABef/31Ore7eV4AvV6PBx54AHv37rU8n5+fb3VLJ7o3MNzIbjg4OFhumLlp0ybL+ueffx5t2rRBbGxsvduuX78e+fn5+Prrr+Hp6YnRo0fjp59+AvDLrY10Ol2T95/sC8ON7Er37t3x1ltv4fnnn0d+fj527NiBLVu2YMOGDXBycqp3Ow8PD/j6+qJPnz5YvXo1rl+/jt27dwOw/li6YcMGuLq6Ws1w9ec//xk9evTAtWvXAACnTp2CwWCAq6srfHx88NRTT6GoqKjpdpqaBMON7M7zzz+P4OBgPPXUU3j22WexYMECBAcHC2/fsmVLAL/Mf/FbkydPxsMPP4xJkyahpqYGO3fuxEcffYRNmzahVatWKCkpwYMPPoj+/fsjPT0dycnJKCwsxBNPPNFo+0d3B+/nRnZHo9Fg9erV6NmzJ/r27YtXX31VeNtr167hjTfegIODA4YPH15nzd/+9jcEBQXhhRdewPbt27Fw4UKEhIQAAOLj49G/f38sXbrUUr9u3ToEBATgxx9/RPfu3e9s5+iuYbiRXVq3bh1atWqFnJwcnD9/Hh07dsSf/vQnbNy40VJTVlZm+TkqKgoODg64fv06vLy8sHbtWgQFBdXZduvWrbF27VpERERgyJAhVuH57bffYt++fXB1da21XXZ2NsOtGWG4kd1JTU3FypUr8dVXX+HNN9/EtGnTsGfPHixevBhz5sypc5uVK1ciPDwcer0eXl5et3yNgwcPwsHBAfn5+SgvL4ebmxuAXwJzzJgxWLZsWa1t1HxLbjViuJFduXbtGqZMmYKZM2di5MiR6NSpE/r27Ys1a9Zg5syZ8Pb2rnM7X19fdO3aVeg1UlNTsWzZMnz++ed45ZVXMGvWLHz88ccAgAEDBuCf//wnOnbsCEdH/nk0Z/xCgezKvHnzoCgK3nrrLQBAx44d8c4772Du3Lk4e/bsHbd/9epVPPXUU3jhhRdgMBiwadMmbN26Ff/4xz8AAM899xwuX76MqKgofPPNN8jOzsauXbswdepUVc/xqUYMN7IbBw4cQEJCAtavX49WrVpZ1s+YMQNDhgzBtGnTcKd3xX/xxRfh4uJi+cKgb9++WLp0KWbMmIELFy7A398fX3/9NUwmE0aNGoW+ffti9uzZ8PDwgFbLP5fmhHMoEJEq8b8iIlIlhhsRqRLDjYhUieFGRKrEcCMiVWK4EZEqMdyISJUYbkSkSgw3IlIlhhsRqRLDjYhU6f8DMsF3cV14NSMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_img = np.random.normal(0, 1, (1, 100))\n",
    "img = generate_img(start_img, gen_ann)\n",
    "plot_image(img, gray=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4e5594-68e2-4689-9fd5-3957e8f3e7e2",
   "metadata": {},
   "source": [
    "Was passiert wenn immer der gleiche Input gegeben wird? \n",
    "- Die Prediction-Funktion (Netz und Parameter) liefert immer dasselbe Ergebnis => Koeffizienten sind statisch genau wie Bias, daher kommt immer das gleiche heraus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "01bed838-5fc9-4a0d-9c92-1c6669de3694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Nehme selben Input.\n",
    "img = generate_img(start_img, gen_ann)\n",
    "plot_image(img, gray=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "76f17fba-7fbd-4f2c-bf42-4e965fa62793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "y_true = generate_img(start_img, gen_ann).reshape((400,))\n",
    "\n",
    "y_pred = [generate_img(start_img, gen_ann).reshape((400,)) for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ee0e3dbd-98f4-400b-8e7b-f47018d28634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(y_pred)):\n",
    "    print(np.array_equal(y_true, y_pred[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2986ccc-d3e4-457e-bf05-717f551182f4",
   "metadata": {},
   "source": [
    "Durch den Einbau von Seeds Dropouts und weitere Elementen kann eine Dynamik miteingebracht werden, damit jedes nachfolgende Bild sich von den vorherigen unterscheidet. \n",
    "- `np.random.normal` erzeugt immer einen anderen Input für das Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07c6d02-1db9-4078-9b31-f14f34f7fe15",
   "metadata": {},
   "source": [
    "<h2>Speichere Bilder während des Trainings</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1deb544-fee2-47d2-984f-fdbef3386e55",
   "metadata": {},
   "source": [
    "Während des Trainings können die Bilder nach n-Epochen gespeichert werden, um die Entwicklung sichtbar zu machen. <br>\n",
    "Auch Möglich: <br>\n",
    "- Vergleiche Vektoren: wie ähnlich sind diese am Ende?\n",
    "- Extrahiere Vektor jedes Layers des Models: Entwicklungsschritte Layer für Layer (möglich, wenn daraus ein Bild konstruiert werden kann)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "97ebae3a-2626-400f-b3f4-221d6a9e8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img(img, epoch):\n",
    "    img = 0.5 * img + 0.5\n",
    "    matimg.imsave(f'./data/data/1__GAN/img{epoch}.jpeg', img.reshape((20,20)))\n",
    "\n",
    "def train(generator, discriminator, gan, train_img, epochs, batch_size): \n",
    "    half_batch = int(batch_size / 2)  \n",
    "    for epoch in range(epochs):  \n",
    "        index = np.random.randint(0, train_img.shape[0], half_batch)  \n",
    "        real_images = train_img[index]  # Hole Samples.\n",
    "        noise       = np.random.normal(0, 1, (half_batch, 100)) \n",
    "        fake_images = generator.predict(noise)  # Erstelle Prediction. \n",
    "        # Berechne Loss. # Setze Labels.\n",
    "        loss_real = discriminator.train_on_batch(real_images, np.ones(  (half_batch, 1) ))  # Label 1 für n-Samples für echte Bilder. \n",
    "        loss_fake = discriminator.train_on_batch(fake_images, np.zeros( (half_batch, 1) ))  # Label 0 für n-Samples für UN-echte Bilder.\n",
    "        d_loss = 0.5 * np.add(loss_real, loss_fake)  # Schnitt der Beiden Losses. \n",
    "        # Generator # Wie Oben. \n",
    "        noise    = np.random.normal(0, 1, (batch_size, 100))\n",
    "        y        = np.ones(batch_size)\n",
    "        gan_loss = gan.train_on_batch(noise, y)\n",
    "        # Manuelle Ausgabe.:\n",
    "        print(f\"Epoche: {epoch + 1}/{epochs} GAN loss: {gan_loss}\")\n",
    "\n",
    "        if (epoch%200==0) | (epoch+1==epochs):\n",
    "            save_img(fake_images[0], epoch)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "85f7dd13-40da-4dd7-9ba1-6ac0d11674a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = create_discriminator()\n",
    "discriminator.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss      = 'binary_crossentropy',\n",
    "    metrics   = 'accuracy'\n",
    ")\n",
    "discriminator.trainable = False\n",
    "# Erstelle GAN\n",
    "generator = create_generator()\n",
    "gan_input = tf.keras.layers.Input(shape=(100,))  # 100 Startpixel.\n",
    "gen_image = generator(gan_input)\n",
    "net_output = discriminator(gen_image)\n",
    "GAN        = tf.keras.Model(gan_input, net_output)\n",
    "GAN.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "26dd3d04-fe1b-4397-8675-8099d36e4f8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step\n",
      "Epoche: 1/1200 GAN loss: 0.6330462694168091\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 2/1200 GAN loss: 0.9008914232254028\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 3/1200 GAN loss: 1.4039802551269531\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 4/1200 GAN loss: 2.2934913635253906\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 5/1200 GAN loss: 3.459859848022461\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 6/1200 GAN loss: 4.912616729736328\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 7/1200 GAN loss: 6.107210636138916\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 8/1200 GAN loss: 7.121273994445801\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 9/1200 GAN loss: 7.913349151611328\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 10/1200 GAN loss: 8.714920043945312\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 11/1200 GAN loss: 9.117280960083008\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 12/1200 GAN loss: 9.668832778930664\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 13/1200 GAN loss: 10.02971363067627\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 14/1200 GAN loss: 10.357820510864258\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 15/1200 GAN loss: 10.7017240524292\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 16/1200 GAN loss: 10.972935676574707\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 17/1200 GAN loss: 11.289938926696777\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 18/1200 GAN loss: 11.756820678710938\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 19/1200 GAN loss: 11.885259628295898\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 20/1200 GAN loss: 11.925607681274414\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 21/1200 GAN loss: 12.51010513305664\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 22/1200 GAN loss: 13.258755683898926\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 23/1200 GAN loss: 13.345620155334473\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 24/1200 GAN loss: 13.638751983642578\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 25/1200 GAN loss: 13.82319450378418\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 26/1200 GAN loss: 14.031973838806152\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 27/1200 GAN loss: 14.860153198242188\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 28/1200 GAN loss: 13.729991912841797\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 29/1200 GAN loss: 13.653818130493164\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 30/1200 GAN loss: 14.211989402770996\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 31/1200 GAN loss: 14.001249313354492\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 32/1200 GAN loss: 13.681350708007812\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 33/1200 GAN loss: 14.80032730102539\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 34/1200 GAN loss: 14.097219467163086\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 35/1200 GAN loss: 15.116413116455078\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 36/1200 GAN loss: 13.794171333312988\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 37/1200 GAN loss: 14.021451950073242\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 38/1200 GAN loss: 13.879140853881836\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 39/1200 GAN loss: 14.214170455932617\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 40/1200 GAN loss: 13.6533842086792\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 41/1200 GAN loss: 14.095791816711426\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 42/1200 GAN loss: 14.738024711608887\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 43/1200 GAN loss: 13.069442749023438\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 44/1200 GAN loss: 11.742183685302734\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 45/1200 GAN loss: 11.201948165893555\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 46/1200 GAN loss: 14.182422637939453\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 47/1200 GAN loss: 19.345184326171875\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 48/1200 GAN loss: 10.038726806640625\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 49/1200 GAN loss: 6.546813488006592\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 50/1200 GAN loss: 6.409512042999268\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 51/1200 GAN loss: 8.584779739379883\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 52/1200 GAN loss: 16.645183563232422\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 53/1200 GAN loss: 24.91088104248047\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 54/1200 GAN loss: 6.678999423980713\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 55/1200 GAN loss: 3.5586256980895996\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 56/1200 GAN loss: 4.434144973754883\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 57/1200 GAN loss: 4.212858200073242\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 58/1200 GAN loss: 4.501557350158691\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 59/1200 GAN loss: 4.969659805297852\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 60/1200 GAN loss: 17.586288452148438\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 61/1200 GAN loss: 27.667926788330078\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 62/1200 GAN loss: 38.70368194580078\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 63/1200 GAN loss: 18.067169189453125\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 64/1200 GAN loss: 6.643037796020508\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 65/1200 GAN loss: 4.026177883148193\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 66/1200 GAN loss: 3.9131808280944824\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 67/1200 GAN loss: 5.0192155838012695\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 68/1200 GAN loss: 4.67137336730957\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 69/1200 GAN loss: 5.950583457946777\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 70/1200 GAN loss: 9.54690933227539\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 71/1200 GAN loss: 21.904754638671875\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 72/1200 GAN loss: 29.101051330566406\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 73/1200 GAN loss: 38.946556091308594\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 74/1200 GAN loss: 24.347251892089844\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 75/1200 GAN loss: 11.067312240600586\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 76/1200 GAN loss: 8.997838020324707\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 77/1200 GAN loss: 9.39748764038086\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 78/1200 GAN loss: 10.143367767333984\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 79/1200 GAN loss: 9.5260648727417\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 80/1200 GAN loss: 8.619531631469727\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 81/1200 GAN loss: 7.331284523010254\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 82/1200 GAN loss: 13.138864517211914\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 83/1200 GAN loss: 19.435529708862305\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 84/1200 GAN loss: 25.464879989624023\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 85/1200 GAN loss: 12.876379013061523\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 86/1200 GAN loss: 5.998579978942871\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 87/1200 GAN loss: 4.74025821685791\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 88/1200 GAN loss: 4.553523540496826\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 89/1200 GAN loss: 3.754883050918579\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 90/1200 GAN loss: 6.363484859466553\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 91/1200 GAN loss: 4.829183101654053\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 92/1200 GAN loss: 7.199904918670654\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 93/1200 GAN loss: 8.568920135498047\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 94/1200 GAN loss: 8.556234359741211\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 95/1200 GAN loss: 6.886285781860352\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 96/1200 GAN loss: 6.911582946777344\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 97/1200 GAN loss: 6.520275115966797\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 98/1200 GAN loss: 6.6684370040893555\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 99/1200 GAN loss: 6.838249683380127\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 100/1200 GAN loss: 7.8261799812316895\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 101/1200 GAN loss: 8.255959510803223\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 102/1200 GAN loss: 7.762302398681641\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 103/1200 GAN loss: 7.994680404663086\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 104/1200 GAN loss: 7.872894287109375\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 105/1200 GAN loss: 7.430452346801758\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 106/1200 GAN loss: 8.05974292755127\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 107/1200 GAN loss: 7.077202796936035\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 108/1200 GAN loss: 6.704862594604492\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 109/1200 GAN loss: 7.433524131774902\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 110/1200 GAN loss: 7.400232315063477\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 111/1200 GAN loss: 7.425047874450684\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 112/1200 GAN loss: 6.888894081115723\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 113/1200 GAN loss: 7.928614139556885\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 114/1200 GAN loss: 7.093835830688477\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 115/1200 GAN loss: 7.996888160705566\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 116/1200 GAN loss: 6.286657810211182\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 117/1200 GAN loss: 6.6575775146484375\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 118/1200 GAN loss: 7.292400360107422\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 119/1200 GAN loss: 7.10474967956543\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 120/1200 GAN loss: 7.9164862632751465\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 121/1200 GAN loss: 7.308570384979248\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 122/1200 GAN loss: 6.85581111907959\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 123/1200 GAN loss: 7.59223747253418\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 124/1200 GAN loss: 8.047333717346191\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 125/1200 GAN loss: 7.962950706481934\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 126/1200 GAN loss: 7.536120414733887\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 127/1200 GAN loss: 7.822622776031494\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 128/1200 GAN loss: 7.76248836517334\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 129/1200 GAN loss: 6.440777778625488\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 130/1200 GAN loss: 6.722781181335449\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 131/1200 GAN loss: 7.110804557800293\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 132/1200 GAN loss: 7.155835151672363\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 133/1200 GAN loss: 5.24576997756958\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 134/1200 GAN loss: 6.562808513641357\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 135/1200 GAN loss: 8.684908866882324\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 136/1200 GAN loss: 8.415940284729004\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 137/1200 GAN loss: 7.456661224365234\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 138/1200 GAN loss: 6.932082653045654\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 139/1200 GAN loss: 7.495843887329102\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 140/1200 GAN loss: 7.724645614624023\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 141/1200 GAN loss: 8.924323081970215\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 142/1200 GAN loss: 6.7917680740356445\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 143/1200 GAN loss: 6.0717058181762695\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 144/1200 GAN loss: 6.837346076965332\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 145/1200 GAN loss: 8.517874717712402\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 146/1200 GAN loss: 6.734959602355957\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 147/1200 GAN loss: 6.547214508056641\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 148/1200 GAN loss: 6.802493095397949\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 149/1200 GAN loss: 7.915573596954346\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 150/1200 GAN loss: 9.048980712890625\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 151/1200 GAN loss: 8.932708740234375\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 152/1200 GAN loss: 9.252443313598633\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 153/1200 GAN loss: 8.083158493041992\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 154/1200 GAN loss: 7.418587684631348\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 155/1200 GAN loss: 7.775721549987793\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 156/1200 GAN loss: 8.631832122802734\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 157/1200 GAN loss: 8.64077091217041\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 158/1200 GAN loss: 8.919917106628418\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 159/1200 GAN loss: 8.636792182922363\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 160/1200 GAN loss: 8.0584077835083\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 161/1200 GAN loss: 7.9707512855529785\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 162/1200 GAN loss: 8.113912582397461\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 163/1200 GAN loss: 8.040816307067871\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 164/1200 GAN loss: 7.876589775085449\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 165/1200 GAN loss: 7.842996120452881\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 166/1200 GAN loss: 7.526246070861816\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 167/1200 GAN loss: 6.9815521240234375\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 168/1200 GAN loss: 6.635485649108887\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 169/1200 GAN loss: 6.889294624328613\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 170/1200 GAN loss: 7.188314914703369\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 171/1200 GAN loss: 6.609762668609619\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 172/1200 GAN loss: 6.563655853271484\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 173/1200 GAN loss: 6.255242347717285\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 174/1200 GAN loss: 7.208080291748047\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 175/1200 GAN loss: 7.724602222442627\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 176/1200 GAN loss: 6.764138698577881\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 177/1200 GAN loss: 6.866432189941406\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 178/1200 GAN loss: 7.876166343688965\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 179/1200 GAN loss: 8.114185333251953\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 180/1200 GAN loss: 8.163712501525879\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 181/1200 GAN loss: 7.750302314758301\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 182/1200 GAN loss: 7.383508682250977\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 183/1200 GAN loss: 7.555878639221191\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 184/1200 GAN loss: 7.782868385314941\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 185/1200 GAN loss: 7.102630138397217\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 186/1200 GAN loss: 7.171124458312988\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 187/1200 GAN loss: 7.12037467956543\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 188/1200 GAN loss: 7.380340576171875\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 189/1200 GAN loss: 7.476048469543457\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 190/1200 GAN loss: 7.4754228591918945\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 191/1200 GAN loss: 7.721980094909668\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 192/1200 GAN loss: 7.682490825653076\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 193/1200 GAN loss: 7.401941299438477\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 194/1200 GAN loss: 7.917817115783691\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 195/1200 GAN loss: 8.025394439697266\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 196/1200 GAN loss: 8.173685073852539\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 197/1200 GAN loss: 8.251579284667969\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 198/1200 GAN loss: 8.965103149414062\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 199/1200 GAN loss: 9.105961799621582\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 200/1200 GAN loss: 8.704972267150879\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 201/1200 GAN loss: 8.844050407409668\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 202/1200 GAN loss: 9.135599136352539\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 203/1200 GAN loss: 8.968649864196777\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 204/1200 GAN loss: 8.517326354980469\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 205/1200 GAN loss: 8.247672080993652\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 206/1200 GAN loss: 8.366483688354492\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 207/1200 GAN loss: 7.979848861694336\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 208/1200 GAN loss: 8.579353332519531\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 209/1200 GAN loss: 7.833390235900879\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 210/1200 GAN loss: 7.510876655578613\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 211/1200 GAN loss: 7.315765380859375\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 212/1200 GAN loss: 7.921927452087402\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 213/1200 GAN loss: 8.960442543029785\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 214/1200 GAN loss: 8.66719913482666\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 215/1200 GAN loss: 8.570035934448242\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 216/1200 GAN loss: 8.876103401184082\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 217/1200 GAN loss: 8.203323364257812\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 218/1200 GAN loss: 8.722477912902832\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 219/1200 GAN loss: 8.197065353393555\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 220/1200 GAN loss: 8.636670112609863\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 221/1200 GAN loss: 8.329069137573242\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 222/1200 GAN loss: 8.365462303161621\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 223/1200 GAN loss: 8.738482475280762\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 224/1200 GAN loss: 8.377241134643555\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 225/1200 GAN loss: 8.431722640991211\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 226/1200 GAN loss: 8.76877498626709\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 227/1200 GAN loss: 9.405860900878906\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 228/1200 GAN loss: 7.772044658660889\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 229/1200 GAN loss: 7.307994842529297\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 230/1200 GAN loss: 7.744997024536133\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 231/1200 GAN loss: 9.664928436279297\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 232/1200 GAN loss: 7.6919331550598145\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 233/1200 GAN loss: 7.28085994720459\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 234/1200 GAN loss: 8.241886138916016\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 235/1200 GAN loss: 8.92763614654541\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 236/1200 GAN loss: 8.929973602294922\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 237/1200 GAN loss: 7.971400737762451\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 238/1200 GAN loss: 7.282620906829834\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 239/1200 GAN loss: 7.643591403961182\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 240/1200 GAN loss: 7.61564826965332\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 241/1200 GAN loss: 7.408011436462402\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 242/1200 GAN loss: 7.691300392150879\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 243/1200 GAN loss: 8.062734603881836\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 244/1200 GAN loss: 8.725364685058594\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 245/1200 GAN loss: 8.206351280212402\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 246/1200 GAN loss: 7.469321250915527\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 247/1200 GAN loss: 7.818170547485352\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoche: 248/1200 GAN loss: 8.192825317382812\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 249/1200 GAN loss: 8.821889877319336\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 250/1200 GAN loss: 7.871728897094727\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 251/1200 GAN loss: 7.326288223266602\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 252/1200 GAN loss: 8.482743263244629\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 253/1200 GAN loss: 7.694986343383789\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 254/1200 GAN loss: 7.541118621826172\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 255/1200 GAN loss: 7.784443378448486\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 256/1200 GAN loss: 6.6607160568237305\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 257/1200 GAN loss: 7.162131309509277\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 258/1200 GAN loss: 8.385763168334961\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 259/1200 GAN loss: 8.166059494018555\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 260/1200 GAN loss: 9.735832214355469\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 261/1200 GAN loss: 3.7643558979034424\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 262/1200 GAN loss: 11.627647399902344\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 263/1200 GAN loss: 1.437828779220581\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 264/1200 GAN loss: 2.303835868835449\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 265/1200 GAN loss: 10.31620979309082\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 266/1200 GAN loss: 24.77536392211914\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 267/1200 GAN loss: 6.484048843383789\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 268/1200 GAN loss: 1.187744140625\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 269/1200 GAN loss: 1.190402626991272\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 270/1200 GAN loss: 2.3286495208740234\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 271/1200 GAN loss: 5.822588920593262\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 272/1200 GAN loss: 11.458883285522461\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 273/1200 GAN loss: 9.294500350952148\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 274/1200 GAN loss: 5.203506946563721\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 275/1200 GAN loss: 2.3603625297546387\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 276/1200 GAN loss: 2.434323787689209\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 277/1200 GAN loss: 1.9201897382736206\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 278/1200 GAN loss: 2.9077610969543457\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 279/1200 GAN loss: 4.435585021972656\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 280/1200 GAN loss: 7.1632537841796875\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 281/1200 GAN loss: 8.887014389038086\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 282/1200 GAN loss: 6.897709846496582\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 283/1200 GAN loss: 5.753257751464844\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 284/1200 GAN loss: 4.478629112243652\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 285/1200 GAN loss: 3.507636547088623\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 286/1200 GAN loss: 5.065860271453857\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 287/1200 GAN loss: 5.796718597412109\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 288/1200 GAN loss: 6.570766448974609\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 289/1200 GAN loss: 5.795313835144043\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 290/1200 GAN loss: 4.591706275939941\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 291/1200 GAN loss: 3.9675817489624023\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 292/1200 GAN loss: 5.157262802124023\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 293/1200 GAN loss: 3.9485318660736084\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 294/1200 GAN loss: 3.3920209407806396\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 295/1200 GAN loss: 4.117463111877441\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 296/1200 GAN loss: 4.1066694259643555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 297/1200 GAN loss: 2.648930549621582\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 298/1200 GAN loss: 3.163172721862793\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 299/1200 GAN loss: 4.0611371994018555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 300/1200 GAN loss: 2.536067485809326\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 301/1200 GAN loss: 2.848034381866455\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 302/1200 GAN loss: 4.713226318359375\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 303/1200 GAN loss: 1.7452712059020996\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 304/1200 GAN loss: 2.8712000846862793\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 305/1200 GAN loss: 6.861828804016113\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 306/1200 GAN loss: 1.9910531044006348\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 307/1200 GAN loss: 0.7121304869651794\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 308/1200 GAN loss: 4.053701400756836\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 309/1200 GAN loss: 11.313594818115234\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 310/1200 GAN loss: 3.776500940322876\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 311/1200 GAN loss: 0.8958298563957214\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 312/1200 GAN loss: 1.0263264179229736\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 313/1200 GAN loss: 2.8721792697906494\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 314/1200 GAN loss: 4.766183853149414\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 315/1200 GAN loss: 3.019601345062256\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 316/1200 GAN loss: 2.0822224617004395\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 317/1200 GAN loss: 1.991628885269165\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 318/1200 GAN loss: 2.424372673034668\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 319/1200 GAN loss: 3.1200690269470215\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 320/1200 GAN loss: 2.220675468444824\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 321/1200 GAN loss: 1.4330493211746216\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 322/1200 GAN loss: 1.5976674556732178\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 323/1200 GAN loss: 2.3113303184509277\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 324/1200 GAN loss: 2.0698232650756836\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 325/1200 GAN loss: 1.702507495880127\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 326/1200 GAN loss: 1.59208345413208\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 327/1200 GAN loss: 1.9602546691894531\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 328/1200 GAN loss: 2.6805853843688965\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 329/1200 GAN loss: 1.6922900676727295\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 330/1200 GAN loss: 1.8590905666351318\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 331/1200 GAN loss: 1.81988525390625\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 332/1200 GAN loss: 2.278926372528076\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 333/1200 GAN loss: 2.056813955307007\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 334/1200 GAN loss: 2.2199220657348633\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 335/1200 GAN loss: 2.3679568767547607\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 336/1200 GAN loss: 1.9533125162124634\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 337/1200 GAN loss: 2.1882829666137695\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 338/1200 GAN loss: 2.669487476348877\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 339/1200 GAN loss: 2.57450008392334\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 340/1200 GAN loss: 2.1750259399414062\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 341/1200 GAN loss: 2.5568346977233887\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 342/1200 GAN loss: 3.166757583618164\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 343/1200 GAN loss: 2.5220370292663574\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 344/1200 GAN loss: 2.529393196105957\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 345/1200 GAN loss: 2.6436574459075928\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 346/1200 GAN loss: 2.4095520973205566\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 347/1200 GAN loss: 2.829519510269165\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 348/1200 GAN loss: 2.6480512619018555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 349/1200 GAN loss: 2.5701847076416016\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 350/1200 GAN loss: 2.9948976039886475\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 351/1200 GAN loss: 2.642673969268799\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 352/1200 GAN loss: 3.0863778591156006\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 353/1200 GAN loss: 3.0989842414855957\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 354/1200 GAN loss: 2.186008930206299\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 355/1200 GAN loss: 2.7714486122131348\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 356/1200 GAN loss: 3.8975324630737305\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 357/1200 GAN loss: 1.8609875440597534\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 358/1200 GAN loss: 2.1501388549804688\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 359/1200 GAN loss: 3.8883187770843506\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 360/1200 GAN loss: 1.3415846824645996\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 361/1200 GAN loss: 1.5013623237609863\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 362/1200 GAN loss: 2.732247829437256\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 363/1200 GAN loss: 3.085747241973877\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 364/1200 GAN loss: 1.1421582698822021\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 365/1200 GAN loss: 1.351019024848938\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 366/1200 GAN loss: 3.333603858947754\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 367/1200 GAN loss: 2.129749298095703\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 368/1200 GAN loss: 1.2587534189224243\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 369/1200 GAN loss: 2.614466428756714\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 370/1200 GAN loss: 3.4688327312469482\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 371/1200 GAN loss: 1.6658961772918701\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 372/1200 GAN loss: 1.4180129766464233\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 373/1200 GAN loss: 2.669703245162964\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 374/1200 GAN loss: 2.0843124389648438\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 375/1200 GAN loss: 1.8856112957000732\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 376/1200 GAN loss: 2.4056735038757324\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 377/1200 GAN loss: 1.9178552627563477\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 378/1200 GAN loss: 1.9147850275039673\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 379/1200 GAN loss: 2.0983848571777344\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 380/1200 GAN loss: 2.4455349445343018\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 381/1200 GAN loss: 1.6596205234527588\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 382/1200 GAN loss: 1.7127959728240967\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 383/1200 GAN loss: 2.3072359561920166\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 384/1200 GAN loss: 2.440401077270508\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 385/1200 GAN loss: 2.4481570720672607\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 386/1200 GAN loss: 1.9811203479766846\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 387/1200 GAN loss: 1.8358004093170166\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 388/1200 GAN loss: 2.3978323936462402\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 389/1200 GAN loss: 2.2252867221832275\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 390/1200 GAN loss: 2.8009085655212402\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 391/1200 GAN loss: 2.716038703918457\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 392/1200 GAN loss: 2.0905373096466064\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 393/1200 GAN loss: 2.5569796562194824\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 394/1200 GAN loss: 3.585645914077759\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 395/1200 GAN loss: 2.9689841270446777\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 396/1200 GAN loss: 2.710480213165283\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 397/1200 GAN loss: 2.5145435333251953\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 398/1200 GAN loss: 3.230210065841675\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 399/1200 GAN loss: 3.009425640106201\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 400/1200 GAN loss: 3.083754062652588\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 401/1200 GAN loss: 3.1910593509674072\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 402/1200 GAN loss: 2.116938352584839\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 403/1200 GAN loss: 2.4355571269989014\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 404/1200 GAN loss: 3.488558769226074\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 405/1200 GAN loss: 2.2752532958984375\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 406/1200 GAN loss: 2.309122085571289\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 407/1200 GAN loss: 2.8050479888916016\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 408/1200 GAN loss: 2.2750301361083984\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 409/1200 GAN loss: 2.616664171218872\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 410/1200 GAN loss: 2.8220534324645996\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 411/1200 GAN loss: 2.9218244552612305\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 412/1200 GAN loss: 2.215608835220337\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 413/1200 GAN loss: 2.0514416694641113\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 414/1200 GAN loss: 2.505873203277588\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 415/1200 GAN loss: 2.0458626747131348\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 416/1200 GAN loss: 1.4452511072158813\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 417/1200 GAN loss: 1.7105205059051514\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 418/1200 GAN loss: 2.407007932662964\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 419/1200 GAN loss: 1.5781240463256836\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 420/1200 GAN loss: 1.8132823705673218\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 421/1200 GAN loss: 1.8766499757766724\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 422/1200 GAN loss: 1.17913818359375\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 423/1200 GAN loss: 2.076223373413086\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 424/1200 GAN loss: 1.5602810382843018\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 425/1200 GAN loss: 1.4995415210723877\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 426/1200 GAN loss: 1.695509433746338\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 427/1200 GAN loss: 1.610483169555664\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 428/1200 GAN loss: 1.5294804573059082\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 429/1200 GAN loss: 1.9742989540100098\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 430/1200 GAN loss: 1.2283644676208496\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 431/1200 GAN loss: 1.8117038011550903\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 432/1200 GAN loss: 1.8140454292297363\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 433/1200 GAN loss: 1.8761016130447388\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 434/1200 GAN loss: 1.613419532775879\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 435/1200 GAN loss: 1.6477231979370117\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 436/1200 GAN loss: 1.7212555408477783\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 437/1200 GAN loss: 1.5485150814056396\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 438/1200 GAN loss: 2.1294045448303223\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 439/1200 GAN loss: 1.92245614528656\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 440/1200 GAN loss: 2.0295491218566895\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 441/1200 GAN loss: 1.8619129657745361\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 442/1200 GAN loss: 1.7363563776016235\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 443/1200 GAN loss: 1.4365432262420654\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 444/1200 GAN loss: 1.6362388134002686\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 445/1200 GAN loss: 1.602210283279419\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 446/1200 GAN loss: 1.3545987606048584\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 447/1200 GAN loss: 2.152794361114502\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 448/1200 GAN loss: 1.520467758178711\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 449/1200 GAN loss: 1.798109769821167\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 450/1200 GAN loss: 1.947858452796936\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 451/1200 GAN loss: 1.5489065647125244\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 452/1200 GAN loss: 1.3939043283462524\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 453/1200 GAN loss: 1.6170573234558105\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 454/1200 GAN loss: 1.5194783210754395\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 455/1200 GAN loss: 1.7865839004516602\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 456/1200 GAN loss: 1.468340277671814\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 457/1200 GAN loss: 1.614933967590332\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 458/1200 GAN loss: 1.545274257659912\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 459/1200 GAN loss: 1.3358339071273804\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 460/1200 GAN loss: 1.408733606338501\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 461/1200 GAN loss: 1.4148720502853394\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 462/1200 GAN loss: 1.1417369842529297\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 463/1200 GAN loss: 1.4670945405960083\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 464/1200 GAN loss: 1.7910653352737427\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 465/1200 GAN loss: 1.0539519786834717\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 466/1200 GAN loss: 1.8881499767303467\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 467/1200 GAN loss: 1.3986533880233765\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 468/1200 GAN loss: 1.306917428970337\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 469/1200 GAN loss: 1.2484869956970215\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 470/1200 GAN loss: 1.363702416419983\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 471/1200 GAN loss: 1.4394261837005615\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 472/1200 GAN loss: 1.178673505783081\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 473/1200 GAN loss: 1.2926779985427856\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 474/1200 GAN loss: 1.9051191806793213\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 475/1200 GAN loss: 1.2337161302566528\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 476/1200 GAN loss: 1.0271625518798828\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 477/1200 GAN loss: 1.2147661447525024\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 478/1200 GAN loss: 1.530301809310913\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 479/1200 GAN loss: 1.023578405380249\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 480/1200 GAN loss: 1.0953037738800049\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 481/1200 GAN loss: 1.3605921268463135\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 482/1200 GAN loss: 1.0108466148376465\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 483/1200 GAN loss: 0.9223932027816772\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 484/1200 GAN loss: 1.1873117685317993\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 485/1200 GAN loss: 1.0273466110229492\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 486/1200 GAN loss: 0.9078986644744873\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 487/1200 GAN loss: 0.9272300601005554\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 488/1200 GAN loss: 1.0148636102676392\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 489/1200 GAN loss: 1.0697784423828125\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 490/1200 GAN loss: 1.0115530490875244\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 491/1200 GAN loss: 0.900559663772583\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 492/1200 GAN loss: 1.029334306716919\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 493/1200 GAN loss: 1.1204214096069336\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 494/1200 GAN loss: 1.2470673322677612\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 495/1200 GAN loss: 0.964408278465271\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 496/1200 GAN loss: 0.9622360467910767\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 497/1200 GAN loss: 1.0016471147537231\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 498/1200 GAN loss: 1.0150014162063599\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 499/1200 GAN loss: 1.1411969661712646\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 500/1200 GAN loss: 1.0821365118026733\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 501/1200 GAN loss: 0.9913514852523804\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 502/1200 GAN loss: 0.9542583227157593\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 503/1200 GAN loss: 1.1011011600494385\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 504/1200 GAN loss: 1.1391425132751465\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 505/1200 GAN loss: 1.3976573944091797\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 506/1200 GAN loss: 0.9855842590332031\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 507/1200 GAN loss: 0.9641246795654297\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 508/1200 GAN loss: 1.0600155591964722\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 509/1200 GAN loss: 1.182120442390442\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 510/1200 GAN loss: 1.0855143070220947\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 511/1200 GAN loss: 0.98847895860672\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 512/1200 GAN loss: 0.9698599576950073\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 513/1200 GAN loss: 1.193195104598999\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 514/1200 GAN loss: 1.3832423686981201\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 515/1200 GAN loss: 1.1703161001205444\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 516/1200 GAN loss: 1.0911844968795776\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 517/1200 GAN loss: 0.9081012010574341\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 518/1200 GAN loss: 1.2923119068145752\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 519/1200 GAN loss: 1.1101405620574951\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 520/1200 GAN loss: 1.0081937313079834\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 521/1200 GAN loss: 0.9933271408081055\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 522/1200 GAN loss: 1.2008674144744873\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 523/1200 GAN loss: 1.0296858549118042\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 524/1200 GAN loss: 1.0526267290115356\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 525/1200 GAN loss: 0.9965561032295227\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 526/1200 GAN loss: 1.0167003870010376\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 527/1200 GAN loss: 1.1918601989746094\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 528/1200 GAN loss: 1.1207082271575928\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 529/1200 GAN loss: 1.0619913339614868\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 530/1200 GAN loss: 1.0818414688110352\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 531/1200 GAN loss: 1.1315422058105469\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 532/1200 GAN loss: 1.3568768501281738\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 533/1200 GAN loss: 0.9709545969963074\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 534/1200 GAN loss: 0.9176368117332458\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 535/1200 GAN loss: 1.086307168006897\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 536/1200 GAN loss: 1.2483930587768555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 537/1200 GAN loss: 1.0974669456481934\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 538/1200 GAN loss: 0.9566640853881836\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 539/1200 GAN loss: 1.0192055702209473\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 540/1200 GAN loss: 1.0812733173370361\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 541/1200 GAN loss: 1.0309460163116455\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 542/1200 GAN loss: 1.0642236471176147\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 543/1200 GAN loss: 1.0295897722244263\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 544/1200 GAN loss: 1.0263766050338745\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 545/1200 GAN loss: 1.111784815788269\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 546/1200 GAN loss: 0.9526546597480774\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 547/1200 GAN loss: 0.9459863901138306\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 548/1200 GAN loss: 0.9131144285202026\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 549/1200 GAN loss: 1.0340392589569092\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 550/1200 GAN loss: 1.0071254968643188\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 551/1200 GAN loss: 1.0459816455841064\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 552/1200 GAN loss: 0.9103097915649414\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 553/1200 GAN loss: 0.9695663452148438\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 554/1200 GAN loss: 0.9349659085273743\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 555/1200 GAN loss: 1.0200018882751465\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 556/1200 GAN loss: 1.0064963102340698\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 557/1200 GAN loss: 0.951189398765564\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 558/1200 GAN loss: 1.0955066680908203\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 559/1200 GAN loss: 1.0930839776992798\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 560/1200 GAN loss: 0.7692527770996094\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 561/1200 GAN loss: 0.911178469657898\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 562/1200 GAN loss: 1.0317721366882324\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 563/1200 GAN loss: 0.9283895492553711\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 564/1200 GAN loss: 0.9949090480804443\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 565/1200 GAN loss: 1.017229676246643\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 566/1200 GAN loss: 0.9935934543609619\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 567/1200 GAN loss: 0.8698107004165649\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 568/1200 GAN loss: 0.9620121121406555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 569/1200 GAN loss: 1.0475691556930542\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 570/1200 GAN loss: 0.7971445918083191\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 571/1200 GAN loss: 0.778547465801239\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 572/1200 GAN loss: 0.8708972930908203\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 573/1200 GAN loss: 1.0002647638320923\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 574/1200 GAN loss: 0.990918755531311\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 575/1200 GAN loss: 0.9000363349914551\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 576/1200 GAN loss: 0.8038191199302673\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 577/1200 GAN loss: 0.892519474029541\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 578/1200 GAN loss: 0.877020537853241\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 579/1200 GAN loss: 0.9000288844108582\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 580/1200 GAN loss: 0.8799275159835815\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 581/1200 GAN loss: 0.9005454778671265\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 582/1200 GAN loss: 0.8663122653961182\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 583/1200 GAN loss: 0.8184250593185425\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 584/1200 GAN loss: 0.8535908460617065\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 585/1200 GAN loss: 0.8497813940048218\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 586/1200 GAN loss: 0.9293833374977112\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 587/1200 GAN loss: 0.8603056073188782\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 588/1200 GAN loss: 0.8301904201507568\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 589/1200 GAN loss: 0.8685739040374756\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 590/1200 GAN loss: 0.9016048908233643\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 591/1200 GAN loss: 0.8524767756462097\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 592/1200 GAN loss: 0.8518459796905518\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 593/1200 GAN loss: 0.8102782964706421\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 594/1200 GAN loss: 0.7619680166244507\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 595/1200 GAN loss: 0.7779121398925781\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 596/1200 GAN loss: 0.8042911291122437\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 597/1200 GAN loss: 0.9322750568389893\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 598/1200 GAN loss: 0.9119129180908203\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 599/1200 GAN loss: 0.7579233646392822\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 600/1200 GAN loss: 0.7567697763442993\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 601/1200 GAN loss: 0.830854058265686\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 602/1200 GAN loss: 0.8331909775733948\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 603/1200 GAN loss: 0.9312007427215576\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 604/1200 GAN loss: 0.8191961050033569\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 605/1200 GAN loss: 0.6784911155700684\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 606/1200 GAN loss: 0.7904013395309448\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 607/1200 GAN loss: 0.8532025218009949\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 608/1200 GAN loss: 0.887607753276825\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 609/1200 GAN loss: 0.8431916236877441\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 610/1200 GAN loss: 0.8623156547546387\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 611/1200 GAN loss: 0.8465631008148193\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 612/1200 GAN loss: 0.8445168733596802\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 613/1200 GAN loss: 0.8456350564956665\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 614/1200 GAN loss: 0.8825680017471313\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 615/1200 GAN loss: 0.894598126411438\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 616/1200 GAN loss: 0.8423359394073486\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 617/1200 GAN loss: 0.8291342854499817\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 618/1200 GAN loss: 0.8690371513366699\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 619/1200 GAN loss: 0.8967956304550171\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 620/1200 GAN loss: 0.8882482051849365\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 621/1200 GAN loss: 0.7536066770553589\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 622/1200 GAN loss: 0.794872522354126\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 623/1200 GAN loss: 0.8346881866455078\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 624/1200 GAN loss: 0.8598315715789795\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 625/1200 GAN loss: 0.9470146894454956\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 626/1200 GAN loss: 0.8689396381378174\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 627/1200 GAN loss: 0.7731096744537354\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 628/1200 GAN loss: 0.7807458639144897\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 629/1200 GAN loss: 0.8001328110694885\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 630/1200 GAN loss: 0.8993741273880005\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 631/1200 GAN loss: 0.9044743776321411\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 632/1200 GAN loss: 0.814306378364563\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 633/1200 GAN loss: 0.7542288303375244\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 634/1200 GAN loss: 0.797302782535553\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 635/1200 GAN loss: 0.77118980884552\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 636/1200 GAN loss: 0.8491945266723633\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 637/1200 GAN loss: 0.8089175224304199\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 638/1200 GAN loss: 0.7924894094467163\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 639/1200 GAN loss: 0.8020374774932861\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 640/1200 GAN loss: 0.8051959276199341\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 641/1200 GAN loss: 0.8226836919784546\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 642/1200 GAN loss: 0.8152909874916077\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 643/1200 GAN loss: 0.8152337074279785\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 644/1200 GAN loss: 0.7858074903488159\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 645/1200 GAN loss: 0.8426216244697571\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 646/1200 GAN loss: 0.8173533082008362\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 647/1200 GAN loss: 0.825092077255249\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 648/1200 GAN loss: 0.832038402557373\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 649/1200 GAN loss: 0.7980612516403198\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 650/1200 GAN loss: 0.7985648512840271\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 651/1200 GAN loss: 0.8355981707572937\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 652/1200 GAN loss: 0.8514108657836914\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 653/1200 GAN loss: 0.8491425514221191\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 654/1200 GAN loss: 0.8572381734848022\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 655/1200 GAN loss: 0.8651933670043945\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 656/1200 GAN loss: 0.7895445823669434\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 657/1200 GAN loss: 0.7821528315544128\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 658/1200 GAN loss: 0.7639137506484985\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 659/1200 GAN loss: 0.7814640998840332\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 660/1200 GAN loss: 0.8338857293128967\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 661/1200 GAN loss: 0.8598409295082092\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 662/1200 GAN loss: 0.8199535608291626\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 663/1200 GAN loss: 0.7840808033943176\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 664/1200 GAN loss: 0.7766155004501343\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 665/1200 GAN loss: 0.7745009064674377\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 666/1200 GAN loss: 0.7535458207130432\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 667/1200 GAN loss: 0.7762597799301147\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 668/1200 GAN loss: 0.7785736918449402\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 669/1200 GAN loss: 0.7885770797729492\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 670/1200 GAN loss: 0.7784935235977173\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 671/1200 GAN loss: 0.800044059753418\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 672/1200 GAN loss: 0.7788609266281128\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 673/1200 GAN loss: 0.783791720867157\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 674/1200 GAN loss: 0.747995138168335\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 675/1200 GAN loss: 0.7425341606140137\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 676/1200 GAN loss: 0.7393088340759277\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 677/1200 GAN loss: 0.798914909362793\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 678/1200 GAN loss: 0.7955962419509888\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 679/1200 GAN loss: 0.7961407899856567\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 680/1200 GAN loss: 0.7637723684310913\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 681/1200 GAN loss: 0.7561427354812622\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 682/1200 GAN loss: 0.7702686190605164\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 683/1200 GAN loss: 0.7885153293609619\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 684/1200 GAN loss: 0.8742002248764038\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 685/1200 GAN loss: 0.8353051543235779\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 686/1200 GAN loss: 0.7868934869766235\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 687/1200 GAN loss: 0.7220702171325684\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 688/1200 GAN loss: 0.6915091276168823\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 689/1200 GAN loss: 0.7887654304504395\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 690/1200 GAN loss: 0.9027878046035767\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 691/1200 GAN loss: 0.9009344577789307\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 692/1200 GAN loss: 0.7833167314529419\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 693/1200 GAN loss: 0.8013193011283875\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 694/1200 GAN loss: 0.710577666759491\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 695/1200 GAN loss: 0.7798808217048645\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 696/1200 GAN loss: 0.7917491793632507\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 697/1200 GAN loss: 0.7967631816864014\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 698/1200 GAN loss: 0.7764912247657776\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 699/1200 GAN loss: 0.7681277990341187\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 700/1200 GAN loss: 0.7947492003440857\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 701/1200 GAN loss: 0.8189836144447327\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 702/1200 GAN loss: 0.8102301359176636\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 703/1200 GAN loss: 0.7812029123306274\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 704/1200 GAN loss: 0.8007184267044067\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 705/1200 GAN loss: 0.791236400604248\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 706/1200 GAN loss: 0.7770587205886841\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 707/1200 GAN loss: 0.7964344620704651\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 708/1200 GAN loss: 0.7905834913253784\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 709/1200 GAN loss: 0.7607834339141846\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 710/1200 GAN loss: 0.7594836354255676\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 711/1200 GAN loss: 0.7358587980270386\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 712/1200 GAN loss: 0.7977529168128967\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 713/1200 GAN loss: 0.7924935817718506\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 714/1200 GAN loss: 0.7720418572425842\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 715/1200 GAN loss: 0.7475780844688416\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 716/1200 GAN loss: 0.7353731989860535\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 717/1200 GAN loss: 0.7642362713813782\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 718/1200 GAN loss: 0.7894962430000305\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 719/1200 GAN loss: 0.7804520130157471\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 720/1200 GAN loss: 0.7786813378334045\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 721/1200 GAN loss: 0.7432419061660767\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 722/1200 GAN loss: 0.7225024700164795\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 723/1200 GAN loss: 0.7095808386802673\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 724/1200 GAN loss: 0.7335944771766663\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 725/1200 GAN loss: 0.7445595860481262\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 726/1200 GAN loss: 0.7783063054084778\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 727/1200 GAN loss: 0.7338018417358398\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 728/1200 GAN loss: 0.7079715728759766\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 729/1200 GAN loss: 0.7040195465087891\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 730/1200 GAN loss: 0.6870769262313843\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 731/1200 GAN loss: 0.7152402400970459\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 732/1200 GAN loss: 0.7341288924217224\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 733/1200 GAN loss: 0.7569977045059204\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 734/1200 GAN loss: 0.7532657384872437\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 735/1200 GAN loss: 0.7374204993247986\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 736/1200 GAN loss: 0.7150903940200806\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 737/1200 GAN loss: 0.7028498649597168\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 738/1200 GAN loss: 0.6943361759185791\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 739/1200 GAN loss: 0.7036136388778687\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 740/1200 GAN loss: 0.7235588431358337\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 741/1200 GAN loss: 0.7422800064086914\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 742/1200 GAN loss: 0.7504295706748962\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 743/1200 GAN loss: 0.7406589388847351\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 744/1200 GAN loss: 0.7110585570335388\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 745/1200 GAN loss: 0.6871423721313477\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 746/1200 GAN loss: 0.6862507462501526\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 747/1200 GAN loss: 0.691051721572876\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 748/1200 GAN loss: 0.7234463691711426\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 749/1200 GAN loss: 0.7403608560562134\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 750/1200 GAN loss: 0.7532036304473877\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 751/1200 GAN loss: 0.7464626431465149\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 752/1200 GAN loss: 0.7212547659873962\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 753/1200 GAN loss: 0.7265900373458862\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 754/1200 GAN loss: 0.7510574460029602\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 755/1200 GAN loss: 0.7478979229927063\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 756/1200 GAN loss: 0.775864839553833\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 757/1200 GAN loss: 0.7788416147232056\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 758/1200 GAN loss: 0.7969561815261841\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 759/1200 GAN loss: 0.8247897624969482\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 760/1200 GAN loss: 0.7707844972610474\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 761/1200 GAN loss: 0.7782716155052185\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 762/1200 GAN loss: 0.7442359924316406\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 763/1200 GAN loss: 0.7793256044387817\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 764/1200 GAN loss: 0.8144030570983887\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 765/1200 GAN loss: 0.7646869421005249\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 766/1200 GAN loss: 0.7329059839248657\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 767/1200 GAN loss: 0.759580135345459\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 768/1200 GAN loss: 0.7852548360824585\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 769/1200 GAN loss: 0.7771354913711548\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 770/1200 GAN loss: 0.7700490355491638\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 771/1200 GAN loss: 0.7816193699836731\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 772/1200 GAN loss: 0.7803319096565247\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 773/1200 GAN loss: 0.771869421005249\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 774/1200 GAN loss: 0.7409934997558594\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 775/1200 GAN loss: 0.7476544380187988\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 776/1200 GAN loss: 0.7210427522659302\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 777/1200 GAN loss: 0.762031078338623\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 778/1200 GAN loss: 0.7877262830734253\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 779/1200 GAN loss: 0.7773900032043457\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 780/1200 GAN loss: 0.7551893591880798\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 781/1200 GAN loss: 0.7569624185562134\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 782/1200 GAN loss: 0.7487810850143433\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 783/1200 GAN loss: 0.7524421215057373\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 784/1200 GAN loss: 0.7394455075263977\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 785/1200 GAN loss: 0.7437213659286499\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 786/1200 GAN loss: 0.7506176233291626\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 787/1200 GAN loss: 0.758074939250946\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 788/1200 GAN loss: 0.7644814252853394\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 789/1200 GAN loss: 0.7602220177650452\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 790/1200 GAN loss: 0.7454803586006165\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 791/1200 GAN loss: 0.700426459312439\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 792/1200 GAN loss: 0.7175391912460327\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 793/1200 GAN loss: 0.776055634021759\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 794/1200 GAN loss: 0.7938480377197266\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 795/1200 GAN loss: 0.7770359516143799\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 796/1200 GAN loss: 0.7510484457015991\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 797/1200 GAN loss: 0.7207030057907104\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 798/1200 GAN loss: 0.7170994281768799\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 799/1200 GAN loss: 0.7475563883781433\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 800/1200 GAN loss: 0.6947324872016907\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 801/1200 GAN loss: 0.6833019256591797\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 802/1200 GAN loss: 0.7025611400604248\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 803/1200 GAN loss: 0.7363930940628052\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 804/1200 GAN loss: 0.7426842451095581\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 805/1200 GAN loss: 0.7322657704353333\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 806/1200 GAN loss: 0.7190141081809998\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 807/1200 GAN loss: 0.7109912633895874\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 808/1200 GAN loss: 0.701292097568512\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 809/1200 GAN loss: 0.6954153776168823\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 810/1200 GAN loss: 0.7051605582237244\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 811/1200 GAN loss: 0.6977723240852356\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 812/1200 GAN loss: 0.7053983211517334\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 813/1200 GAN loss: 0.7280631065368652\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 814/1200 GAN loss: 0.7144575119018555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 815/1200 GAN loss: 0.7072696685791016\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 816/1200 GAN loss: 0.6979118585586548\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 817/1200 GAN loss: 0.7114379405975342\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 818/1200 GAN loss: 0.7345660924911499\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 819/1200 GAN loss: 0.7623218297958374\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 820/1200 GAN loss: 0.7686703205108643\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 821/1200 GAN loss: 0.7600202560424805\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 822/1200 GAN loss: 0.7497378587722778\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 823/1200 GAN loss: 0.7293493747711182\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 824/1200 GAN loss: 0.7162703275680542\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 825/1200 GAN loss: 0.7261989712715149\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 826/1200 GAN loss: 0.7491292953491211\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 827/1200 GAN loss: 0.7302889823913574\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 828/1200 GAN loss: 0.7580008506774902\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 829/1200 GAN loss: 0.7428104877471924\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 830/1200 GAN loss: 0.7532234191894531\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 831/1200 GAN loss: 0.7548500895500183\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 832/1200 GAN loss: 0.7430344223976135\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 833/1200 GAN loss: 0.7540103793144226\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 834/1200 GAN loss: 0.7494062185287476\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 835/1200 GAN loss: 0.7515493631362915\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 836/1200 GAN loss: 0.7518143057823181\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 837/1200 GAN loss: 0.7273602485656738\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 838/1200 GAN loss: 0.7232427000999451\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 839/1200 GAN loss: 0.7234352827072144\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 840/1200 GAN loss: 0.7372369766235352\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 841/1200 GAN loss: 0.7525472640991211\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 842/1200 GAN loss: 0.7708556056022644\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 843/1200 GAN loss: 0.7682381272315979\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 844/1200 GAN loss: 0.7517061829566956\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 845/1200 GAN loss: 0.7329963445663452\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 846/1200 GAN loss: 0.7280896902084351\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 847/1200 GAN loss: 0.7220551371574402\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 848/1200 GAN loss: 0.718031644821167\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 849/1200 GAN loss: 0.7307038307189941\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 850/1200 GAN loss: 0.7370951175689697\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 851/1200 GAN loss: 0.7540135383605957\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 852/1200 GAN loss: 0.7607226371765137\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 853/1200 GAN loss: 0.7664271593093872\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 854/1200 GAN loss: 0.745060384273529\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 855/1200 GAN loss: 0.7339102029800415\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 856/1200 GAN loss: 0.6959516406059265\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 857/1200 GAN loss: 0.6926960349082947\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 858/1200 GAN loss: 0.6997412443161011\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 859/1200 GAN loss: 0.7189662456512451\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 860/1200 GAN loss: 0.7226202487945557\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 861/1200 GAN loss: 0.7226194143295288\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 862/1200 GAN loss: 0.7274751663208008\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 863/1200 GAN loss: 0.7317649126052856\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 864/1200 GAN loss: 0.7306292057037354\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 865/1200 GAN loss: 0.7253001928329468\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 866/1200 GAN loss: 0.7293279767036438\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 867/1200 GAN loss: 0.7170689702033997\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 868/1200 GAN loss: 0.7117986083030701\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 869/1200 GAN loss: 0.7209327816963196\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 870/1200 GAN loss: 0.7193624973297119\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 871/1200 GAN loss: 0.7247059941291809\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 872/1200 GAN loss: 0.72157883644104\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 873/1200 GAN loss: 0.7181016206741333\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 874/1200 GAN loss: 0.7192299962043762\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 875/1200 GAN loss: 0.7213497161865234\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 876/1200 GAN loss: 0.7251196503639221\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 877/1200 GAN loss: 0.7334564924240112\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 878/1200 GAN loss: 0.7216359376907349\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 879/1200 GAN loss: 0.7302407026290894\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 880/1200 GAN loss: 0.7369099855422974\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 881/1200 GAN loss: 0.7355377674102783\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 882/1200 GAN loss: 0.7439550757408142\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 883/1200 GAN loss: 0.718212902545929\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 884/1200 GAN loss: 0.7138710618019104\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 885/1200 GAN loss: 0.7118610739707947\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 886/1200 GAN loss: 0.722274124622345\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 887/1200 GAN loss: 0.7350260019302368\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 888/1200 GAN loss: 0.7276633381843567\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 889/1200 GAN loss: 0.7285975813865662\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 890/1200 GAN loss: 0.7193829417228699\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 891/1200 GAN loss: 0.713473916053772\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 892/1200 GAN loss: 0.7133338451385498\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 893/1200 GAN loss: 0.7167972326278687\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 894/1200 GAN loss: 0.7209158539772034\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 895/1200 GAN loss: 0.7257611751556396\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 896/1200 GAN loss: 0.7207249999046326\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 897/1200 GAN loss: 0.7206850051879883\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 898/1200 GAN loss: 0.7211016416549683\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 899/1200 GAN loss: 0.7174118161201477\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 900/1200 GAN loss: 0.6998007297515869\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 901/1200 GAN loss: 0.6979312896728516\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 902/1200 GAN loss: 0.7052582502365112\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 903/1200 GAN loss: 0.7028746008872986\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 904/1200 GAN loss: 0.7160941362380981\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 905/1200 GAN loss: 0.7185105085372925\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 906/1200 GAN loss: 0.7201502323150635\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 907/1200 GAN loss: 0.7137422561645508\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 908/1200 GAN loss: 0.714840292930603\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 909/1200 GAN loss: 0.7208650708198547\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 910/1200 GAN loss: 0.7040690779685974\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 911/1200 GAN loss: 0.7053142189979553\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 912/1200 GAN loss: 0.7092733979225159\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 913/1200 GAN loss: 0.7114439606666565\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 914/1200 GAN loss: 0.7169018983840942\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 915/1200 GAN loss: 0.7180262804031372\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 916/1200 GAN loss: 0.718124270439148\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 917/1200 GAN loss: 0.7167215943336487\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 918/1200 GAN loss: 0.7149357795715332\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 919/1200 GAN loss: 0.708831250667572\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 920/1200 GAN loss: 0.7128003835678101\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 921/1200 GAN loss: 0.7064344882965088\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 922/1200 GAN loss: 0.7009618282318115\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 923/1200 GAN loss: 0.6992597579956055\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 924/1200 GAN loss: 0.6988201141357422\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 925/1200 GAN loss: 0.7027121782302856\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 926/1200 GAN loss: 0.7095702290534973\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 927/1200 GAN loss: 0.7258892059326172\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 928/1200 GAN loss: 0.7233608365058899\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 929/1200 GAN loss: 0.7201200127601624\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 930/1200 GAN loss: 0.7146206498146057\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 931/1200 GAN loss: 0.715130090713501\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 932/1200 GAN loss: 0.7031984329223633\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 933/1200 GAN loss: 0.7110884189605713\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 934/1200 GAN loss: 0.706590473651886\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 935/1200 GAN loss: 0.6959163546562195\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 936/1200 GAN loss: 0.7034580707550049\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 937/1200 GAN loss: 0.7083746194839478\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 938/1200 GAN loss: 0.7089554071426392\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 939/1200 GAN loss: 0.7104216814041138\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 940/1200 GAN loss: 0.7133357524871826\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 941/1200 GAN loss: 0.7188137769699097\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 942/1200 GAN loss: 0.7145019173622131\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 943/1200 GAN loss: 0.7073469161987305\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 944/1200 GAN loss: 0.7032510638237\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 945/1200 GAN loss: 0.6975207924842834\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 946/1200 GAN loss: 0.7046560049057007\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 947/1200 GAN loss: 0.7066870927810669\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 948/1200 GAN loss: 0.7064253687858582\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 949/1200 GAN loss: 0.7115869522094727\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 950/1200 GAN loss: 0.7207340002059937\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 951/1200 GAN loss: 0.718055248260498\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 952/1200 GAN loss: 0.7076458930969238\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 953/1200 GAN loss: 0.6996152400970459\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 954/1200 GAN loss: 0.700218141078949\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 955/1200 GAN loss: 0.6964115500450134\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 956/1200 GAN loss: 0.7000107765197754\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 957/1200 GAN loss: 0.7027319073677063\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 958/1200 GAN loss: 0.7051113247871399\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 959/1200 GAN loss: 0.7016251087188721\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 960/1200 GAN loss: 0.701381504535675\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 961/1200 GAN loss: 0.7025931477546692\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 962/1200 GAN loss: 0.7048218250274658\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 963/1200 GAN loss: 0.71121746301651\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 964/1200 GAN loss: 0.7103054523468018\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 965/1200 GAN loss: 0.706125020980835\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 966/1200 GAN loss: 0.7030412554740906\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 967/1200 GAN loss: 0.6994417905807495\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 968/1200 GAN loss: 0.7051701545715332\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 969/1200 GAN loss: 0.710145890712738\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 970/1200 GAN loss: 0.7152376174926758\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 971/1200 GAN loss: 0.7091015577316284\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 972/1200 GAN loss: 0.7012614011764526\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 973/1200 GAN loss: 0.6993530988693237\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 974/1200 GAN loss: 0.696582555770874\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 975/1200 GAN loss: 0.6945400238037109\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 976/1200 GAN loss: 0.693073034286499\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 977/1200 GAN loss: 0.6949310302734375\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 978/1200 GAN loss: 0.7006844282150269\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 979/1200 GAN loss: 0.7056746482849121\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 980/1200 GAN loss: 0.7054144144058228\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 981/1200 GAN loss: 0.7089731693267822\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 982/1200 GAN loss: 0.7131776809692383\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 983/1200 GAN loss: 0.7314783334732056\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 984/1200 GAN loss: 0.7356386184692383\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 985/1200 GAN loss: 0.7236097455024719\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 986/1200 GAN loss: 0.7111712694168091\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 987/1200 GAN loss: 0.6892648935317993\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 988/1200 GAN loss: 0.6828498244285583\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 989/1200 GAN loss: 0.6895449161529541\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 990/1200 GAN loss: 0.7028318047523499\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 991/1200 GAN loss: 0.7164719104766846\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 992/1200 GAN loss: 0.7368271946907043\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 993/1200 GAN loss: 0.7259730100631714\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 994/1200 GAN loss: 0.7148429751396179\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 995/1200 GAN loss: 0.7035245895385742\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 996/1200 GAN loss: 0.7037779092788696\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 997/1200 GAN loss: 0.6923351287841797\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 998/1200 GAN loss: 0.6955258250236511\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 999/1200 GAN loss: 0.7023220062255859\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1000/1200 GAN loss: 0.7596027255058289\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1001/1200 GAN loss: 0.7750356793403625\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1002/1200 GAN loss: 0.7606763243675232\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1003/1200 GAN loss: 0.7380738854408264\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1004/1200 GAN loss: 0.6961767673492432\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1005/1200 GAN loss: 0.678864598274231\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1006/1200 GAN loss: 0.6814988851547241\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1007/1200 GAN loss: 0.7011181116104126\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1008/1200 GAN loss: 0.7283244729042053\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1009/1200 GAN loss: 0.7455353140830994\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1010/1200 GAN loss: 0.7405768036842346\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1011/1200 GAN loss: 0.7299260497093201\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1012/1200 GAN loss: 0.7110673189163208\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1013/1200 GAN loss: 0.7019578814506531\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1014/1200 GAN loss: 0.700960099697113\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1015/1200 GAN loss: 0.7037162780761719\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1016/1200 GAN loss: 0.7170416116714478\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1017/1200 GAN loss: 0.7277514934539795\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1018/1200 GAN loss: 0.7245132923126221\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1019/1200 GAN loss: 0.7185207605361938\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1020/1200 GAN loss: 0.7051637172698975\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1021/1200 GAN loss: 0.7050984501838684\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1022/1200 GAN loss: 0.7039185166358948\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1023/1200 GAN loss: 0.699967086315155\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1024/1200 GAN loss: 0.696668267250061\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1025/1200 GAN loss: 0.7057832479476929\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1026/1200 GAN loss: 0.721583366394043\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1027/1200 GAN loss: 0.7299097180366516\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1028/1200 GAN loss: 0.7301987409591675\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1029/1200 GAN loss: 0.7238751649856567\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1030/1200 GAN loss: 0.7129793167114258\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1031/1200 GAN loss: 0.7066354751586914\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1032/1200 GAN loss: 0.6982800960540771\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1033/1200 GAN loss: 0.6989384889602661\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1034/1200 GAN loss: 0.7095341682434082\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1035/1200 GAN loss: 0.7063131332397461\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1036/1200 GAN loss: 0.711280882358551\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1037/1200 GAN loss: 0.706767737865448\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1038/1200 GAN loss: 0.7114092111587524\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1039/1200 GAN loss: 0.709470272064209\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1040/1200 GAN loss: 0.7124226689338684\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1041/1200 GAN loss: 0.7110518217086792\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1042/1200 GAN loss: 0.7086813449859619\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1043/1200 GAN loss: 0.7055490016937256\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1044/1200 GAN loss: 0.7222781777381897\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1045/1200 GAN loss: 0.7285976409912109\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1046/1200 GAN loss: 0.7284872531890869\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1047/1200 GAN loss: 0.7202993631362915\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1048/1200 GAN loss: 0.7140304446220398\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1049/1200 GAN loss: 0.7090951204299927\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1050/1200 GAN loss: 0.7026376724243164\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1051/1200 GAN loss: 0.7052079439163208\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1052/1200 GAN loss: 0.7023441791534424\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1053/1200 GAN loss: 0.7093645334243774\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1054/1200 GAN loss: 0.7089318037033081\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1055/1200 GAN loss: 0.7113025188446045\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1056/1200 GAN loss: 0.7128661274909973\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1057/1200 GAN loss: 0.7064933776855469\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1058/1200 GAN loss: 0.7043728232383728\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1059/1200 GAN loss: 0.7042382955551147\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1060/1200 GAN loss: 0.7011280059814453\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1061/1200 GAN loss: 0.7057880163192749\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1062/1200 GAN loss: 0.7123928070068359\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1063/1200 GAN loss: 0.7154446244239807\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1064/1200 GAN loss: 0.7177647948265076\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1065/1200 GAN loss: 0.716354250907898\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1066/1200 GAN loss: 0.7128221988677979\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1067/1200 GAN loss: 0.7127383947372437\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1068/1200 GAN loss: 0.7055197954177856\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1069/1200 GAN loss: 0.6963039040565491\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1070/1200 GAN loss: 0.6958970427513123\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1071/1200 GAN loss: 0.7042835354804993\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1072/1200 GAN loss: 0.7129435539245605\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1073/1200 GAN loss: 0.7139449119567871\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1074/1200 GAN loss: 0.7080453038215637\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1075/1200 GAN loss: 0.706567645072937\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1076/1200 GAN loss: 0.7064456939697266\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1077/1200 GAN loss: 0.7051828503608704\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1078/1200 GAN loss: 0.704953134059906\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1079/1200 GAN loss: 0.7094686031341553\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1080/1200 GAN loss: 0.707483172416687\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1081/1200 GAN loss: 0.7062095999717712\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1082/1200 GAN loss: 0.71234130859375\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1083/1200 GAN loss: 0.7162483930587769\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1084/1200 GAN loss: 0.7221437692642212\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1085/1200 GAN loss: 0.7179456949234009\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1086/1200 GAN loss: 0.7146565318107605\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1087/1200 GAN loss: 0.7107032537460327\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1088/1200 GAN loss: 0.704359769821167\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1089/1200 GAN loss: 0.7035211324691772\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1090/1200 GAN loss: 0.7028506994247437\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1091/1200 GAN loss: 0.708177924156189\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1092/1200 GAN loss: 0.7061406373977661\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1093/1200 GAN loss: 0.7079979777336121\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1094/1200 GAN loss: 0.7091197967529297\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1095/1200 GAN loss: 0.7098733186721802\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1096/1200 GAN loss: 0.7088533043861389\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1097/1200 GAN loss: 0.7102696895599365\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1098/1200 GAN loss: 0.7071918845176697\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1099/1200 GAN loss: 0.707218587398529\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1100/1200 GAN loss: 0.7077040672302246\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1101/1200 GAN loss: 0.7061553597450256\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1102/1200 GAN loss: 0.7079241275787354\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1103/1200 GAN loss: 0.7119584083557129\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1104/1200 GAN loss: 0.7129755616188049\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1105/1200 GAN loss: 0.7092664837837219\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1106/1200 GAN loss: 0.7078494429588318\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1107/1200 GAN loss: 0.7092239856719971\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1108/1200 GAN loss: 0.7106664776802063\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1109/1200 GAN loss: 0.7075693011283875\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1110/1200 GAN loss: 0.7107378840446472\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1111/1200 GAN loss: 0.7027265429496765\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1112/1200 GAN loss: 0.7036172151565552\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1113/1200 GAN loss: 0.7053517699241638\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1114/1200 GAN loss: 0.7094271183013916\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1115/1200 GAN loss: 0.7084897756576538\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1116/1200 GAN loss: 0.7087105512619019\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1117/1200 GAN loss: 0.7044039964675903\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1118/1200 GAN loss: 0.6986652612686157\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1119/1200 GAN loss: 0.6958814263343811\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1120/1200 GAN loss: 0.7019684314727783\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1121/1200 GAN loss: 0.7092869281768799\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1122/1200 GAN loss: 0.7124425172805786\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1123/1200 GAN loss: 0.7095993161201477\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1124/1200 GAN loss: 0.7091413736343384\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1125/1200 GAN loss: 0.7040496468544006\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1126/1200 GAN loss: 0.7024896740913391\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1127/1200 GAN loss: 0.7026003003120422\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1128/1200 GAN loss: 0.7026136517524719\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1129/1200 GAN loss: 0.702764630317688\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1130/1200 GAN loss: 0.7021383047103882\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1131/1200 GAN loss: 0.7030839323997498\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1132/1200 GAN loss: 0.7012056708335876\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1133/1200 GAN loss: 0.7018241882324219\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1134/1200 GAN loss: 0.7019511461257935\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1135/1200 GAN loss: 0.7041430473327637\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1136/1200 GAN loss: 0.7049407362937927\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1137/1200 GAN loss: 0.7051509022712708\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1138/1200 GAN loss: 0.7058151960372925\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1139/1200 GAN loss: 0.7053443193435669\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1140/1200 GAN loss: 0.7022683620452881\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1141/1200 GAN loss: 0.7032426595687866\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1142/1200 GAN loss: 0.7088467478752136\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1143/1200 GAN loss: 0.710820734500885\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1144/1200 GAN loss: 0.7148411870002747\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1145/1200 GAN loss: 0.7116649746894836\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1146/1200 GAN loss: 0.7072304487228394\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1147/1200 GAN loss: 0.7074123024940491\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1148/1200 GAN loss: 0.706357479095459\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1149/1200 GAN loss: 0.7021458148956299\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1150/1200 GAN loss: 0.7019590139389038\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1151/1200 GAN loss: 0.7015602588653564\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1152/1200 GAN loss: 0.706179141998291\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1153/1200 GAN loss: 0.709730863571167\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1154/1200 GAN loss: 0.7056254148483276\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1155/1200 GAN loss: 0.7042700052261353\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1156/1200 GAN loss: 0.7035249471664429\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1157/1200 GAN loss: 0.7014021277427673\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1158/1200 GAN loss: 0.6993834972381592\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1159/1200 GAN loss: 0.7000200748443604\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1160/1200 GAN loss: 0.7013843059539795\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1161/1200 GAN loss: 0.7025278806686401\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1162/1200 GAN loss: 0.7039949893951416\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1163/1200 GAN loss: 0.7059950828552246\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1164/1200 GAN loss: 0.7062544822692871\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1165/1200 GAN loss: 0.7052828073501587\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1166/1200 GAN loss: 0.7041597366333008\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1167/1200 GAN loss: 0.702556312084198\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1168/1200 GAN loss: 0.7020682692527771\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1169/1200 GAN loss: 0.6971753239631653\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1170/1200 GAN loss: 0.6985814571380615\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1171/1200 GAN loss: 0.6991336345672607\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1172/1200 GAN loss: 0.7012882828712463\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1173/1200 GAN loss: 0.7036395072937012\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1174/1200 GAN loss: 0.700537919998169\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1175/1200 GAN loss: 0.7042372822761536\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1176/1200 GAN loss: 0.7038785815238953\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1177/1200 GAN loss: 0.7049579620361328\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1178/1200 GAN loss: 0.7066014409065247\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1179/1200 GAN loss: 0.7074946165084839\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1180/1200 GAN loss: 0.7014616131782532\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1181/1200 GAN loss: 0.6993964910507202\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1182/1200 GAN loss: 0.693555474281311\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1183/1200 GAN loss: 0.6944904327392578\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1184/1200 GAN loss: 0.6964826583862305\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1185/1200 GAN loss: 0.6960654854774475\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1186/1200 GAN loss: 0.699006199836731\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1187/1200 GAN loss: 0.7008320093154907\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1188/1200 GAN loss: 0.7006557583808899\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1189/1200 GAN loss: 0.7009527087211609\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1190/1200 GAN loss: 0.7010678052902222\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1191/1200 GAN loss: 0.7010185122489929\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1192/1200 GAN loss: 0.7002825736999512\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1193/1200 GAN loss: 0.7015324831008911\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1194/1200 GAN loss: 0.6957631707191467\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 1195/1200 GAN loss: 0.693472146987915\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1196/1200 GAN loss: 0.6946475505828857\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1197/1200 GAN loss: 0.6944913864135742\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1198/1200 GAN loss: 0.701262354850769\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 1199/1200 GAN loss: 0.7044317722320557\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1200/1200 GAN loss: 0.7054157257080078\n"
     ]
    }
   ],
   "source": [
    "train(generator, discriminator, GAN, dataset_numpy_scaled, epochs=1200, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5b52e92b-0808-410d-9600-99fedbe8ab52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img0.jpeg',\n",
       " 'img1000.jpeg',\n",
       " 'img1199.jpeg',\n",
       " 'img200.jpeg',\n",
       " 'img400.jpeg',\n",
       " 'img600.jpeg',\n",
       " 'img800.jpeg']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path ='./data/data/1__GAN/'\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d0f47196-6124-4ea3-ab41-7c921550a027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = [np.asarray(Image.open(path+imgname)) for imgname in os.listdir(path)]\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "1f53ef2c-f847-4f37-a7c8-107ff0f63e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Füge optional weitere Inhalte zu.\n",
    "fig, axs = plt.subplots(1, 7, figsize=(10, 6))\n",
    "fig.tight_layout(pad=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "img_names = os.listdir(path)\n",
    "\n",
    "\n",
    "for i in range(len(images)):\n",
    "    axs[i].set_title(img_names[i])\n",
    "    axs[i].imshow(images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1cb142-38d2-46b5-ad68-8e3061174c94",
   "metadata": {},
   "source": [
    "<h1>Zweites Beispiel - 2 Verschiedene Formen</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8efc500-2565-4951-b551-c967e1d654db",
   "metadata": {},
   "source": [
    "Diesmal wollen wir 2 Formen und ein größeres Netz nutzen. Das Vorgehen ist ähnlich aber Umfangreicher.\n",
    "\n",
    "Um ein GAN zu erstellen, das verschiedene Klassen unterscheidet, nutzen wir Embeddings, um den Input des Generators zu verändern.<br>\n",
    "Zusätzlich können wir Dropouts nutzen. Bei komplexeren Formen und größeren Netzen nutzen wir auch CNN Layers. Weitere ist optional.\n",
    "- Hier wieder als ANN. CNN ist üblich bei GANs.\n",
    "- Es ist üblich, das man für das Training mehrere Klassen nutzt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc97c06-e37b-4215-8047-29bcd3c339db",
   "metadata": {},
   "source": [
    "<h2>Dataset</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5764b1e-bdc4-4523-b996-90fd41491c09",
   "metadata": {},
   "source": [
    "Für den Versuch erstellen wir 2 Formen- einmal mit einem Zeichenprogramm und einmal mit Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80c16e8b-4e8e-40df-a8b3-3b7eebb70274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeichne Bild mit Numpy.\n",
    "def create_image_2(color:int=1) -> np.array:\n",
    "    image = np.zeros((20, 20))  # 2D Matrix, 20x20 Pixel.\n",
    "    # img [yloc, xloc]\n",
    "    image[1:17, 3]  = 1  \n",
    "    image[1:17, 4]  = 1  \n",
    "    image[2:10, 10] = 1  \n",
    "    image[2:10, 11] = 1  \n",
    "    image[9, 4:10]  = 1  \n",
    "    image[10, 4:12] = 1 \n",
    "    image[1, 4:17]  = 1  \n",
    "    image[2, 4:17]  = 1 \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa68f50a-73d4-4561-ae5f-8bdd391defcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = create_image_2()\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(img)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fab0d0bf-7dcc-4e59-b44e-87b552b81ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fa640bd070>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "img = np.asarray(Image.open('./data/datasets/two_shapes/shape.jpg'))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcccc0f-b135-4b0f-9291-a66fe32f9042",
   "metadata": {},
   "source": [
    "Dann erstellen wir ein Encoding für die Labels als Input für das Embedding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "037209e8-058a-4bde-aecd-15e47e7191a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle Labels für Embeddings:\n",
    "# - Mit 0 und 1 soll die Klasse \"ausgewählt\" werden.\n",
    "form_labels    = ['Form A', 'Form B']\n",
    "encoded_labels = {'Form A':0, 'Form B': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaa357ef-f893-46cd-b85d-14299496b448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle Dataset aus n-Samples \n",
    "def numpy_dataset(n:int):  # Shape A, Label 0\n",
    "    return np.array([create_image_2() for _ in range(n)])\n",
    "\n",
    "def load_img_array(n:int):  # Shape B, Label 1\n",
    "    return np.array([np.array(Image.open('./data/datasets/two_shapes/shape.jpg').convert('L')) for _ in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0fea138-f0d4-4894-8126-f152273cf24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20, 20) (1000, 20, 20)\n"
     ]
    }
   ],
   "source": [
    "size = 1000  # n-Samples\n",
    "\n",
    "dataset_shape_A = numpy_dataset(  size)\n",
    "#dataset_shape_B = load_img_array( size)\n",
    "dataset_shape_B = np.array([create_image() for _ in range(size)])  # Shape L \n",
    "\n",
    "print(dataset_shape_A.shape, dataset_shape_B.shape )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9002a63d-1232-4e7c-a0ea-806429bef07b",
   "metadata": {},
   "source": [
    "plt.matshow(dataset_shape_A[0])  # Zeige Form. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8c8b0f2-69b5-4f27-b484-f639bd6a85a5",
   "metadata": {},
   "source": [
    "plt.matshow(dataset_shape_B[0])  # Zeige Form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d5334d7-808d-466d-b901-efac094c956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape. # \n",
    "dataset_shape_A = dataset_shape_A.reshape(size, 20, 20, 1).astype('float')\n",
    "dataset_shape_B = dataset_shape_B.reshape(size, 20, 20, 1).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de2a1448-f09c-4602-932b-f5b89a8b292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skaliere. #\n",
    "dataset_shape_A = ( dataset_shape_A - 0.5 ) / 0.5\n",
    "dataset_shape_B = ( dataset_shape_B - 0.5 ) / 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98a57e5a-810a-472f-a795-882a28f71ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_shape_A[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf36ab1b-04c6-4681-9245-63bf7e19da49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_shape_B[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "101c2119-0c5d-4f45-861d-18c6751cce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle Dataset mit A und B. \n",
    "dataset_shapes = []\n",
    "dataset_shapes.extend(dataset_shape_A)  # Label 0\n",
    "dataset_shapes.extend(dataset_shape_B)  # Label 1\n",
    "dataset_shapes = np.array(dataset_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e161d5a9-1e88-43a2-a516-61e038fec41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle Dataset Labels # \n",
    "dataset_labels = np.asarray([encoded_labels[label]   for label in form_labels  for _ in range(size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35fe85ed-1a11-4c64-af46-3e606e549a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_labels) == size*2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5580cbfe-8e32-4925-8763-09435da939de",
   "metadata": {},
   "source": [
    "Das ist eine Möglichkeit Datasets zu erstellen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc7f32-53cc-4c69-b057-00925d9f437d",
   "metadata": {},
   "source": [
    "<h2>Erstelle Model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a0f207-5521-4b61-8520-1dd657f0ddec",
   "metadata": {},
   "source": [
    "Diesmal hat das Model Embeddings, um mehrere Klassen abzudecken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "966624c5-563c-490e-8eb2-26d6188e5991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle Generator für Bildgenerierung # \n",
    "def create_generator(num_classes: int = 2):\n",
    "    # Hier Nutzen wir zusätzlich Embeddings Layers.\n",
    "\n",
    "    noise_input = tf.keras.Input(shape=(100,))  # Startbild: 100 Pixel Vektor. \n",
    "    label_input = tf.keras.Input(shape=(1,), dtype='int32') # Klassen Label wie z. B. Form_A, Form_B als 0 und 1. \n",
    "    \n",
    "    label_embedding = tf.keras.layers.Embedding(input_dim=2, output_dim=100)(label_input)\n",
    "    label_embedding = tf.keras.layers.Flatten()(label_embedding)\n",
    "    model_input     = tf.keras.layers.multiply([noise_input, label_embedding])  # Multipliziere, damit haben die Labels direkten Einfluss.\n",
    "    \n",
    "    # --------- #\n",
    "    \"\"\" \n",
    "    gen_ann = tf.keras.Sequential()\n",
    "    gen_ann.add( tf.keras.layers.Dense(units=300, activation='relu'))\n",
    "    gen_ann.add( tf.keras.layers.BatchNormalization())\n",
    "    gen_ann.add( tf.keras.layers.Dense(units=500, activation='relu'))\n",
    "\n",
    "    \"\"\"\n",
    "    # Nutze andere Herangehensweise. \n",
    "    # - Dieser Ansatz funktioniert besser. \n",
    "    x = tf.keras.layers.Dense(units=300, activation='relu')(model_input)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(units=500, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(units=800, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = tf.keras.layers.Dense(units=450, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(units=20*20, activation='tanh')(x)\n",
    "    output = tf.keras.layers.Reshape((20, 20, 1))(x)\n",
    "   \n",
    "    return tf.keras.Model([noise_input, label_input], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "777602dd-60bb-41f6-860c-57ae4a1f56e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 102ms/step\n"
     ]
    }
   ],
   "source": [
    "# Teste, ob Aufbau funktioniert. \n",
    "generator = create_generator(2)\n",
    "noise     = np.random.normal(0, 1, (1, 100))\n",
    "\n",
    "fake_labels = np.random.randint(0, 2, 1)\n",
    "fake_images = generator.predict([noise, fake_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35fedd6a-6b96-43ab-935c-36eb3c3a8eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator(num_classes: int = 2):\n",
    "    # Hier Nutzen wir zusätzlich Embeddings.\n",
    "    \n",
    "    image_input = tf.keras.Input(shape=(20, 20, 1))  # Bild als Input\n",
    "    label_input = tf.keras.Input(shape=(1,), dtype='int32')  # Auch hier kommen die Labels zum Einsatz. \n",
    "    \n",
    "    label_embedding = tf.keras.layers.Embedding(input_dim=2, output_dim=20*20)(label_input)\n",
    "    label_embedding = tf.keras.layers.Flatten()(label_embedding)\n",
    "    label_embedding = tf.keras.layers.Reshape((20, 20, 1))(label_embedding) \n",
    "    # Durch Konkatenation: Passt Bild auch zum Label? \n",
    "    model_input = tf.keras.layers.concatenate([image_input, label_embedding])   \n",
    "    # --------- #\n",
    "    x = tf.keras.layers.Flatten(input_shape=(20,20, 1))(model_input)\n",
    "    x = tf.keras.layers.Dense(500, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(700, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(550, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(320, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(150, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(75, activation='relu')(x)\n",
    "    output =  tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "   \n",
    "    return tf.keras.Model([image_input, label_input], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e2e92ab-651e-4c0c-be02-a215f9f58b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5010406]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Teste, ob Aufbau funktioniert. \n",
    "discriminator = create_discriminator()\n",
    "\n",
    "generator = create_generator(2)\n",
    "noise     = np.random.normal(0, 1, (1, 100))\n",
    "\n",
    "fake_labels = np.random.randint(0, 2, 1)\n",
    "fake_images = generator.predict([noise, fake_labels])\n",
    "\n",
    "discriminator.predict([fake_images, fake_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27ae3916-2621-40d6-86e9-d1603238d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = create_discriminator()\n",
    "discriminator.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss      = 'binary_crossentropy',\n",
    "    metrics   = 'accuracy'\n",
    ")\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Erstelle GAN # \n",
    "generator = create_generator()\n",
    "gan_input   = tf.keras.layers.Input(shape=(100,))  \n",
    "label_input = tf.keras.Input(shape=(1,), dtype='int32')\n",
    "\n",
    "generated_image = generator([gan_input, label_input])\n",
    "gan_output = discriminator([generated_image, label_input])\n",
    "\n",
    "GAN = tf.keras.Model([gan_input, label_input], gan_output)\n",
    "GAN.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "GAN.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7982ad7a-d419-4e86-871a-0965d5e96c6c",
   "metadata": {},
   "source": [
    "<h2>Training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e42fc3f-19f8-45ea-a511-269ff3a2b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsschleife #\n",
    "# - Sehr ähnlicher Aufbau mit kleinen Unterschieden. \n",
    "def train(generator, discriminator, gan, train_images, train_labels, epochs, batch_size, num_classes:int=2):\n",
    "    \n",
    "    half_batch = int(batch_size / 2)  # Ausgleich an Samples. \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        #  Discriminator #\n",
    "        idx = np.random.randint(0, train_images.shape[0], half_batch)  # Index für Img und Label. \n",
    "        real_images = train_images[idx]  # Wie bisher.\n",
    "        real_labels = train_labels[idx]  # Nehme Labels dazu. \n",
    "        noise       = np.random.normal(0, 1, (half_batch, 100))  # Startbild.\n",
    "        fake_labels = np.random.randint(0, num_classes, half_batch)  # Wie Bisher.\n",
    "        fake_images = generator.predict([noise, fake_labels])  # Nehme Labels dazu. \n",
    "\n",
    "        loss_real = discriminator.train_on_batch([real_images, real_labels], np.ones(  (half_batch, 1)))  # Wie bisher\n",
    "        loss_fake = discriminator.train_on_batch([fake_images, fake_labels], np.zeros( (half_batch, 1)))  # Wie bisher.\n",
    "        d_loss = 0.5 * np.add(loss_real, loss_fake)  # Wie bisher.\n",
    "\n",
    "        # Generator #\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))  # Startbild\n",
    "        labels= np.random.randint(0, num_classes, batch_size)  # Labels\n",
    "        y = np.ones((batch_size, 1))\n",
    "        g_loss = gan.train_on_batch([noise, labels], y)\n",
    "\n",
    "        # Manuelle Ausgabe.:\n",
    "        print(f\"Epoche: {epoch + 1}/{epochs} GAN loss: {g_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "864126db-3b01-4d95-9d45-655867fb50b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 102ms/step\n",
      "Epoche: 1/1400 GAN loss: 0.5761806964874268\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 2/1400 GAN loss: 0.3762649595737457\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 3/1400 GAN loss: 0.23936408758163452\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 4/1400 GAN loss: 0.19176720082759857\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 5/1400 GAN loss: 0.1752128005027771\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 6/1400 GAN loss: 0.23676997423171997\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 7/1400 GAN loss: 0.2515065670013428\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 8/1400 GAN loss: 0.4967023730278015\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 9/1400 GAN loss: 1.100185751914978\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 10/1400 GAN loss: 2.6646571159362793\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 11/1400 GAN loss: 6.142308712005615\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 12/1400 GAN loss: 4.071322441101074\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 13/1400 GAN loss: 2.4299404621124268\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 14/1400 GAN loss: 1.152793049812317\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 15/1400 GAN loss: 1.1472663879394531\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 16/1400 GAN loss: 1.809934139251709\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 17/1400 GAN loss: 1.851593017578125\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 18/1400 GAN loss: 1.6535687446594238\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 19/1400 GAN loss: 3.1372010707855225\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 20/1400 GAN loss: 4.187175750732422\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 21/1400 GAN loss: 4.954721450805664\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 22/1400 GAN loss: 4.7935004234313965\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 23/1400 GAN loss: 7.957552909851074\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 24/1400 GAN loss: 7.1788835525512695\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 25/1400 GAN loss: 8.386734008789062\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 26/1400 GAN loss: 9.66592788696289\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 27/1400 GAN loss: 11.561124801635742\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 28/1400 GAN loss: 11.215875625610352\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 29/1400 GAN loss: 15.023351669311523\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 30/1400 GAN loss: 14.479170799255371\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 31/1400 GAN loss: 15.580205917358398\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 32/1400 GAN loss: 16.494861602783203\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 33/1400 GAN loss: 19.810497283935547\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 34/1400 GAN loss: 23.00676727294922\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 35/1400 GAN loss: 23.545440673828125\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 36/1400 GAN loss: 25.500001907348633\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 37/1400 GAN loss: 26.23885726928711\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 38/1400 GAN loss: 24.208866119384766\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 39/1400 GAN loss: 26.55340576171875\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 40/1400 GAN loss: 24.916515350341797\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 41/1400 GAN loss: 30.244956970214844\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 42/1400 GAN loss: 4.634389877319336\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 43/1400 GAN loss: 0.0023301823530346155\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 44/1400 GAN loss: 7.081268016406739e-09\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 45/1400 GAN loss: 6.925363749132885e-08\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 46/1400 GAN loss: 0.0012441477738320827\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 47/1400 GAN loss: 0.19285443425178528\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 48/1400 GAN loss: 1.763118028640747\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 49/1400 GAN loss: 3.0516412258148193\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 50/1400 GAN loss: 5.034416198730469\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 51/1400 GAN loss: 6.048408031463623\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 52/1400 GAN loss: 6.611498832702637\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 53/1400 GAN loss: 6.892266273498535\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 54/1400 GAN loss: 5.425686836242676\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 55/1400 GAN loss: 6.539597034454346\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 56/1400 GAN loss: 4.967182159423828\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 57/1400 GAN loss: 5.088075637817383\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 58/1400 GAN loss: 5.622838020324707\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 59/1400 GAN loss: 5.220348834991455\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 60/1400 GAN loss: 4.544922351837158\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 61/1400 GAN loss: 4.237669944763184\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 62/1400 GAN loss: 3.45206880569458\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 63/1400 GAN loss: 4.403313636779785\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 64/1400 GAN loss: 3.1776723861694336\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 65/1400 GAN loss: 2.7852652072906494\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 66/1400 GAN loss: 3.2168898582458496\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 67/1400 GAN loss: 2.1455636024475098\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 68/1400 GAN loss: 1.7078616619110107\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 69/1400 GAN loss: 1.069570779800415\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 70/1400 GAN loss: 2.419729232788086\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 71/1400 GAN loss: 3.18636417388916\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 72/1400 GAN loss: 2.2955989837646484\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 73/1400 GAN loss: 4.464141845703125\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 74/1400 GAN loss: 6.890364646911621\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 75/1400 GAN loss: 2.54779052734375\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 76/1400 GAN loss: 0.968818187713623\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 77/1400 GAN loss: 2.1122024059295654\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 78/1400 GAN loss: 2.3346986770629883\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 79/1400 GAN loss: 3.438159465789795\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 80/1400 GAN loss: 2.1487624645233154\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 81/1400 GAN loss: 1.532024621963501\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 82/1400 GAN loss: 0.6912687420845032\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 83/1400 GAN loss: 4.626775741577148\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 84/1400 GAN loss: 4.962531089782715\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 85/1400 GAN loss: 0.5804913640022278\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 86/1400 GAN loss: 0.5339751839637756\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 87/1400 GAN loss: 0.6971197724342346\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 88/1400 GAN loss: 0.19900745153427124\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 89/1400 GAN loss: 0.5540140867233276\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 90/1400 GAN loss: 0.5766350030899048\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 91/1400 GAN loss: 0.725884735584259\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 92/1400 GAN loss: 1.9641300439834595\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 93/1400 GAN loss: 2.465416669845581\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 94/1400 GAN loss: 1.364414095878601\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 95/1400 GAN loss: 2.812674045562744\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 96/1400 GAN loss: 1.6623409986495972\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 97/1400 GAN loss: 1.830532431602478\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 98/1400 GAN loss: 0.7080559134483337\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 99/1400 GAN loss: 1.4745314121246338\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 100/1400 GAN loss: 4.186297416687012\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 101/1400 GAN loss: 6.445294380187988\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 102/1400 GAN loss: 7.5649213790893555\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 103/1400 GAN loss: 1.7148432731628418\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 104/1400 GAN loss: 8.958900451660156\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 105/1400 GAN loss: 3.678122043609619\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 106/1400 GAN loss: 7.431828022003174\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 107/1400 GAN loss: 10.221080780029297\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 108/1400 GAN loss: 12.394805908203125\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 109/1400 GAN loss: 6.084135055541992\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 110/1400 GAN loss: 5.9324750900268555\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 111/1400 GAN loss: 8.524123191833496\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 112/1400 GAN loss: 21.8917293548584\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 113/1400 GAN loss: 7.055078029632568\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 114/1400 GAN loss: 9.800644874572754\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 115/1400 GAN loss: 10.497161865234375\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 116/1400 GAN loss: 14.138269424438477\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 117/1400 GAN loss: 13.58956241607666\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 118/1400 GAN loss: 9.111644744873047\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 119/1400 GAN loss: 11.031417846679688\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 120/1400 GAN loss: 11.446836471557617\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 121/1400 GAN loss: 14.94058609008789\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 122/1400 GAN loss: 14.878274917602539\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 123/1400 GAN loss: 25.31359100341797\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 124/1400 GAN loss: 28.696340560913086\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 125/1400 GAN loss: 27.130229949951172\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 126/1400 GAN loss: 23.398746490478516\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 127/1400 GAN loss: 16.814172744750977\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 128/1400 GAN loss: 21.386322021484375\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 129/1400 GAN loss: 28.684803009033203\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 130/1400 GAN loss: 30.382003784179688\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 131/1400 GAN loss: 27.799419403076172\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 132/1400 GAN loss: 24.59347152709961\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 133/1400 GAN loss: 28.517555236816406\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 134/1400 GAN loss: 26.059608459472656\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 135/1400 GAN loss: 30.70182991027832\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 136/1400 GAN loss: 29.495922088623047\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 137/1400 GAN loss: 28.441314697265625\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 138/1400 GAN loss: 24.020883560180664\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 139/1400 GAN loss: 30.647401809692383\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 140/1400 GAN loss: 34.775264739990234\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 141/1400 GAN loss: 15.899314880371094\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 142/1400 GAN loss: 19.782634735107422\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 143/1400 GAN loss: 21.300289154052734\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 144/1400 GAN loss: 29.146251678466797\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 145/1400 GAN loss: 28.162269592285156\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 146/1400 GAN loss: 19.223726272583008\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 147/1400 GAN loss: 14.425287246704102\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 148/1400 GAN loss: 16.231874465942383\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 149/1400 GAN loss: 14.446297645568848\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 150/1400 GAN loss: 17.79192352294922\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 151/1400 GAN loss: 20.1119384765625\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 152/1400 GAN loss: 24.099925994873047\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 153/1400 GAN loss: 18.94002914428711\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 154/1400 GAN loss: 20.903165817260742\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 155/1400 GAN loss: 21.565448760986328\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 156/1400 GAN loss: 14.298959732055664\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 157/1400 GAN loss: 10.355470657348633\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 158/1400 GAN loss: 11.507194519042969\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 159/1400 GAN loss: 13.932039260864258\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 160/1400 GAN loss: 13.732632637023926\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 161/1400 GAN loss: 14.09945297241211\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 162/1400 GAN loss: 12.055807113647461\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 163/1400 GAN loss: 15.906084060668945\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 164/1400 GAN loss: 9.441856384277344\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 165/1400 GAN loss: 13.658340454101562\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 166/1400 GAN loss: 16.30917739868164\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 167/1400 GAN loss: 24.00067138671875\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 168/1400 GAN loss: 7.379138946533203\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 169/1400 GAN loss: 5.458658218383789\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 170/1400 GAN loss: 10.089645385742188\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 171/1400 GAN loss: 8.77492904663086\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 172/1400 GAN loss: 6.405227184295654\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 173/1400 GAN loss: 7.7914628982543945\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 174/1400 GAN loss: 8.813060760498047\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 175/1400 GAN loss: 13.299625396728516\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 176/1400 GAN loss: 18.655120849609375\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 177/1400 GAN loss: 13.56562614440918\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 178/1400 GAN loss: 17.242279052734375\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 179/1400 GAN loss: 20.08847427368164\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 180/1400 GAN loss: 14.181114196777344\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 181/1400 GAN loss: 12.94651985168457\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 182/1400 GAN loss: 11.08210563659668\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 183/1400 GAN loss: 14.592352867126465\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 184/1400 GAN loss: 13.803640365600586\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 185/1400 GAN loss: 10.045842170715332\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 186/1400 GAN loss: 12.541511535644531\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 187/1400 GAN loss: 19.066139221191406\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 188/1400 GAN loss: 22.523780822753906\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 189/1400 GAN loss: 20.168739318847656\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 190/1400 GAN loss: 14.071554183959961\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 191/1400 GAN loss: 14.324217796325684\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 192/1400 GAN loss: 19.300920486450195\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 193/1400 GAN loss: 25.33102035522461\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 194/1400 GAN loss: 22.53508949279785\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 195/1400 GAN loss: 20.587291717529297\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 196/1400 GAN loss: 26.52665138244629\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 197/1400 GAN loss: 16.155139923095703\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 198/1400 GAN loss: 15.494770050048828\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 199/1400 GAN loss: 10.509733200073242\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 200/1400 GAN loss: 6.92466926574707\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 201/1400 GAN loss: 7.718297481536865\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 202/1400 GAN loss: 7.165074825286865\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 203/1400 GAN loss: 8.577840805053711\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 204/1400 GAN loss: 8.4946870803833\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 205/1400 GAN loss: 8.186698913574219\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 206/1400 GAN loss: 7.082697868347168\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 207/1400 GAN loss: 3.9038028717041016\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 208/1400 GAN loss: 5.853099822998047\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 209/1400 GAN loss: 9.592710494995117\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 210/1400 GAN loss: 15.864585876464844\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 211/1400 GAN loss: 16.226882934570312\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 212/1400 GAN loss: 21.33376693725586\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 213/1400 GAN loss: 22.77196502685547\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 214/1400 GAN loss: 29.643085479736328\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 215/1400 GAN loss: 23.961130142211914\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 216/1400 GAN loss: 24.04483413696289\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 217/1400 GAN loss: 30.500839233398438\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoche: 218/1400 GAN loss: 23.77571678161621\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 219/1400 GAN loss: 27.18828582763672\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 220/1400 GAN loss: 27.598997116088867\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 221/1400 GAN loss: 23.387502670288086\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 222/1400 GAN loss: 13.259320259094238\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 223/1400 GAN loss: 24.202428817749023\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 224/1400 GAN loss: 28.769134521484375\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 225/1400 GAN loss: 70.3768310546875\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 226/1400 GAN loss: 26.481719970703125\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 227/1400 GAN loss: 34.19919967651367\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 228/1400 GAN loss: 34.15917205810547\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 229/1400 GAN loss: 40.573917388916016\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 230/1400 GAN loss: 50.240936279296875\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 231/1400 GAN loss: 54.54320526123047\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 232/1400 GAN loss: 54.69841766357422\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 233/1400 GAN loss: 58.23371124267578\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 234/1400 GAN loss: 58.07992935180664\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 235/1400 GAN loss: 60.35856246948242\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 236/1400 GAN loss: 58.640525817871094\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 237/1400 GAN loss: 59.59894561767578\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 238/1400 GAN loss: 52.767669677734375\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 239/1400 GAN loss: 49.58395767211914\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 240/1400 GAN loss: 44.30644607543945\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 241/1400 GAN loss: 43.767112731933594\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 242/1400 GAN loss: 27.856643676757812\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 243/1400 GAN loss: 35.6512451171875\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 244/1400 GAN loss: 25.688133239746094\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 245/1400 GAN loss: 32.74958419799805\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 246/1400 GAN loss: 32.74055480957031\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 247/1400 GAN loss: 42.21809768676758\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 248/1400 GAN loss: 49.2891731262207\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 249/1400 GAN loss: 42.02314758300781\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 250/1400 GAN loss: 48.58006286621094\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 251/1400 GAN loss: 40.671600341796875\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 252/1400 GAN loss: 39.85371017456055\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 253/1400 GAN loss: 26.582311630249023\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 254/1400 GAN loss: 45.2059440612793\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 255/1400 GAN loss: 47.85036087036133\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 256/1400 GAN loss: 45.84143829345703\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 257/1400 GAN loss: 43.159263610839844\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 258/1400 GAN loss: 52.05126190185547\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 259/1400 GAN loss: 53.29150390625\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 260/1400 GAN loss: 65.44574737548828\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 261/1400 GAN loss: 43.78321075439453\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 262/1400 GAN loss: 36.863739013671875\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 263/1400 GAN loss: 43.65123748779297\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 264/1400 GAN loss: 48.66537857055664\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 265/1400 GAN loss: 63.775489807128906\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 266/1400 GAN loss: 46.711265563964844\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 267/1400 GAN loss: 39.81768035888672\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 268/1400 GAN loss: 26.895292282104492\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 269/1400 GAN loss: 33.81742477416992\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 270/1400 GAN loss: 32.58395767211914\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 271/1400 GAN loss: 43.31618881225586\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 272/1400 GAN loss: 62.416831970214844\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 273/1400 GAN loss: 42.31608963012695\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 274/1400 GAN loss: 37.90923309326172\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 275/1400 GAN loss: 59.24482727050781\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 276/1400 GAN loss: 59.400970458984375\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 277/1400 GAN loss: 51.7923469543457\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 278/1400 GAN loss: 49.12657165527344\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 279/1400 GAN loss: 35.821720123291016\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 280/1400 GAN loss: 64.30238342285156\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 281/1400 GAN loss: 67.77530670166016\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 282/1400 GAN loss: 34.249549865722656\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 283/1400 GAN loss: 28.362733840942383\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 284/1400 GAN loss: 31.12395477294922\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 285/1400 GAN loss: 35.14818572998047\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 286/1400 GAN loss: 41.09184265136719\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 287/1400 GAN loss: 44.49610900878906\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 288/1400 GAN loss: 39.39349365234375\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 289/1400 GAN loss: 37.0739631652832\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 290/1400 GAN loss: 40.81061553955078\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 291/1400 GAN loss: 27.1422119140625\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 292/1400 GAN loss: 30.335866928100586\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 293/1400 GAN loss: 22.084789276123047\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 294/1400 GAN loss: 20.028553009033203\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 295/1400 GAN loss: 28.1892032623291\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 296/1400 GAN loss: 28.515647888183594\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 297/1400 GAN loss: 23.28130340576172\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 298/1400 GAN loss: 20.604671478271484\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 299/1400 GAN loss: 24.888898849487305\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 300/1400 GAN loss: 18.99454116821289\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 301/1400 GAN loss: 26.057567596435547\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 302/1400 GAN loss: 28.113779067993164\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 303/1400 GAN loss: 27.287498474121094\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 304/1400 GAN loss: 24.276939392089844\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 305/1400 GAN loss: 24.48238754272461\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 306/1400 GAN loss: 15.803425788879395\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 307/1400 GAN loss: 17.872539520263672\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 308/1400 GAN loss: 14.25401782989502\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 309/1400 GAN loss: 16.867822647094727\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 310/1400 GAN loss: 11.019591331481934\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 311/1400 GAN loss: 15.302244186401367\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 312/1400 GAN loss: 13.260435104370117\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 313/1400 GAN loss: 12.859613418579102\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 314/1400 GAN loss: 10.003353118896484\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 315/1400 GAN loss: 11.945158004760742\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 316/1400 GAN loss: 9.61939525604248\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 317/1400 GAN loss: 21.46930694580078\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 318/1400 GAN loss: 15.214884757995605\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 319/1400 GAN loss: 10.51685905456543\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 320/1400 GAN loss: 12.969581604003906\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 321/1400 GAN loss: 6.929095268249512\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 322/1400 GAN loss: 12.56722640991211\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 323/1400 GAN loss: 5.664698600769043\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 324/1400 GAN loss: 7.7600860595703125\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 325/1400 GAN loss: 14.29486083984375\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 326/1400 GAN loss: 27.082260131835938\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 327/1400 GAN loss: 35.27799606323242\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 328/1400 GAN loss: 42.757076263427734\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 329/1400 GAN loss: 46.626670837402344\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 330/1400 GAN loss: 49.310211181640625\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 331/1400 GAN loss: 47.426048278808594\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 332/1400 GAN loss: 41.26673889160156\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 333/1400 GAN loss: 34.80410385131836\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 334/1400 GAN loss: 36.085296630859375\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 335/1400 GAN loss: 23.386470794677734\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 336/1400 GAN loss: 18.771377563476562\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 337/1400 GAN loss: 14.600570678710938\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 338/1400 GAN loss: 25.703632354736328\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 339/1400 GAN loss: 24.954631805419922\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 340/1400 GAN loss: 19.191904067993164\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 341/1400 GAN loss: 22.574718475341797\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 342/1400 GAN loss: 14.003923416137695\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 343/1400 GAN loss: 25.322132110595703\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 344/1400 GAN loss: 28.972572326660156\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 345/1400 GAN loss: 21.476844787597656\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 346/1400 GAN loss: 41.80291748046875\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 347/1400 GAN loss: 7.713364601135254\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 348/1400 GAN loss: 19.835147857666016\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 349/1400 GAN loss: 30.637100219726562\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 350/1400 GAN loss: 35.84260940551758\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 351/1400 GAN loss: 42.872222900390625\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 352/1400 GAN loss: 35.54499053955078\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 353/1400 GAN loss: 21.774187088012695\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 354/1400 GAN loss: 21.36493682861328\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 355/1400 GAN loss: 23.491004943847656\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 356/1400 GAN loss: 12.815746307373047\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 357/1400 GAN loss: 8.46041202545166\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 358/1400 GAN loss: 2.45985746383667\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 359/1400 GAN loss: 6.655613899230957\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 360/1400 GAN loss: 3.338387966156006\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 361/1400 GAN loss: 5.5472540855407715\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 362/1400 GAN loss: 4.552905559539795\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 363/1400 GAN loss: 12.926403999328613\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 364/1400 GAN loss: 9.938887596130371\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 365/1400 GAN loss: 9.344137191772461\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 366/1400 GAN loss: 7.456173419952393\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 367/1400 GAN loss: 7.437652111053467\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 368/1400 GAN loss: 5.324748992919922\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 369/1400 GAN loss: 3.9110615253448486\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 370/1400 GAN loss: 7.31208610534668\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 371/1400 GAN loss: 10.633817672729492\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 372/1400 GAN loss: 7.406375885009766\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 373/1400 GAN loss: 7.324743270874023\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 374/1400 GAN loss: 11.119575500488281\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 375/1400 GAN loss: 8.910487174987793\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 376/1400 GAN loss: 7.617507457733154\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 377/1400 GAN loss: 14.033989906311035\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 378/1400 GAN loss: 17.395523071289062\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 379/1400 GAN loss: 18.534404754638672\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 380/1400 GAN loss: 30.106136322021484\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 381/1400 GAN loss: 18.108928680419922\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 382/1400 GAN loss: 20.64731216430664\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 383/1400 GAN loss: 20.28006362915039\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 384/1400 GAN loss: 11.15042495727539\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 385/1400 GAN loss: 20.592769622802734\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 386/1400 GAN loss: 15.067276000976562\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 387/1400 GAN loss: 9.394119262695312\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 388/1400 GAN loss: 25.65411376953125\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 389/1400 GAN loss: 13.434223175048828\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 390/1400 GAN loss: 16.751672744750977\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 391/1400 GAN loss: 17.40846824645996\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 392/1400 GAN loss: 29.30134391784668\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 393/1400 GAN loss: 25.789676666259766\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 394/1400 GAN loss: 22.574575424194336\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 395/1400 GAN loss: 22.18679428100586\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 396/1400 GAN loss: 19.807533264160156\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 397/1400 GAN loss: 13.2229642868042\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 398/1400 GAN loss: 15.132181167602539\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 399/1400 GAN loss: 19.668502807617188\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 400/1400 GAN loss: 26.727323532104492\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 401/1400 GAN loss: 25.31756591796875\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 402/1400 GAN loss: 19.65823745727539\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 403/1400 GAN loss: 25.968198776245117\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 404/1400 GAN loss: 22.94108009338379\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 405/1400 GAN loss: 20.209171295166016\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 406/1400 GAN loss: 24.0485897064209\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 407/1400 GAN loss: 19.435121536254883\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 408/1400 GAN loss: 21.35354232788086\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 409/1400 GAN loss: 15.82518196105957\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 410/1400 GAN loss: 12.006601333618164\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 411/1400 GAN loss: 20.16185760498047\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 412/1400 GAN loss: 28.1656494140625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 413/1400 GAN loss: 7.4163079261779785\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 414/1400 GAN loss: 13.107206344604492\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 415/1400 GAN loss: 18.591827392578125\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 416/1400 GAN loss: 25.317623138427734\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 417/1400 GAN loss: 31.346534729003906\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 418/1400 GAN loss: 34.832637786865234\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 419/1400 GAN loss: 33.76259994506836\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 420/1400 GAN loss: 43.10624694824219\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 421/1400 GAN loss: 42.11418151855469\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 422/1400 GAN loss: 40.521522521972656\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 423/1400 GAN loss: 53.07698059082031\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 424/1400 GAN loss: 54.45126724243164\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 425/1400 GAN loss: 50.85226821899414\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 426/1400 GAN loss: 46.065879821777344\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 427/1400 GAN loss: 51.39213943481445\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 428/1400 GAN loss: 38.01258087158203\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 429/1400 GAN loss: 57.133514404296875\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 430/1400 GAN loss: 62.515625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 431/1400 GAN loss: 41.2558708190918\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 432/1400 GAN loss: 22.079713821411133\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 433/1400 GAN loss: 35.28331756591797\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 434/1400 GAN loss: 24.020553588867188\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 435/1400 GAN loss: 33.610565185546875\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 436/1400 GAN loss: 22.25934600830078\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 437/1400 GAN loss: 37.206939697265625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 438/1400 GAN loss: 33.79608154296875\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 439/1400 GAN loss: 37.02082824707031\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 440/1400 GAN loss: 37.16350555419922\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 441/1400 GAN loss: 18.64451789855957\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 442/1400 GAN loss: 20.245208740234375\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 443/1400 GAN loss: 25.27291488647461\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 444/1400 GAN loss: 23.12384033203125\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 445/1400 GAN loss: 16.425722122192383\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 446/1400 GAN loss: 24.872356414794922\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 447/1400 GAN loss: 29.9884033203125\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 448/1400 GAN loss: 16.54943084716797\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 449/1400 GAN loss: 21.05681610107422\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 450/1400 GAN loss: 17.52243423461914\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 451/1400 GAN loss: 36.77568054199219\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 452/1400 GAN loss: 37.808441162109375\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 453/1400 GAN loss: 34.56359100341797\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 454/1400 GAN loss: 37.638099670410156\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 455/1400 GAN loss: 21.655536651611328\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 456/1400 GAN loss: 28.626941680908203\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 457/1400 GAN loss: 32.842254638671875\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 458/1400 GAN loss: 30.906089782714844\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 459/1400 GAN loss: 32.77031326293945\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 460/1400 GAN loss: 32.431297302246094\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 461/1400 GAN loss: 31.20395851135254\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 462/1400 GAN loss: 22.469955444335938\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 463/1400 GAN loss: 21.94411849975586\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 464/1400 GAN loss: 20.93075942993164\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 465/1400 GAN loss: 27.886096954345703\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 466/1400 GAN loss: 13.563129425048828\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 467/1400 GAN loss: 17.80179786682129\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 468/1400 GAN loss: 15.595474243164062\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 469/1400 GAN loss: 30.078664779663086\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 470/1400 GAN loss: 35.74436569213867\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 471/1400 GAN loss: 65.00548553466797\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 472/1400 GAN loss: 16.545635223388672\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 473/1400 GAN loss: 16.431528091430664\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 474/1400 GAN loss: 25.141935348510742\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 475/1400 GAN loss: 60.27528381347656\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 476/1400 GAN loss: 29.608505249023438\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 477/1400 GAN loss: 42.67613983154297\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 478/1400 GAN loss: 21.109012603759766\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 479/1400 GAN loss: 19.984130859375\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 480/1400 GAN loss: 16.497394561767578\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 481/1400 GAN loss: 26.358200073242188\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 482/1400 GAN loss: 27.510507583618164\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 483/1400 GAN loss: 25.841135025024414\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 484/1400 GAN loss: 32.79366683959961\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 485/1400 GAN loss: 28.532852172851562\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 486/1400 GAN loss: 25.430452346801758\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 487/1400 GAN loss: 40.15365982055664\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 488/1400 GAN loss: 36.161964416503906\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 489/1400 GAN loss: 54.1424560546875\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 490/1400 GAN loss: 62.967384338378906\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 491/1400 GAN loss: 83.53756713867188\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 492/1400 GAN loss: 72.67955017089844\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 493/1400 GAN loss: 64.12716674804688\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 494/1400 GAN loss: 78.23741149902344\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 495/1400 GAN loss: 58.11835861206055\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 496/1400 GAN loss: 63.18748474121094\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 497/1400 GAN loss: 57.638004302978516\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 498/1400 GAN loss: 50.53147888183594\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 499/1400 GAN loss: 56.92064666748047\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 500/1400 GAN loss: 46.952056884765625\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 501/1400 GAN loss: 43.860557556152344\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 502/1400 GAN loss: 37.11690139770508\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 503/1400 GAN loss: 40.02751541137695\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 504/1400 GAN loss: 44.60590362548828\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 505/1400 GAN loss: 35.03851318359375\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 506/1400 GAN loss: 49.5103759765625\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 507/1400 GAN loss: 59.86555099487305\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 508/1400 GAN loss: 32.63087463378906\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 509/1400 GAN loss: 33.875694274902344\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 510/1400 GAN loss: 44.23808288574219\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 511/1400 GAN loss: 41.078575134277344\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 512/1400 GAN loss: 41.951255798339844\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 513/1400 GAN loss: 37.95559310913086\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 514/1400 GAN loss: 33.713008880615234\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 515/1400 GAN loss: 42.1012077331543\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 516/1400 GAN loss: 25.20294952392578\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 517/1400 GAN loss: 30.510574340820312\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 518/1400 GAN loss: 33.887428283691406\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 519/1400 GAN loss: 34.7916259765625\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 520/1400 GAN loss: 31.157028198242188\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 521/1400 GAN loss: 28.204345703125\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 522/1400 GAN loss: 27.004579544067383\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 523/1400 GAN loss: 25.368488311767578\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 524/1400 GAN loss: 33.60564422607422\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 525/1400 GAN loss: 16.43508529663086\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 526/1400 GAN loss: 16.093027114868164\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 527/1400 GAN loss: 18.805877685546875\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 528/1400 GAN loss: 27.073293685913086\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 529/1400 GAN loss: 19.34769058227539\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 530/1400 GAN loss: 26.991657257080078\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 531/1400 GAN loss: 9.553947448730469\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 532/1400 GAN loss: 19.291528701782227\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 533/1400 GAN loss: 42.328006744384766\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 534/1400 GAN loss: 55.99928665161133\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 535/1400 GAN loss: 92.00238037109375\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 536/1400 GAN loss: 97.87351989746094\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 537/1400 GAN loss: 112.16178131103516\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 538/1400 GAN loss: 107.908447265625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 539/1400 GAN loss: 100.78253173828125\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 540/1400 GAN loss: 92.78057098388672\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 541/1400 GAN loss: 98.6123046875\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 542/1400 GAN loss: 90.58580017089844\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 543/1400 GAN loss: 111.81217193603516\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 544/1400 GAN loss: 85.8450927734375\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 545/1400 GAN loss: 76.00146484375\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 546/1400 GAN loss: 65.36485290527344\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 547/1400 GAN loss: 86.18111419677734\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 548/1400 GAN loss: 52.0380859375\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 549/1400 GAN loss: 60.79435729980469\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 550/1400 GAN loss: 38.94952392578125\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 551/1400 GAN loss: 45.34754943847656\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 552/1400 GAN loss: 44.548255920410156\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 553/1400 GAN loss: 46.80471420288086\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 554/1400 GAN loss: 56.73883056640625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 555/1400 GAN loss: 0.015089668333530426\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 556/1400 GAN loss: 0.024275172501802444\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 557/1400 GAN loss: 0.12173302471637726\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 558/1400 GAN loss: 1.6532952785491943\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 559/1400 GAN loss: 1.816286563873291\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 560/1400 GAN loss: 0.979457437992096\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 561/1400 GAN loss: 0.7781583070755005\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 562/1400 GAN loss: 0.8561221361160278\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 563/1400 GAN loss: 0.9963512420654297\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 564/1400 GAN loss: 0.7162444591522217\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 565/1400 GAN loss: 1.478232502937317\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 566/1400 GAN loss: 1.4259142875671387\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 567/1400 GAN loss: 0.8912471532821655\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 568/1400 GAN loss: 1.083101511001587\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 569/1400 GAN loss: 3.0270779132843018\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 570/1400 GAN loss: 3.7459969520568848\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 571/1400 GAN loss: 5.519051551818848\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 572/1400 GAN loss: 7.451895236968994\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 573/1400 GAN loss: 7.905647277832031\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 574/1400 GAN loss: 6.7233686447143555\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 575/1400 GAN loss: 6.318404197692871\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 576/1400 GAN loss: 10.956897735595703\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 577/1400 GAN loss: 14.516962051391602\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 578/1400 GAN loss: 21.442176818847656\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 579/1400 GAN loss: 11.562906265258789\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 580/1400 GAN loss: 9.151917457580566\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 581/1400 GAN loss: 11.12893295288086\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 582/1400 GAN loss: 13.647934913635254\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 583/1400 GAN loss: 28.182815551757812\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 584/1400 GAN loss: 58.99894714355469\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 585/1400 GAN loss: 0.21286514401435852\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 586/1400 GAN loss: 0.024800289422273636\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 587/1400 GAN loss: 0.03874344006180763\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 588/1400 GAN loss: 0.22015736997127533\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 589/1400 GAN loss: 2.877166271209717\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 590/1400 GAN loss: 1.7098383903503418\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 591/1400 GAN loss: 0.3951999545097351\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 592/1400 GAN loss: 0.3118859529495239\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 593/1400 GAN loss: 0.5119611620903015\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 594/1400 GAN loss: 0.9719459414482117\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 595/1400 GAN loss: 1.163404941558838\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 596/1400 GAN loss: 0.9322859048843384\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 597/1400 GAN loss: 0.6336804628372192\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 598/1400 GAN loss: 0.47028279304504395\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 599/1400 GAN loss: 0.4697984755039215\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 600/1400 GAN loss: 0.5343508124351501\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 601/1400 GAN loss: 0.6227734088897705\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 602/1400 GAN loss: 0.7254986763000488\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 603/1400 GAN loss: 0.7773280739784241\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 604/1400 GAN loss: 0.7947911620140076\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 605/1400 GAN loss: 0.7594032287597656\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 606/1400 GAN loss: 0.7130086421966553\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 607/1400 GAN loss: 0.6763190031051636\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 608/1400 GAN loss: 0.6425921320915222\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 609/1400 GAN loss: 0.6150410175323486\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 610/1400 GAN loss: 0.6132939457893372\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 611/1400 GAN loss: 0.6583805084228516\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 612/1400 GAN loss: 0.6746503710746765\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 613/1400 GAN loss: 0.7156426906585693\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 614/1400 GAN loss: 0.7285639047622681\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 615/1400 GAN loss: 0.7343463897705078\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 616/1400 GAN loss: 0.7100048065185547\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 617/1400 GAN loss: 0.7128500938415527\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 618/1400 GAN loss: 0.6622170209884644\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 619/1400 GAN loss: 0.6651337146759033\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 620/1400 GAN loss: 0.6357272863388062\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 621/1400 GAN loss: 0.6287684440612793\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 622/1400 GAN loss: 0.6522984504699707\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 623/1400 GAN loss: 0.6625438928604126\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 624/1400 GAN loss: 0.7032849192619324\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 625/1400 GAN loss: 0.7353560924530029\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 626/1400 GAN loss: 0.7493220567703247\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 627/1400 GAN loss: 0.7592037916183472\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 628/1400 GAN loss: 0.7240726351737976\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 629/1400 GAN loss: 0.6839220523834229\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 630/1400 GAN loss: 0.6565162539482117\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 631/1400 GAN loss: 0.6834810972213745\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 632/1400 GAN loss: 0.7631667852401733\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 633/1400 GAN loss: 0.7905361652374268\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 634/1400 GAN loss: 0.7678160071372986\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 635/1400 GAN loss: 0.8124561309814453\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 636/1400 GAN loss: 0.8900927901268005\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 637/1400 GAN loss: 0.8959209322929382\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 638/1400 GAN loss: 1.0553028583526611\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 639/1400 GAN loss: 1.433638095855713\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 640/1400 GAN loss: 1.4844609498977661\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 641/1400 GAN loss: 2.5711586475372314\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 642/1400 GAN loss: 4.353005409240723\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 643/1400 GAN loss: 5.318815231323242\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 644/1400 GAN loss: 5.420037269592285\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 645/1400 GAN loss: 11.22103500366211\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 646/1400 GAN loss: 11.620911598205566\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 647/1400 GAN loss: 14.350814819335938\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 648/1400 GAN loss: 15.64102840423584\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 649/1400 GAN loss: 15.26677417755127\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 650/1400 GAN loss: 15.251060485839844\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 651/1400 GAN loss: 24.945966720581055\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 652/1400 GAN loss: 30.807363510131836\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 653/1400 GAN loss: 8.346336364746094\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 654/1400 GAN loss: 4.108852386474609\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 655/1400 GAN loss: 2.378502130508423\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 656/1400 GAN loss: 2.373051166534424\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 657/1400 GAN loss: 5.622811794281006\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 658/1400 GAN loss: 4.609330177307129\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 659/1400 GAN loss: 7.659259796142578\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 660/1400 GAN loss: 5.17039680480957\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 661/1400 GAN loss: 7.257842063903809\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 662/1400 GAN loss: 6.909421920776367\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 663/1400 GAN loss: 10.824474334716797\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 664/1400 GAN loss: 13.237014770507812\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 665/1400 GAN loss: 11.152996063232422\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 666/1400 GAN loss: 8.903274536132812\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 667/1400 GAN loss: 7.859785079956055\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 668/1400 GAN loss: 8.973371505737305\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 669/1400 GAN loss: 10.568824768066406\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 670/1400 GAN loss: 5.92030668258667\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 671/1400 GAN loss: 12.265382766723633\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 672/1400 GAN loss: 6.8838791847229\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 673/1400 GAN loss: 6.82879638671875\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 674/1400 GAN loss: 5.691598892211914\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 675/1400 GAN loss: 14.38725471496582\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 676/1400 GAN loss: 13.539173126220703\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 677/1400 GAN loss: 3.3191757202148438\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 678/1400 GAN loss: 1.4024920463562012\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 679/1400 GAN loss: 0.7955342531204224\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 680/1400 GAN loss: 1.3225703239440918\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 681/1400 GAN loss: 1.366729974746704\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 682/1400 GAN loss: 2.0758416652679443\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 683/1400 GAN loss: 0.9217933416366577\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 684/1400 GAN loss: 0.5605316758155823\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 685/1400 GAN loss: 0.5062869787216187\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 686/1400 GAN loss: 0.6358426809310913\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 687/1400 GAN loss: 0.7700493335723877\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 688/1400 GAN loss: 0.8289437294006348\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 689/1400 GAN loss: 0.799408495426178\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 690/1400 GAN loss: 0.7380129098892212\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 691/1400 GAN loss: 0.74012291431427\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 692/1400 GAN loss: 0.627659022808075\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 693/1400 GAN loss: 0.5980729460716248\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 694/1400 GAN loss: 0.5825332403182983\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 695/1400 GAN loss: 0.6099084615707397\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 696/1400 GAN loss: 0.7090804576873779\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 697/1400 GAN loss: 0.6561363935470581\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 698/1400 GAN loss: 0.6496448516845703\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 699/1400 GAN loss: 0.6536270380020142\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 700/1400 GAN loss: 0.6676995754241943\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 701/1400 GAN loss: 0.6417018175125122\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 702/1400 GAN loss: 0.6993157863616943\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 703/1400 GAN loss: 0.6191444396972656\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 704/1400 GAN loss: 0.6737185716629028\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 705/1400 GAN loss: 0.7598477602005005\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 706/1400 GAN loss: 0.6813520789146423\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 707/1400 GAN loss: 0.7780758142471313\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 708/1400 GAN loss: 0.765261709690094\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 709/1400 GAN loss: 0.7436635494232178\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 710/1400 GAN loss: 0.7987171411514282\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 711/1400 GAN loss: 1.0350761413574219\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 712/1400 GAN loss: 1.1206843852996826\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 713/1400 GAN loss: 1.4355709552764893\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 714/1400 GAN loss: 1.846293330192566\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 715/1400 GAN loss: 1.9109313488006592\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 716/1400 GAN loss: 2.358774185180664\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 717/1400 GAN loss: 1.846919059753418\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 718/1400 GAN loss: 1.6022887229919434\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 719/1400 GAN loss: 2.219700574874878\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 720/1400 GAN loss: 3.1594223976135254\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 721/1400 GAN loss: 5.50799560546875\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 722/1400 GAN loss: 4.7740936279296875\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 723/1400 GAN loss: 6.647762298583984\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 724/1400 GAN loss: 6.137185096740723\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 725/1400 GAN loss: 6.197196006774902\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 726/1400 GAN loss: 7.384416580200195\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 727/1400 GAN loss: 9.51740837097168\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 728/1400 GAN loss: 11.50374984741211\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 729/1400 GAN loss: 9.15673828125\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 730/1400 GAN loss: 13.627717018127441\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 731/1400 GAN loss: 10.299216270446777\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 732/1400 GAN loss: 15.75949478149414\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 733/1400 GAN loss: 17.59920310974121\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoche: 734/1400 GAN loss: 14.610164642333984\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 735/1400 GAN loss: 17.53385353088379\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 736/1400 GAN loss: 14.671707153320312\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 737/1400 GAN loss: 13.256784439086914\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 738/1400 GAN loss: 12.578649520874023\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 739/1400 GAN loss: 18.060264587402344\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 740/1400 GAN loss: 20.749706268310547\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 741/1400 GAN loss: 2.4806270599365234\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 742/1400 GAN loss: 1.7213979959487915\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 743/1400 GAN loss: 0.24201084673404694\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 744/1400 GAN loss: 0.6715734004974365\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 745/1400 GAN loss: 0.5504122376441956\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 746/1400 GAN loss: 0.6994662284851074\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 747/1400 GAN loss: 1.1682684421539307\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 748/1400 GAN loss: 1.066110372543335\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 749/1400 GAN loss: 1.195906400680542\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 750/1400 GAN loss: 1.298112154006958\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 751/1400 GAN loss: 1.6384819746017456\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 752/1400 GAN loss: 1.586338758468628\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 753/1400 GAN loss: 1.2815799713134766\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 754/1400 GAN loss: 1.5107886791229248\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 755/1400 GAN loss: 1.4295110702514648\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 756/1400 GAN loss: 1.2551345825195312\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 757/1400 GAN loss: 1.1455140113830566\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 758/1400 GAN loss: 0.5653294324874878\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 759/1400 GAN loss: 0.5870853662490845\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 760/1400 GAN loss: 1.2856119871139526\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 761/1400 GAN loss: 1.4015589952468872\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 762/1400 GAN loss: 0.6447827816009521\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 763/1400 GAN loss: 1.572604775428772\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 764/1400 GAN loss: 0.7232025861740112\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 765/1400 GAN loss: 0.7139861583709717\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 766/1400 GAN loss: 1.2995643615722656\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 767/1400 GAN loss: 0.6918798685073853\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 768/1400 GAN loss: 1.5590012073516846\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 769/1400 GAN loss: 0.7248208522796631\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 770/1400 GAN loss: 2.151197910308838\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 771/1400 GAN loss: 2.3348898887634277\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 772/1400 GAN loss: 2.2394111156463623\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 773/1400 GAN loss: 2.7832281589508057\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 774/1400 GAN loss: 3.003391742706299\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 775/1400 GAN loss: 3.343256711959839\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 776/1400 GAN loss: 6.234148979187012\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 777/1400 GAN loss: 2.441088914871216\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 778/1400 GAN loss: 6.035058498382568\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 779/1400 GAN loss: 7.294741630554199\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 780/1400 GAN loss: 9.137264251708984\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 781/1400 GAN loss: 8.18764591217041\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 782/1400 GAN loss: 6.724264144897461\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 783/1400 GAN loss: 13.777460098266602\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 784/1400 GAN loss: 11.538690567016602\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 785/1400 GAN loss: 8.564407348632812\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 786/1400 GAN loss: 14.10638427734375\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 787/1400 GAN loss: 20.577945709228516\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 788/1400 GAN loss: 14.293315887451172\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 789/1400 GAN loss: 27.966590881347656\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 790/1400 GAN loss: 24.403167724609375\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 791/1400 GAN loss: 24.2828369140625\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 792/1400 GAN loss: 24.6918888092041\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 793/1400 GAN loss: 15.808300018310547\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 794/1400 GAN loss: 23.68853759765625\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 795/1400 GAN loss: 34.714813232421875\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 796/1400 GAN loss: 2.248041868209839\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 797/1400 GAN loss: 2.2713518142700195\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 798/1400 GAN loss: 0.2939624786376953\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 799/1400 GAN loss: 0.26292943954467773\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 800/1400 GAN loss: 0.4894697070121765\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 801/1400 GAN loss: 0.5404528975486755\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 802/1400 GAN loss: 0.7988910675048828\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoche: 803/1400 GAN loss: 0.937226414680481\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 804/1400 GAN loss: 1.0405893325805664\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 805/1400 GAN loss: 1.0161702632904053\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 806/1400 GAN loss: 0.869826078414917\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 807/1400 GAN loss: 0.7640253305435181\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 808/1400 GAN loss: 0.7445713877677917\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 809/1400 GAN loss: 0.6478941440582275\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 810/1400 GAN loss: 0.8417658805847168\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 811/1400 GAN loss: 1.8153806924819946\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 812/1400 GAN loss: 5.120521545410156\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 813/1400 GAN loss: 6.671595096588135\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 814/1400 GAN loss: 4.769696235656738\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 815/1400 GAN loss: 6.047965049743652\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 816/1400 GAN loss: 6.903258323669434\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 817/1400 GAN loss: 7.044554710388184\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 818/1400 GAN loss: 6.08607292175293\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 819/1400 GAN loss: 11.774559020996094\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 820/1400 GAN loss: 6.196804046630859\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 821/1400 GAN loss: 15.659149169921875\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 822/1400 GAN loss: 8.324658393859863\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 823/1400 GAN loss: 10.272005081176758\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 824/1400 GAN loss: 10.490330696105957\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 825/1400 GAN loss: 11.577119827270508\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 826/1400 GAN loss: 13.588691711425781\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 827/1400 GAN loss: 7.114526748657227\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 828/1400 GAN loss: 4.419544219970703\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 829/1400 GAN loss: 1.8658989667892456\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 830/1400 GAN loss: 1.1776928901672363\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 831/1400 GAN loss: 2.229217052459717\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 832/1400 GAN loss: 1.989532232284546\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 833/1400 GAN loss: 5.874598979949951\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 834/1400 GAN loss: 11.616687774658203\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 835/1400 GAN loss: 2.801978588104248\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 836/1400 GAN loss: 9.489253997802734\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 837/1400 GAN loss: 12.843311309814453\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 838/1400 GAN loss: 8.391159057617188\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 839/1400 GAN loss: 12.391117095947266\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 840/1400 GAN loss: 10.115428924560547\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 841/1400 GAN loss: 6.426536560058594\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 842/1400 GAN loss: 8.418899536132812\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 843/1400 GAN loss: 6.1002068519592285\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 844/1400 GAN loss: 9.834565162658691\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 845/1400 GAN loss: 13.15804672241211\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 846/1400 GAN loss: 16.693418502807617\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 847/1400 GAN loss: 0.5403732657432556\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 848/1400 GAN loss: 0.47151631116867065\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 849/1400 GAN loss: 0.41899052262306213\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 850/1400 GAN loss: 0.44854578375816345\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 851/1400 GAN loss: 0.6200389266014099\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 852/1400 GAN loss: 0.8364588022232056\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 853/1400 GAN loss: 0.9425269365310669\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 854/1400 GAN loss: 0.8650089502334595\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 855/1400 GAN loss: 0.6636313199996948\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 856/1400 GAN loss: 0.5064325332641602\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 857/1400 GAN loss: 0.5107889175415039\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 858/1400 GAN loss: 0.6195098161697388\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 859/1400 GAN loss: 0.7624866962432861\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 860/1400 GAN loss: 0.8265457153320312\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 861/1400 GAN loss: 0.7336658835411072\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 862/1400 GAN loss: 0.6879357099533081\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 863/1400 GAN loss: 0.6832960844039917\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 864/1400 GAN loss: 0.697257936000824\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 865/1400 GAN loss: 0.7042029500007629\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 866/1400 GAN loss: 0.7137736082077026\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 867/1400 GAN loss: 0.6749063730239868\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoche: 868/1400 GAN loss: 0.6545311212539673\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 869/1400 GAN loss: 0.6040016412734985\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 870/1400 GAN loss: 0.6004781723022461\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 871/1400 GAN loss: 0.5763918161392212\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 872/1400 GAN loss: 0.5571706295013428\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 873/1400 GAN loss: 0.6061867475509644\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 874/1400 GAN loss: 0.6713767051696777\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 875/1400 GAN loss: 0.7405453324317932\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 876/1400 GAN loss: 0.8055959343910217\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 877/1400 GAN loss: 0.7726000547409058\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 878/1400 GAN loss: 0.7146730422973633\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 879/1400 GAN loss: 0.616685688495636\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 880/1400 GAN loss: 0.5474692583084106\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 881/1400 GAN loss: 0.5502212643623352\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 882/1400 GAN loss: 0.5714213848114014\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 883/1400 GAN loss: 0.6730479598045349\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 884/1400 GAN loss: 0.758850634098053\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 885/1400 GAN loss: 0.7879683375358582\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 886/1400 GAN loss: 0.7910569906234741\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 887/1400 GAN loss: 0.7525172233581543\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 888/1400 GAN loss: 0.6838656663894653\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 889/1400 GAN loss: 0.6658229827880859\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 890/1400 GAN loss: 0.6254242062568665\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 891/1400 GAN loss: 0.6302103996276855\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 892/1400 GAN loss: 0.632905125617981\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 893/1400 GAN loss: 0.6827747821807861\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 894/1400 GAN loss: 0.7124353647232056\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 895/1400 GAN loss: 0.7481374740600586\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 896/1400 GAN loss: 0.7676051259040833\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 897/1400 GAN loss: 0.7206841111183167\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 898/1400 GAN loss: 0.7251068353652954\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 899/1400 GAN loss: 0.6748889088630676\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 900/1400 GAN loss: 0.6289135813713074\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 901/1400 GAN loss: 0.5795618295669556\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 902/1400 GAN loss: 0.5627760291099548\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 903/1400 GAN loss: 0.5785369873046875\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 904/1400 GAN loss: 0.6302851438522339\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 905/1400 GAN loss: 0.6892299652099609\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 906/1400 GAN loss: 0.7578219175338745\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 907/1400 GAN loss: 0.7927181720733643\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 908/1400 GAN loss: 0.7863959074020386\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 909/1400 GAN loss: 0.7424243688583374\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 910/1400 GAN loss: 0.6544201374053955\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 911/1400 GAN loss: 0.5881969928741455\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 912/1400 GAN loss: 0.5619485974311829\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 913/1400 GAN loss: 0.5852301716804504\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 914/1400 GAN loss: 0.5887296199798584\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 915/1400 GAN loss: 0.58555006980896\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 916/1400 GAN loss: 0.7387463450431824\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 917/1400 GAN loss: 0.7705378532409668\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 918/1400 GAN loss: 0.8053451180458069\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 919/1400 GAN loss: 0.7961891889572144\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 920/1400 GAN loss: 0.7512753009796143\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 921/1400 GAN loss: 0.6713032126426697\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 922/1400 GAN loss: 0.6299197673797607\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 923/1400 GAN loss: 0.6139965057373047\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 924/1400 GAN loss: 0.6458488702774048\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 925/1400 GAN loss: 0.6363351941108704\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 926/1400 GAN loss: 0.6065194606781006\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 927/1400 GAN loss: 0.640746533870697\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 928/1400 GAN loss: 0.6193481683731079\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 929/1400 GAN loss: 0.5908375382423401\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 930/1400 GAN loss: 0.6456621885299683\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 931/1400 GAN loss: 0.696101725101471\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 932/1400 GAN loss: 0.7147969007492065\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoche: 933/1400 GAN loss: 0.7038207054138184\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 934/1400 GAN loss: 0.7233921885490417\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 935/1400 GAN loss: 0.7884939908981323\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 936/1400 GAN loss: 0.7700597643852234\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 937/1400 GAN loss: 0.8148317933082581\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 938/1400 GAN loss: 0.8189860582351685\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 939/1400 GAN loss: 0.7248862385749817\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 940/1400 GAN loss: 0.6661434769630432\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 941/1400 GAN loss: 0.6782901287078857\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 942/1400 GAN loss: 0.6809131503105164\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 943/1400 GAN loss: 0.6723004579544067\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 944/1400 GAN loss: 0.7230041027069092\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 945/1400 GAN loss: 0.7410805225372314\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoche: 946/1400 GAN loss: 0.758705735206604\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 947/1400 GAN loss: 0.7404727935791016\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 948/1400 GAN loss: 0.7545938491821289\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 949/1400 GAN loss: 0.7675589323043823\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 950/1400 GAN loss: 0.7457528114318848\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 951/1400 GAN loss: 0.6950912475585938\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 952/1400 GAN loss: 0.6011302471160889\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 953/1400 GAN loss: 0.575795590877533\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 954/1400 GAN loss: 0.6399669647216797\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 955/1400 GAN loss: 0.591423511505127\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 956/1400 GAN loss: 0.651806116104126\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 957/1400 GAN loss: 0.7049784660339355\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 958/1400 GAN loss: 0.7664320468902588\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 959/1400 GAN loss: 0.7730966806411743\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 960/1400 GAN loss: 0.8928963541984558\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 961/1400 GAN loss: 0.7877342700958252\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 962/1400 GAN loss: 0.7924251556396484\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 963/1400 GAN loss: 0.7325074672698975\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 964/1400 GAN loss: 0.7324390411376953\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 965/1400 GAN loss: 0.7431827783584595\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 966/1400 GAN loss: 0.7137526869773865\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 967/1400 GAN loss: 1.0523066520690918\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 968/1400 GAN loss: 1.643462896347046\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 969/1400 GAN loss: 2.485044002532959\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 970/1400 GAN loss: 3.346813678741455\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 971/1400 GAN loss: 2.4297916889190674\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 972/1400 GAN loss: 2.4022879600524902\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 973/1400 GAN loss: 2.3526177406311035\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 974/1400 GAN loss: 2.466144561767578\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 975/1400 GAN loss: 2.477644205093384\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 976/1400 GAN loss: 2.7129454612731934\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 977/1400 GAN loss: 3.1248135566711426\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 978/1400 GAN loss: 3.3891725540161133\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 979/1400 GAN loss: 3.362766981124878\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 980/1400 GAN loss: 3.458373785018921\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 981/1400 GAN loss: 3.2600436210632324\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 982/1400 GAN loss: 3.727760076522827\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 983/1400 GAN loss: 3.2893338203430176\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 984/1400 GAN loss: 3.788533926010132\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 985/1400 GAN loss: 5.313516616821289\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 986/1400 GAN loss: 4.402122974395752\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 987/1400 GAN loss: 2.7213644981384277\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 988/1400 GAN loss: 3.7604026794433594\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 989/1400 GAN loss: 2.6189067363739014\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 990/1400 GAN loss: 3.481356143951416\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 991/1400 GAN loss: 3.3895299434661865\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 992/1400 GAN loss: 2.559014081954956\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 993/1400 GAN loss: 2.4941444396972656\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 994/1400 GAN loss: 2.0813379287719727\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 995/1400 GAN loss: 1.564204454421997\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 996/1400 GAN loss: 1.6100499629974365\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 997/1400 GAN loss: 1.5810089111328125\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 998/1400 GAN loss: 1.9573081731796265\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 999/1400 GAN loss: 1.7059082984924316\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1000/1400 GAN loss: 1.883662462234497\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1001/1400 GAN loss: 2.30306339263916\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1002/1400 GAN loss: 3.1875898838043213\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1003/1400 GAN loss: 2.8935813903808594\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1004/1400 GAN loss: 2.4265995025634766\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1005/1400 GAN loss: 1.9964499473571777\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1006/1400 GAN loss: 2.508026361465454\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1007/1400 GAN loss: 2.1804420948028564\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1008/1400 GAN loss: 2.5138580799102783\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1009/1400 GAN loss: 2.2863364219665527\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 1010/1400 GAN loss: 2.3937008380889893\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1011/1400 GAN loss: 2.2537343502044678\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1012/1400 GAN loss: 2.113208293914795\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1013/1400 GAN loss: 3.113518714904785\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1014/1400 GAN loss: 3.6829288005828857\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1015/1400 GAN loss: 3.079149007797241\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1016/1400 GAN loss: 3.243345022201538\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1017/1400 GAN loss: 4.159307956695557\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 1018/1400 GAN loss: 5.504049777984619\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1019/1400 GAN loss: 5.373310089111328\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1020/1400 GAN loss: 3.5074849128723145\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1021/1400 GAN loss: 3.6641950607299805\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1022/1400 GAN loss: 4.703927516937256\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1023/1400 GAN loss: 5.377292156219482\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 1024/1400 GAN loss: 7.033104419708252\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1025/1400 GAN loss: 6.104475021362305\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1026/1400 GAN loss: 6.626897811889648\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1027/1400 GAN loss: 7.119913101196289\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1028/1400 GAN loss: 7.220932960510254\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1029/1400 GAN loss: 8.170196533203125\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1030/1400 GAN loss: 7.576229572296143\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 1031/1400 GAN loss: 8.614558219909668\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1032/1400 GAN loss: 12.900932312011719\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1033/1400 GAN loss: 10.734413146972656\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1034/1400 GAN loss: 7.681263446807861\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1035/1400 GAN loss: 10.802580833435059\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1036/1400 GAN loss: 15.262947082519531\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1037/1400 GAN loss: 8.571564674377441\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 1038/1400 GAN loss: 6.621847152709961\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1039/1400 GAN loss: 11.472789764404297\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1040/1400 GAN loss: 1.1534041166305542\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1041/1400 GAN loss: 0.2975120544433594\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1042/1400 GAN loss: 0.6337010860443115\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1043/1400 GAN loss: 0.897167444229126\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1044/1400 GAN loss: 1.4749771356582642\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 1045/1400 GAN loss: 1.665759801864624\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1046/1400 GAN loss: 1.6001145839691162\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1047/1400 GAN loss: 1.3629788160324097\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1048/1400 GAN loss: 1.2674741744995117\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1049/1400 GAN loss: 1.1640971899032593\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1050/1400 GAN loss: 1.0330123901367188\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1051/1400 GAN loss: 1.1737734079360962\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1052/1400 GAN loss: 1.3206102848052979\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1053/1400 GAN loss: 1.5393813848495483\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1054/1400 GAN loss: 1.3919439315795898\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1055/1400 GAN loss: 1.8145668506622314\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 1056/1400 GAN loss: 1.7808741331100464\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1057/1400 GAN loss: 2.1831936836242676\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1058/1400 GAN loss: 2.044283151626587\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1059/1400 GAN loss: 2.1374616622924805\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1060/1400 GAN loss: 2.0788023471832275\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1061/1400 GAN loss: 2.0334596633911133\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1062/1400 GAN loss: 2.392925262451172\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1063/1400 GAN loss: 2.4217824935913086\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1064/1400 GAN loss: 2.7450671195983887\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1065/1400 GAN loss: 2.6085498332977295\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1066/1400 GAN loss: 2.9363269805908203\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1067/1400 GAN loss: 2.3933277130126953\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1068/1400 GAN loss: 2.760761260986328\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1069/1400 GAN loss: 2.5638320446014404\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1070/1400 GAN loss: 2.7293694019317627\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1071/1400 GAN loss: 2.6993355751037598\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1072/1400 GAN loss: 2.558570384979248\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 1073/1400 GAN loss: 3.6211929321289062\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1074/1400 GAN loss: 3.7715182304382324\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1075/1400 GAN loss: 4.481227874755859\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1076/1400 GAN loss: 4.573616981506348\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1077/1400 GAN loss: 3.5634069442749023\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1078/1400 GAN loss: 3.8871757984161377\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1079/1400 GAN loss: 3.095518112182617\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 1080/1400 GAN loss: 3.562028408050537\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1081/1400 GAN loss: 4.451072692871094\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1082/1400 GAN loss: 5.176418304443359\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1083/1400 GAN loss: 4.638141632080078\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1084/1400 GAN loss: 3.1347548961639404\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1085/1400 GAN loss: 4.761838912963867\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1086/1400 GAN loss: 3.2145533561706543\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 1087/1400 GAN loss: 4.504474639892578\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1088/1400 GAN loss: 4.914641857147217\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1089/1400 GAN loss: 5.354179382324219\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1090/1400 GAN loss: 4.690098762512207\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1091/1400 GAN loss: 6.832204818725586\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1092/1400 GAN loss: 3.695199966430664\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoche: 1093/1400 GAN loss: 3.316312313079834\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1094/1400 GAN loss: 1.6534196138381958\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1095/1400 GAN loss: 1.8657089471817017\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1096/1400 GAN loss: 3.8533918857574463\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1097/1400 GAN loss: 4.621217727661133\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1098/1400 GAN loss: 5.884018421173096\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1099/1400 GAN loss: 5.325726509094238\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1100/1400 GAN loss: 2.95121693611145\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1101/1400 GAN loss: 3.044339656829834\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1102/1400 GAN loss: 1.9595203399658203\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1103/1400 GAN loss: 2.1307904720306396\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1104/1400 GAN loss: 2.8900904655456543\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1105/1400 GAN loss: 3.977863311767578\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1106/1400 GAN loss: 2.7251758575439453\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1107/1400 GAN loss: 4.583402156829834\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1108/1400 GAN loss: 4.79781436920166\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1109/1400 GAN loss: 7.144824028015137\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1110/1400 GAN loss: 6.9477033615112305\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1111/1400 GAN loss: 8.998223304748535\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1112/1400 GAN loss: 12.516218185424805\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1113/1400 GAN loss: 14.559761047363281\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1114/1400 GAN loss: 22.513317108154297\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1115/1400 GAN loss: 18.5445499420166\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 1116/1400 GAN loss: 13.949506759643555\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 1117/1400 GAN loss: 22.56592559814453\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1118/1400 GAN loss: 22.450838088989258\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1119/1400 GAN loss: 9.983190536499023\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1120/1400 GAN loss: 4.510666847229004\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1121/1400 GAN loss: 5.689294338226318\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 1122/1400 GAN loss: 6.242967128753662\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1123/1400 GAN loss: 4.511312484741211\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1124/1400 GAN loss: 4.098665237426758\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1125/1400 GAN loss: 4.874352931976318\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1126/1400 GAN loss: 11.158796310424805\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1127/1400 GAN loss: 12.828788757324219\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 1128/1400 GAN loss: 10.170923233032227\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1129/1400 GAN loss: 10.32217788696289\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1130/1400 GAN loss: 6.958335876464844\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1131/1400 GAN loss: 4.0745439529418945\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1132/1400 GAN loss: 3.7661426067352295\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoche: 1133/1400 GAN loss: 1.1930770874023438\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1134/1400 GAN loss: 3.484161853790283\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1135/1400 GAN loss: 0.8154728412628174\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1136/1400 GAN loss: 1.2832973003387451\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1137/1400 GAN loss: 2.728670120239258\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1138/1400 GAN loss: 3.913602352142334\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 1139/1400 GAN loss: 2.414280891418457\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1140/1400 GAN loss: 15.482316970825195\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1141/1400 GAN loss: 11.788957595825195\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1142/1400 GAN loss: 12.010700225830078\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1143/1400 GAN loss: 9.872088432312012\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1144/1400 GAN loss: 9.484783172607422\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1145/1400 GAN loss: 8.22041130065918\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1146/1400 GAN loss: 13.328432083129883\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1147/1400 GAN loss: 14.890104293823242\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1148/1400 GAN loss: 11.307283401489258\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1149/1400 GAN loss: 5.937745094299316\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1150/1400 GAN loss: 10.053559303283691\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1151/1400 GAN loss: 11.210321426391602\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1152/1400 GAN loss: 7.340414047241211\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1153/1400 GAN loss: 14.131293296813965\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1154/1400 GAN loss: 13.74135684967041\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 1155/1400 GAN loss: 9.08734130859375\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1156/1400 GAN loss: 3.6621365547180176\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1157/1400 GAN loss: 8.773782730102539\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1158/1400 GAN loss: 10.851489067077637\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1159/1400 GAN loss: 9.54409408569336\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1160/1400 GAN loss: 3.622654438018799\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1161/1400 GAN loss: 5.058750629425049\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1162/1400 GAN loss: 4.110397815704346\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1163/1400 GAN loss: 3.233114719390869\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1164/1400 GAN loss: 8.813904762268066\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 1165/1400 GAN loss: 12.766458511352539\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1166/1400 GAN loss: 15.104799270629883\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1167/1400 GAN loss: 16.84735107421875\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1168/1400 GAN loss: 10.757719039916992\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1169/1400 GAN loss: 5.676487445831299\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1170/1400 GAN loss: 14.68091106414795\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1171/1400 GAN loss: 15.3876953125\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1172/1400 GAN loss: 4.81721830368042\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1173/1400 GAN loss: 8.691020965576172\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1174/1400 GAN loss: 4.85180139541626\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 1175/1400 GAN loss: 4.0035624504089355\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1176/1400 GAN loss: 19.605243682861328\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1177/1400 GAN loss: 3.10105562210083\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1178/1400 GAN loss: 0.17349183559417725\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1179/1400 GAN loss: 3.7508201599121094\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1180/1400 GAN loss: 3.495915412902832\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1181/1400 GAN loss: 0.295769065618515\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1182/1400 GAN loss: 0.434872567653656\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1183/1400 GAN loss: 2.519731044769287\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1184/1400 GAN loss: 0.6108956336975098\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1185/1400 GAN loss: 0.7954819798469543\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1186/1400 GAN loss: 2.229909896850586\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1187/1400 GAN loss: 2.561511993408203\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1188/1400 GAN loss: 1.1522903442382812\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1189/1400 GAN loss: 2.4380972385406494\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1190/1400 GAN loss: 1.587937355041504\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1191/1400 GAN loss: 1.6392145156860352\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1192/1400 GAN loss: 5.389884948730469\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1193/1400 GAN loss: 1.2561510801315308\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1194/1400 GAN loss: 4.092993259429932\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1195/1400 GAN loss: 2.3374381065368652\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 1196/1400 GAN loss: 2.010530471801758\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1197/1400 GAN loss: 4.140251159667969\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1198/1400 GAN loss: 3.1560776233673096\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1199/1400 GAN loss: 4.607349872589111\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1200/1400 GAN loss: 0.7792606949806213\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 1201/1400 GAN loss: 3.887739658355713\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1202/1400 GAN loss: 2.4735724925994873\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1203/1400 GAN loss: 3.8483846187591553\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1204/1400 GAN loss: 2.603524684906006\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 1205/1400 GAN loss: 3.017031192779541\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1206/1400 GAN loss: 4.316034317016602\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 1207/1400 GAN loss: 4.17423152923584\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1208/1400 GAN loss: 2.571129560470581\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1209/1400 GAN loss: 4.160721302032471\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1210/1400 GAN loss: 7.155043125152588\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 1211/1400 GAN loss: 3.3590784072875977\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1212/1400 GAN loss: 1.8261414766311646\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1213/1400 GAN loss: 0.8587445616722107\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1214/1400 GAN loss: 3.1729838848114014\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1215/1400 GAN loss: 0.968384325504303\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1216/1400 GAN loss: 1.0288071632385254\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1217/1400 GAN loss: 3.8340673446655273\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1218/1400 GAN loss: 3.2051401138305664\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1219/1400 GAN loss: 3.829066753387451\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1220/1400 GAN loss: 0.7760410308837891\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1221/1400 GAN loss: 0.7034661769866943\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1222/1400 GAN loss: 1.017911672592163\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1223/1400 GAN loss: 0.9263685345649719\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1224/1400 GAN loss: 0.9654927849769592\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1225/1400 GAN loss: 1.2701817750930786\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1226/1400 GAN loss: 1.1907587051391602\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1227/1400 GAN loss: 1.7799134254455566\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1228/1400 GAN loss: 3.532522201538086\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1229/1400 GAN loss: 1.2490277290344238\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1230/1400 GAN loss: 0.8906961679458618\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1231/1400 GAN loss: 2.3621010780334473\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1232/1400 GAN loss: 1.573064923286438\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1233/1400 GAN loss: 2.1651711463928223\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1234/1400 GAN loss: 3.4472475051879883\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1235/1400 GAN loss: 1.9352308511734009\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1236/1400 GAN loss: 2.873882293701172\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 1237/1400 GAN loss: 4.602525234222412\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1238/1400 GAN loss: 4.19696569442749\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1239/1400 GAN loss: 5.2905659675598145\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1240/1400 GAN loss: 4.134261131286621\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1241/1400 GAN loss: 2.3711886405944824\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1242/1400 GAN loss: 2.1385385990142822\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1243/1400 GAN loss: 3.5720415115356445\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1244/1400 GAN loss: 3.6179897785186768\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1245/1400 GAN loss: 4.477896690368652\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1246/1400 GAN loss: 3.0742626190185547\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1247/1400 GAN loss: 3.035388708114624\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1248/1400 GAN loss: 5.388328552246094\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1249/1400 GAN loss: 1.2437721490859985\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1250/1400 GAN loss: 7.543369770050049\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1251/1400 GAN loss: 4.669295310974121\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1252/1400 GAN loss: 8.310705184936523\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1253/1400 GAN loss: 5.705587387084961\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1254/1400 GAN loss: 4.672797203063965\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1255/1400 GAN loss: 7.731954574584961\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1256/1400 GAN loss: 2.8621206283569336\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1257/1400 GAN loss: 4.234811782836914\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1258/1400 GAN loss: 4.897063255310059\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1259/1400 GAN loss: 5.387511253356934\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1260/1400 GAN loss: 1.8451669216156006\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1261/1400 GAN loss: 6.233429908752441\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 1262/1400 GAN loss: 3.089076280593872\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1263/1400 GAN loss: 2.8182287216186523\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1264/1400 GAN loss: 2.3751602172851562\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1265/1400 GAN loss: 4.298625469207764\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1266/1400 GAN loss: 2.8515572547912598\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 1267/1400 GAN loss: 1.7951346635818481\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1268/1400 GAN loss: 5.6055908203125\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1269/1400 GAN loss: 6.0666985511779785\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1270/1400 GAN loss: 5.767242908477783\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1271/1400 GAN loss: 12.572957992553711\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 1272/1400 GAN loss: 0.6540899276733398\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1273/1400 GAN loss: 0.4500488042831421\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1274/1400 GAN loss: 0.37939515709877014\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1275/1400 GAN loss: 0.41632577776908875\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1276/1400 GAN loss: 0.7489248514175415\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1277/1400 GAN loss: 1.0451515913009644\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1278/1400 GAN loss: 1.306004524230957\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1279/1400 GAN loss: 1.1412770748138428\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1280/1400 GAN loss: 0.7400671243667603\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1281/1400 GAN loss: 0.5996671319007874\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 1282/1400 GAN loss: 0.5563241839408875\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1283/1400 GAN loss: 0.6824796199798584\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1284/1400 GAN loss: 0.9482869505882263\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1285/1400 GAN loss: 1.2044720649719238\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1286/1400 GAN loss: 1.0698312520980835\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 1287/1400 GAN loss: 0.8573459386825562\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1288/1400 GAN loss: 0.6948108673095703\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1289/1400 GAN loss: 0.6915426254272461\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 1290/1400 GAN loss: 0.7310140132904053\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1291/1400 GAN loss: 0.9696504473686218\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1292/1400 GAN loss: 1.1246308088302612\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1293/1400 GAN loss: 0.981616735458374\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1294/1400 GAN loss: 0.8583459854125977\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1295/1400 GAN loss: 0.7114390134811401\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1296/1400 GAN loss: 0.6687190532684326\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1297/1400 GAN loss: 0.6429893374443054\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1298/1400 GAN loss: 0.6287620067596436\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1299/1400 GAN loss: 0.7022684812545776\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoche: 1300/1400 GAN loss: 0.7128852009773254\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1301/1400 GAN loss: 0.7826195359230042\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1302/1400 GAN loss: 0.7896789312362671\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1303/1400 GAN loss: 0.7806824445724487\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1304/1400 GAN loss: 0.7883342504501343\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 1305/1400 GAN loss: 0.7402104735374451\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1306/1400 GAN loss: 0.662582278251648\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1307/1400 GAN loss: 0.7670223712921143\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1308/1400 GAN loss: 0.6354734897613525\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1309/1400 GAN loss: 0.6954789757728577\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1310/1400 GAN loss: 0.6682566404342651\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1311/1400 GAN loss: 0.7349391579627991\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1312/1400 GAN loss: 0.7253228425979614\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1313/1400 GAN loss: 0.7612369656562805\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1314/1400 GAN loss: 0.785849928855896\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoche: 1315/1400 GAN loss: 0.8249061107635498\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1316/1400 GAN loss: 0.7947400212287903\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1317/1400 GAN loss: 0.7637068629264832\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1318/1400 GAN loss: 0.7141005992889404\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1319/1400 GAN loss: 0.7140723466873169\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 1320/1400 GAN loss: 0.6368497610092163\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1321/1400 GAN loss: 0.6670926213264465\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1322/1400 GAN loss: 0.5849348306655884\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1323/1400 GAN loss: 0.5059075355529785\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1324/1400 GAN loss: 0.579946756362915\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoche: 1325/1400 GAN loss: 0.5278559923171997\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1326/1400 GAN loss: 0.706296443939209\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1327/1400 GAN loss: 0.721320629119873\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1328/1400 GAN loss: 0.7785073518753052\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1329/1400 GAN loss: 0.8614295721054077\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1330/1400 GAN loss: 0.911865234375\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1331/1400 GAN loss: 0.9020849466323853\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1332/1400 GAN loss: 0.8753007650375366\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1333/1400 GAN loss: 0.7949569225311279\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1334/1400 GAN loss: 0.7502381801605225\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 1335/1400 GAN loss: 0.7133015394210815\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1336/1400 GAN loss: 0.6375530958175659\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1337/1400 GAN loss: 0.6767438650131226\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1338/1400 GAN loss: 0.7418736219406128\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1339/1400 GAN loss: 0.707168459892273\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1340/1400 GAN loss: 0.760151743888855\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1341/1400 GAN loss: 0.7441902756690979\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1342/1400 GAN loss: 0.7895988821983337\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1343/1400 GAN loss: 0.819997251033783\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1344/1400 GAN loss: 0.8290455937385559\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 1345/1400 GAN loss: 0.8436596393585205\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1346/1400 GAN loss: 0.8525230884552002\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1347/1400 GAN loss: 0.8231557011604309\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1348/1400 GAN loss: 0.7649070620536804\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1349/1400 GAN loss: 0.7359771728515625\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoche: 1350/1400 GAN loss: 0.6690149307250977\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoche: 1351/1400 GAN loss: 0.6965829133987427\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1352/1400 GAN loss: 0.666272759437561\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1353/1400 GAN loss: 0.6844426393508911\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1354/1400 GAN loss: 0.6938571929931641\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoche: 1355/1400 GAN loss: 0.7470605373382568\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1356/1400 GAN loss: 0.7511903047561646\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1357/1400 GAN loss: 0.7486578226089478\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1358/1400 GAN loss: 0.7711166143417358\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoche: 1359/1400 GAN loss: 0.7550842761993408\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1360/1400 GAN loss: 0.7943544387817383\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1361/1400 GAN loss: 0.7844061851501465\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1362/1400 GAN loss: 0.783125638961792\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1363/1400 GAN loss: 0.7698986530303955\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoche: 1364/1400 GAN loss: 0.8040673732757568\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1365/1400 GAN loss: 0.821090817451477\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1366/1400 GAN loss: 0.8022173047065735\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1367/1400 GAN loss: 0.7565492391586304\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1368/1400 GAN loss: 0.8212417364120483\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1369/1400 GAN loss: 0.7741382122039795\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1370/1400 GAN loss: 0.7761882543563843\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1371/1400 GAN loss: 0.7981188297271729\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1372/1400 GAN loss: 0.7795705795288086\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1373/1400 GAN loss: 0.7846992015838623\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1374/1400 GAN loss: 0.8209092617034912\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1375/1400 GAN loss: 0.7526751756668091\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1376/1400 GAN loss: 0.7654235363006592\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1377/1400 GAN loss: 0.7050172090530396\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 1378/1400 GAN loss: 0.6976732015609741\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1379/1400 GAN loss: 0.7111838459968567\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1380/1400 GAN loss: 0.7317917346954346\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1381/1400 GAN loss: 0.7213568687438965\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1382/1400 GAN loss: 0.7605677843093872\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoche: 1383/1400 GAN loss: 0.7444906234741211\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1384/1400 GAN loss: 0.7280966639518738\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1385/1400 GAN loss: 0.7487884759902954\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1386/1400 GAN loss: 0.7312026023864746\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1387/1400 GAN loss: 0.7335725426673889\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1388/1400 GAN loss: 0.7407724857330322\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1389/1400 GAN loss: 0.7407033443450928\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1390/1400 GAN loss: 0.6622617244720459\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1391/1400 GAN loss: 0.7462495565414429\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoche: 1392/1400 GAN loss: 0.8277194499969482\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1393/1400 GAN loss: 0.7599092721939087\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1394/1400 GAN loss: 0.8734118938446045\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoche: 1395/1400 GAN loss: 0.9571453332901001\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1396/1400 GAN loss: 0.8932552337646484\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoche: 1397/1400 GAN loss: 0.7714431285858154\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1398/1400 GAN loss: 1.011175513267517\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoche: 1399/1400 GAN loss: 0.8337253332138062\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoche: 1400/1400 GAN loss: 1.0849944353103638\n"
     ]
    }
   ],
   "source": [
    "# Train the GAN\n",
    "train(generator, discriminator, GAN, dataset_shapes, dataset_labels, epochs=1400, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334e9e76-bc5c-4bd0-ac06-12dcf6199c49",
   "metadata": {},
   "source": [
    "<h2>Predict mit 2 Klassen</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db817221-f120-485c-ab8a-f710ae34f384",
   "metadata": {},
   "source": [
    "Jetzt können wir durch eingab eines Labels die Generierung der Bilder verändern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5d00d65-f064-44f6-a167-7cddf854e402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fa64fa9f70>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise = np.random.normal(0, 1, (1, 100)) \n",
    "img   = generator([noise, np.array([1])])\n",
    "plt.imshow(img[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5905ae-050d-44f2-b79f-b0113447e322",
   "metadata": {},
   "source": [
    "<h1>Sonstiges</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e84ad3-9a50-4db1-9a87-fca4d7e528a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
